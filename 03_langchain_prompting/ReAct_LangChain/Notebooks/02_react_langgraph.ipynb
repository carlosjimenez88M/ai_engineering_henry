{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# ReAct con LangGraph: Arquitectura de Agente con Herramientas Visualizable\n",
    "\n",
    "Este notebook demuestra como migrar ReAct (Reasoning + Acting) desde implementaciones manuales de LangChain a **LangGraph**, habilitando:\n",
    "\n",
    "1. **Visualizacion de arquitectura**: Grafos PNG renderizados con `draw_mermaid_png()`\n",
    "2. **ToolNode integrado**: Ejecucion automatica de herramientas con routing\n",
    "3. **Debugging mejorado**: Trazas de tool calls con observaciones\n",
    "4. **Patron agente-tools**: Ciclo automatizado Thought->Action->Observation\n",
    "5. **Composabilidad**: Nodos reutilizables y flujos condicionales\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Fundamento Teorico: ReAct (Reasoning + Acting)\n",
    "\n",
    "### Origen y Contexto Historico\n",
    "\n",
    "ReAct es un paradigma de prompting introducido por **Yao et al. (2022)** en el paper \"ReAct: Synergizing Reasoning and Acting in Language Models\". A diferencia de Chain of Thought (CoT) que solo genera razonamiento interno, ReAct permite que el modelo **interactue con el mundo externo** mediante herramientas.\n",
    "\n",
    "El fundamento teorico se basa en:\n",
    "\n",
    "1. **Agentes cognitivos** (Newell & Simon, 1976): Los sistemas inteligentes requieren tanto razonamiento interno como capacidad de actuar sobre el entorno.\n",
    "2. **Aprendizaje activo** (Sutton & Barto, 1998): La observacion de resultados de acciones mejora la toma de decisiones futuras.\n",
    "3. **Tool use en LLMs** (Schick et al., 2023 - Toolformer): Los modelos pueden aprender cuando y como usar herramientas externas.\n",
    "\n",
    "### Diseno Arquitectonico\n",
    "\n",
    "En esta implementacion, ReAct se estructura como un **grafo ciclico** con los siguientes componentes:\n",
    "\n",
    "```\n",
    "agent -> [tools] -> agent -> [tools] -> ... -> END\n",
    "   |                 |         |\n",
    "Thought           Action   Observation\n",
    "```\n",
    "\n",
    "**Componentes clave:**\n",
    "\n",
    "1. **Agent Node**: Decide que accion tomar (call tool o dar respuesta final)\n",
    "2. **Tool Node**: Ejecuta herramientas en paralelo y retorna observaciones\n",
    "3. **Conditional Router**: Decide si continuar con tools o terminar\n",
    "4. **Message History**: Mantiene historial completo de Thought->Action->Observation\n",
    "\n",
    "**Ciclo ReAct:**\n",
    "\n",
    "- **Thought**: El agente razona sobre el estado actual y decide que hacer\n",
    "- **Action**: Ejecuta una herramienta especifica (analizar_perfil, generar_mensaje, auditar_respeto)\n",
    "- **Observation**: Recibe resultado de la herramienta y actualiza su conocimiento\n",
    "- **Repeat**: Vuelve a Thought con nueva informacion hasta completar tarea\n",
    "\n",
    "### Criterios de Decision\n",
    "\n",
    "**Usa ReAct cuando:**\n",
    "\n",
    "- Necesitas interactuar con APIs, bases de datos, o sistemas externos\n",
    "- La tarea requiere validacion o auditoria de outputs intermedios\n",
    "- Quieres trazabilidad completa de acciones (compliance, debugging)\n",
    "- El razonamiento debe estar fundamentado en observaciones reales (no alucinaciones)\n",
    "- Necesitas control granular sobre el flujo de ejecucion\n",
    "\n",
    "**NO uses ReAct cuando:**\n",
    "\n",
    "- La tarea es puramente de razonamiento interno (usa CoT)\n",
    "- No tienes herramientas que aporten valor real\n",
    "- La latencia es critica y las herramientas son lentas\n",
    "- Una llamada directa al LLM ya cumple los requisitos\n",
    "- El costo de tool calls no justifica la mejora de precision\n",
    "\n",
    "### Trade-offs y Limitaciones\n",
    "\n",
    "| Dimension | ReAct | CoT | Direct Prompting | Notas |\n",
    "|-----------|-------|-----|------------------|-------|\n",
    "| **Precision con tools** | Muy Alta | Media | Baja | ReAct evita alucinaciones usando tools |\n",
    "| **Latencia** | Alta (tools + LLM) | Media (solo LLM) | Baja | Cada tool call agrega latencia |\n",
    "| **Costo** | Alto (multi-turn) | Medio | Bajo | ~5-10x mas tokens que direct |\n",
    "| **Trazabilidad** | Maxima | Alta | Baja | Historial completo de actions |\n",
    "| **Explicabilidad** | Maxima | Alta | Baja | Thought + Action + Observation |\n",
    "| **Control de flujo** | Dinamico | Fijo | Fijo | El agente decide dinamicamente |\n",
    "| **Complejidad impl.** | Alta | Media | Baja | Requiere tools + routing |\n",
    "| **Failure modes** | Tool errors | Logic errors | Hallucinations | Diferentes puntos de falla |\n",
    "\n",
    "**Failure modes comunes:**\n",
    "\n",
    "1. **Tool description drift**: Descripciones ambiguas -> el agente usa tools incorrectamente\n",
    "2. **Infinite loops**: Sin guardrails de max_iterations -> el agente cicla indefinidamente\n",
    "3. **Tool errors no manejados**: Herramienta falla -> todo el pipeline se rompe\n",
    "4. **Hallucination in observations**: El agente inventa resultados de tools que no ejecuto\n",
    "5. **Tool overload**: Demasiadas herramientas -> el agente se confunde\n",
    "\n",
    "### Consideraciones de Produccion\n",
    "\n",
    "**Escalabilidad:**\n",
    "- ReAct es inherentemente secuencial (cada tool call depende del anterior)\n",
    "- Considera ejecutar tools independientes en paralelo (ToolNode hace esto automaticamente)\n",
    "- Implementa caching de tool results para contextos similares\n",
    "- Usa modelos mas rapidos para decision making (Haiku), mas potentes para razonamiento complejo (Opus)\n",
    "\n",
    "**Monitoreo:**\n",
    "- Trackea: num_tool_calls, latency_per_tool, token_usage_per_turn, success_rate\n",
    "- Alertas: max_iterations_exceeded, tool_error_rate > 5%, unexpected_tool_sequences\n",
    "- Logs: Historial completo de messages para replay y debugging\n",
    "\n",
    "**Timeouts:**\n",
    "- Timeout por tool (e.g., 5s para tools rapidos, 30s para APIs lentas)\n",
    "- Timeout global del agente (e.g., 2 minutos)\n",
    "- Max iterations (e.g., 10 tool calls) para evitar loops infinitos\n",
    "\n",
    "**Validacion de tools:**\n",
    "- Todas las tools deben tener docstrings claros con ejemplos\n",
    "- Input/output schemas bien definidos (Pydantic)\n",
    "- Error handling explicito en cada tool\n",
    "- Unit tests para cada tool antes de usarlos en el agente\n",
    "\n",
    "### Referencias Academicas\n",
    "\n",
    "- **Yao et al. (2022)**: \"ReAct: Synergizing Reasoning and Acting in Language Models\" - Paper original de ReAct\n",
    "- **Schick et al. (2023)**: \"Toolformer: Language Models Can Teach Themselves to Use Tools\" - Fundamento de tool use\n",
    "- **Newell & Simon (1976)**: \"Computer Science as Empirical Inquiry\" - Fundamento cognitivo de agentes\n",
    "- **Sutton & Barto (1998)**: \"Reinforcement Learning: An Introduction\" - Learning from observations\n",
    "- **Wei et al. (2022)**: \"Chain of Thought Prompting\" - Comparacion con CoT puro\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "# Setup\nimport sys\nfrom pathlib import Path\n\n# Agregar root al path para imports\nrepo_root = Path.cwd()\nwhile not (repo_root / \"pyproject.toml\").exists() and repo_root != repo_root.parent:\n    repo_root = repo_root.parent\nsys.path.insert(0, str(repo_root))\n\n# Agregar 03_langchain_prompting al path para common imports\nlangchain_prompting_path = repo_root / \"03_langchain_prompting\"\nif str(langchain_prompting_path) not in sys.path:\n    sys.path.insert(0, str(langchain_prompting_path))\n\n# Imports\nfrom IPython.display import Image, display\nimport json"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ReAct_LangChain'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Importar modulo\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mReAct_LangChain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mNotebooks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m react_langgraph_02 \u001b[38;5;28;01mas\u001b[39;00m react_module\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Importar funciones\u001b[39;00m\n\u001b[32m      5\u001b[39m build_react_graph = react_module.build_react_graph\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'ReAct_LangChain'"
     ]
    }
   ],
   "source": [
    "# Importar modulo\n",
    "from ReAct_LangChain.Notebooks import react_langgraph_02 as react_module\n",
    "\n",
    "# Importar funciones\n",
    "build_react_graph = react_module.build_react_graph\n",
    "run_react_langgraph = react_module.run_react_langgraph\n",
    "ReActState = react_module.ReActState"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Visualizacion del Grafo ReAct\n",
    "\n",
    "A continuacion, construimos el grafo de ReAct y visualizamos su arquitectura usando `draw_mermaid_png()`. Este grafo muestra:\n",
    "\n",
    "- **Agent Node**: Decide que accion tomar (thought)\n",
    "- **Tool Node**: Ejecuta herramientas en paralelo (action)\n",
    "- **Conditional Routing**: Decide si continuar con tools o terminar\n",
    "- **Ciclo feedback**: tools -> agent -> tools (observation loop)\n",
    "\n",
    "**Nota tecnica**: LangGraph renderiza el grafo usando Mermaid y Graphviz. Si la visualizacion falla, se mostrara el codigo Mermaid en texto plano.\n",
    "\n",
    "**Diferencia clave vs CoT**: En CoT el flujo es lineal (zero_shot -> few_shot -> evaluate -> refine). En ReAct el flujo es **ciclico** (agent <-> tools) hasta que el agente decide terminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir grafo ReAct\n",
    "app = build_react_graph()\n",
    "\n",
    "# Visualizar arquitectura\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "    print(\"\\n[Grafo renderizado exitosamente]\")\n",
    "    print(\"Observa el ciclo: agent -> tools -> agent -> tools -> ... -> END\")\n",
    "except Exception as e:\n",
    "    print(f\"No se pudo renderizar grafo PNG: {e}\")\n",
    "    print(\"Asegurate de tener graphviz instalado: brew install graphviz (macOS)\")\n",
    "    print(\"\\nGrafo en formato mermaid:\")\n",
    "    print(app.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Ejemplo 1: Arquitecta Apasionada por Fotografia Urbana\n",
    "\n",
    "Ejecutamos el pipeline completo de ReAct con el perfil default. Observa:\n",
    "\n",
    "1. **Tool Call 1: analizar_perfil** - Extrae insights del context packet\n",
    "2. **Tool Call 2: generar_mensaje** - Crea opener y follow_up basado en analisis\n",
    "3. **Tool Call 3: auditar_respeto** - Valida que el mensaje sea respetuoso\n",
    "4. **Final Answer** - Respuesta estructurada con trace summary\n",
    "\n",
    "**Trace de ejecucion:**\n",
    "```\n",
    "[Agent] Thought: Necesito analizar el perfil primero\n",
    "[Agent] Action: analizar_perfil(context_packet)\n",
    "[Tool] Observation: {persona: \"arquitecta...\", insights: [...]}\n",
    "[Agent] Thought: Ahora puedo generar el mensaje\n",
    "[Agent] Action: generar_mensaje(analysis)\n",
    "[Tool] Observation: {opener: \"...\", follow_up: \"...\"}\n",
    "[Agent] Thought: Debo auditar respeto\n",
    "[Agent] Action: auditar_respeto(message)\n",
    "[Tool] Observation: {ok: true, flags: []}\n",
    "[Agent] Thought: Tengo toda la info, puedo dar respuesta final\n",
    "[Agent] Final Answer: {...}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar con perfil default\n",
    "print(\"=\" * 80)\n",
    "print(\"EJECUCION: Perfil arquitecta + fotografia urbana\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result = run_react_langgraph(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Analisis de Resultados Intermedios\n",
    "\n",
    "Inspeccionamos los resultados de cada herramienta ejecutada durante el ciclo ReAct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== ANALISIS DE PERFIL ===\")\n",
    "print(json.dumps(result[\"analysis\"], indent=2, ensure_ascii=False))\n",
    "\n",
    "print(\"\\n=== DRAFT GENERADO ===\")\n",
    "print(json.dumps(result[\"draft\"], indent=2, ensure_ascii=False))\n",
    "\n",
    "print(\"\\n=== AUDITORIA DE RESPETO ===\")\n",
    "print(json.dumps(result[\"audit\"], indent=2, ensure_ascii=False))\n",
    "\n",
    "print(\"\\n=== RESPUESTA FINAL ===\")\n",
    "print(json.dumps(result[\"final_answer\"], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Trace Summary: Observabilidad Completa\n",
    "\n",
    "Una de las principales ventajas de ReAct es la **trazabilidad completa** del proceso de decision. Cada tool call queda registrado con su input y output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== TRACE DE TOOL CALLS ===\")\n",
    "for i, step in enumerate(result[\"trace\"], 1):\n",
    "    print(f\"\\n{i}. Tool: {step['tool']}\")\n",
    "    print(f\"   Result preview: {step['result'][:150]}...\")\n",
    "\n",
    "print(\"\\n=== METADATA ===\")\n",
    "print(f\"Modelo: {result['__model']}\")\n",
    "print(f\"Arquitectura: {result['__architecture']}\")\n",
    "print(f\"Context hash: {result['__context_hash']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Errores Comunes al Implementar ReAct\n",
    "\n",
    "### 1. Tool Descriptions Ambiguas\n",
    "\n",
    "**Problema**: Docstrings poco claros -> el agente no sabe cuando usar cada tool.\n",
    "\n",
    "**Malo:**\n",
    "```python\n",
    "@tool\n",
    "def procesar(data: str) -> str:\n",
    "    \"\"\"Procesa datos.\"\"\"\n",
    "    # Que hace \"procesar\"? Cuando usarlo?\n",
    "    return result\n",
    "```\n",
    "\n",
    "**Bueno:**\n",
    "```python\n",
    "@tool\n",
    "def analizar_perfil(context_packet_json: str) -> str:\n",
    "    \"\"\"Extrae insights accionables desde un context packet JSON.\n",
    "    \n",
    "    Usa esta herramienta PRIMERO antes de generar mensajes.\n",
    "    Input: JSON string con perfil, gustos, estilo.\n",
    "    Output: JSON con persona, estilo_preferido, insights.\n",
    "    \n",
    "    Ejemplo input: {\"profile\": {\"tipo_persona\": \"arquitecta\", ...}}\n",
    "    Ejemplo output: {\"persona\": \"arquitecta\", \"insights\": [...]}\n",
    "    \"\"\"\n",
    "    ...\n",
    "```\n",
    "\n",
    "### 2. Sin Limites de Iteraciones\n",
    "\n",
    "**Problema**: El agente cicla indefinidamente si no logra completar la tarea.\n",
    "\n",
    "**Solucion**: Implementar max_iterations y timeout:\n",
    "```python\n",
    "def agent_node(state: ReActState) -> ReActState:\n",
    "    # Validar max iterations\n",
    "    if state.get(\"iteration_count\", 0) >= 10:\n",
    "        raise RuntimeError(\"Max iterations exceeded\")\n",
    "    \n",
    "    # Incrementar contador\n",
    "    state[\"iteration_count\"] = state.get(\"iteration_count\", 0) + 1\n",
    "    ...\n",
    "```\n",
    "\n",
    "### 3. No Validar Outputs de Tools\n",
    "\n",
    "**Problema**: Confias ciegamente en tool outputs sin validar formato/contenido.\n",
    "\n",
    "**Solucion**: Validacion de schema:\n",
    "```python\n",
    "@tool\n",
    "def analizar_perfil(context_packet_json: str) -> str:\n",
    "    try:\n",
    "        context_packet = json.loads(context_packet_json)\n",
    "        assert \"profile\" in context_packet\n",
    "        # ... procesamiento ...\n",
    "        return json.dumps(result)\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": str(e), \"suggestion\": \"Verifica formato JSON\"})\n",
    "```\n",
    "\n",
    "### 4. Sobrecarga de Herramientas (Tool Overload)\n",
    "\n",
    "**Problema**: Dar 20+ tools al agente -> confusion y mal uso.\n",
    "\n",
    "**Regla empirica**: 3-7 tools es optimo. Mas alla, el agente pierde precision.\n",
    "\n",
    "**Solucion**: Agrupar tools relacionados:\n",
    "```python\n",
    "# Malo: 10 tools micro\n",
    "analizar_nombre, analizar_gustos, analizar_estilo, ...\n",
    "\n",
    "# Bueno: 1 tool con opciones\n",
    "@tool\n",
    "def analizar_perfil(aspect: Literal[\"nombre\", \"gustos\", \"estilo\", \"todo\"]) -> str:\n",
    "    ...\n",
    "```\n",
    "\n",
    "### 5. Sin Timeout por Tool\n",
    "\n",
    "**Problema**: Una tool lenta bloquea todo el pipeline.\n",
    "\n",
    "**Solucion**: Wrapper con timeout:\n",
    "```python\n",
    "from functools import wraps\n",
    "import signal\n",
    "\n",
    "def timeout(seconds):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            def handler(signum, frame):\n",
    "                raise TimeoutError(f\"Tool {func.__name__} timeout after {seconds}s\")\n",
    "            \n",
    "            signal.signal(signal.SIGALRM, handler)\n",
    "            signal.alarm(seconds)\n",
    "            try:\n",
    "                return func(*args, **kwargs)\n",
    "            finally:\n",
    "                signal.alarm(0)\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@tool\n",
    "@timeout(5)  # Max 5 segundos\n",
    "def slow_tool(data: str) -> str:\n",
    "    ...\n",
    "```\n",
    "\n",
    "### 6. Sin Guardrails de Secuencia\n",
    "\n",
    "**Problema**: El agente ejecuta tools en orden incorrecto (e.g., auditar antes de generar).\n",
    "\n",
    "**Solucion**: Validacion de secuencia en agent node:\n",
    "```python\n",
    "def agent_node(state: ReActState) -> ReActState:\n",
    "    # Validar secuencia esperada\n",
    "    executed_tools = [msg.name for msg in state[\"messages\"] if isinstance(msg, ToolMessage)]\n",
    "    \n",
    "    if \"generar_mensaje\" in executed_tools and \"analizar_perfil\" not in executed_tools:\n",
    "        raise RuntimeError(\"Debes analizar perfil ANTES de generar mensaje\")\n",
    "    ...\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Decision Tree: Cuando Usar ReAct\n",
    "\n",
    "```\n",
    "Necesitas interactuar con sistemas externos (APIs, DBs, validadores)?\n",
    "- SI NO → Evalua: Necesitas razonamiento multi-paso?\n",
    "  - SI SI → Usa CoT (mas simple, mas rapido)\n",
    "  - SI NO → Usa Direct Prompting\n",
    "- SI SI → Evalua: Las tools aportan valor real (no mock)?\n",
    "    - SI NO → Reconsiderar arquitectura (tal vez no necesitas agente)\n",
    "    - SI SI → Evalua: El costo/latencia es aceptable?\n",
    "        - SI NO → Optimizar tools (caching, paralelizacion) o reconsiderar\n",
    "        - SI SI → Usa ReAct\n",
    "```\n",
    "\n",
    "**Casos de uso claros para ReAct:**\n",
    "\n",
    "- **Customer support con acceso a CRM**: Buscar info del cliente, crear tickets, actualizar estado\n",
    "- **Data analysis agent**: Query databases, run scripts, generate reports\n",
    "- **Code review bot**: Read files, run linters, suggest fixes, create PRs\n",
    "- **Content moderation**: Analyze text, check against policies, flag/approve\n",
    "- **Booking assistant**: Check availability, make reservations, send confirmations\n",
    "\n",
    "**Casos donde ReAct es overkill:**\n",
    "\n",
    "- **Clasificacion de texto**: No necesitas tools, un prompt directo funciona\n",
    "- **Traduccion simple**: Direct prompting es suficiente\n",
    "- **Resumen de texto**: CoT puede ayudar, pero tools no aportan\n",
    "- **Generacion creativa**: Las tools suelen limitar creatividad\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Comparacion: LangGraph vs Loop Manual\n",
    "\n",
    "### Implementacion Manual (Loop ReAct basico)\n",
    "\n",
    "```python\n",
    "# ReAct manual con while loop\n",
    "messages = [HumanMessage(content=\"Task: ...\")]\n",
    "max_iterations = 10\n",
    "\n",
    "for iteration in range(max_iterations):\n",
    "    # Agent decide\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    messages.append(response)\n",
    "    \n",
    "    # Si tiene tool calls, ejecutarlos\n",
    "    if hasattr(response, \"tool_calls\") and response.tool_calls:\n",
    "        for tool_call in response.tool_calls:\n",
    "            # Buscar tool manualmente\n",
    "            tool = next(t for t in tools if t.name == tool_call[\"name\"])\n",
    "            \n",
    "            # Ejecutar tool\n",
    "            result = tool.invoke(tool_call[\"args\"])\n",
    "            \n",
    "            # Agregar observacion\n",
    "            messages.append(ToolMessage(\n",
    "                content=result,\n",
    "                name=tool_call[\"name\"],\n",
    "                tool_call_id=tool_call[\"id\"]\n",
    "            ))\n",
    "    else:\n",
    "        # No mas tool calls, terminar\n",
    "        break\n",
    "\n",
    "final_answer = messages[-1].content\n",
    "```\n",
    "\n",
    "**Problemas:**\n",
    "- Estado (messages) pasado manualmente\n",
    "- Logica de routing mezclada con ejecucion\n",
    "- Dificil de visualizar\n",
    "- Sin checkpointing ni recovery\n",
    "- Dificil de unit test\n",
    "- No hay paralelizacion de tools\n",
    "\n",
    "### LangGraph con ToolNode\n",
    "\n",
    "```python\n",
    "# ReAct con LangGraph\n",
    "def agent_node(state: ReActState) -> ReActState:\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    result = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {**state, \"messages\": [result]}\n",
    "\n",
    "def should_continue(state: ReActState) -> Literal[\"tools\", \"end\"]:\n",
    "    last = state[\"messages\"][-1]\n",
    "    return \"tools\" if hasattr(last, \"tool_calls\") and last.tool_calls else \"end\"\n",
    "\n",
    "# Construir grafo\n",
    "graph = StateGraph(ReActState)\n",
    "graph.add_node(\"agent\", agent_node)\n",
    "graph.add_node(\"tools\", ToolNode(tools))  # ToolNode maneja ejecucion automatica\n",
    "\n",
    "graph.set_entry_point(\"agent\")\n",
    "graph.add_conditional_edges(\"agent\", should_continue, {\"tools\": \"tools\", \"end\": END})\n",
    "graph.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "app = graph.compile()\n",
    "result = app.invoke(initial_state)\n",
    "```\n",
    "\n",
    "**Ventajas:**\n",
    "- Estado compartido via StateGraph (menos boilerplate)\n",
    "- Routing declarativo (should_continue es puro)\n",
    "- ToolNode ejecuta tools automaticamente **en paralelo** si son independientes\n",
    "- Visualizacion built-in (draw_mermaid_png)\n",
    "- Checkpointing con memory/redis (recovery en caso de fallo)\n",
    "- Mejor testing (cada nodo es unit-testable)\n",
    "- Streaming de updates en tiempo real\n",
    "\n",
    "**Trade-off:**\n",
    "- Setup inicial mas verboso (~40 lineas vs 20 del loop)\n",
    "- Curva de aprendizaje (conceptos de grafo, state management)\n",
    "- Overhead minimo en runtime (~5-10ms por invocation)\n",
    "\n",
    "**Conclusion**: Para prototipos rapidos, loop manual puede ser suficiente. Para produccion o pipelines complejos (3+ tools, conditional routing, checkpointing), LangGraph es superior.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Beneficios del ToolNode\n",
    "\n",
    "**ToolNode** es una abstraccion de LangGraph que maneja la ejecucion de herramientas automaticamente. Ventajas:\n",
    "\n",
    "1. **Ejecucion paralela**: Si el agente hace 3 tool calls independientes, ToolNode los ejecuta en paralelo\n",
    "2. **Error handling**: Captura excepciones y las convierte en ToolMessages con error info\n",
    "3. **Tool matching**: Busca la tool correcta por nombre automaticamente\n",
    "4. **Message formatting**: Formatea outputs como ToolMessages con metadata correcto\n",
    "\n",
    "**Comparacion con ejecucion manual:**\n",
    "\n",
    "```python\n",
    "# Manual: ejecutar tools secuencialmente\n",
    "for tool_call in response.tool_calls:\n",
    "    tool = next(t for t in tools if t.name == tool_call[\"name\"])\n",
    "    result = tool.invoke(tool_call[\"args\"])  # Secuencial!\n",
    "    messages.append(ToolMessage(...))\n",
    "\n",
    "# ToolNode: ejecutar en paralelo automaticamente\n",
    "tool_node = ToolNode(tools)\n",
    "result = tool_node.invoke(state)  # Paralelo si tools son independientes!\n",
    "```\n",
    "\n",
    "**Ejemplo de paralelizacion:**\n",
    "\n",
    "Si el agente decide hacer:\n",
    "```\n",
    "tool_calls = [\n",
    "    {\"name\": \"buscar_usuario\", \"args\": {\"id\": 123}},\n",
    "    {\"name\": \"buscar_pedidos\", \"args\": {\"user_id\": 123}},\n",
    "    {\"name\": \"buscar_reviews\", \"args\": {\"user_id\": 123}}\n",
    "]\n",
    "```\n",
    "\n",
    "ToolNode ejecutara las 3 en paralelo (si son independientes) -> latencia total = max(latencias), no sum(latencias).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Proximos Pasos y Experimentacion\n",
    "\n",
    "### 1. Agrega Herramientas Propias\n",
    "\n",
    "Experimenta agregando tools relevantes para tu dominio:\n",
    "\n",
    "```python\n",
    "@tool\n",
    "def buscar_documentacion(query: str) -> str:\n",
    "    \"\"\"Busca en documentacion interna.\n",
    "    \n",
    "    Args:\n",
    "        query: Termino de busqueda\n",
    "    \n",
    "    Returns:\n",
    "        JSON con resultados relevantes\n",
    "    \"\"\"\n",
    "    # Implementar busqueda real (vector DB, Elasticsearch, etc)\n",
    "    results = search_docs(query)\n",
    "    return json.dumps(results)\n",
    "\n",
    "# Agregar a la lista de tools\n",
    "tools = [analizar_perfil, generar_mensaje, auditar_respeto, buscar_documentacion]\n",
    "```\n",
    "\n",
    "### 2. Implementa Guardrails Sofisticados\n",
    "\n",
    "Agrega validacion de secuencia, timeouts, y limites:\n",
    "\n",
    "```python\n",
    "def agent_node_with_guardrails(state: ReActState) -> ReActState:\n",
    "    # Validar max iterations\n",
    "    iteration = state.get(\"iteration\", 0)\n",
    "    if iteration >= 10:\n",
    "        return {**state, \"messages\": [AIMessage(content=\"Max iterations exceeded\")]}\n",
    "    \n",
    "    # Validar secuencia de tools\n",
    "    executed_tools = [m.name for m in state[\"messages\"] if isinstance(m, ToolMessage)]\n",
    "    if \"generar_mensaje\" in executed_tools and \"analizar_perfil\" not in executed_tools:\n",
    "        return {**state, \"messages\": [AIMessage(content=\"Debes analizar antes de generar\")]}\n",
    "    \n",
    "    # Ejecutar agent normalmente\n",
    "    result = agent_node(state)\n",
    "    result[\"iteration\"] = iteration + 1\n",
    "    return result\n",
    "```\n",
    "\n",
    "### 3. Agrega Checkpointing para Long-Running Agents\n",
    "\n",
    "Para agentes que corren por mucho tiempo, implementa checkpointing:\n",
    "\n",
    "```python\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Crear checkpointer\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Compilar con checkpointing\n",
    "app = graph.compile(checkpointer=memory)\n",
    "\n",
    "# Ejecutar con thread_id para recovery\n",
    "config = {\"configurable\": {\"thread_id\": \"user-123-session-456\"}}\n",
    "result = app.invoke(initial_state, config=config)\n",
    "\n",
    "# Si falla, recuperar estado\n",
    "checkpoint = memory.get(config)\n",
    "recovered_result = app.invoke(checkpoint.state, config=config)\n",
    "```\n",
    "\n",
    "### 4. Implementa A/B Testing\n",
    "\n",
    "Compara diferentes versiones del agente:\n",
    "\n",
    "```python\n",
    "# Version A: modelo rapido + 3 tools\n",
    "def agent_node_v1(state):\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    tools = [analizar_perfil, generar_mensaje, auditar_respeto]\n",
    "    ...\n",
    "\n",
    "# Version B: modelo lento + 5 tools\n",
    "def agent_node_v2(state):\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "    tools = [analizar_perfil, generar_mensaje, auditar_respeto, buscar_docs, validate_output]\n",
    "    ...\n",
    "\n",
    "# Medir precision, latencia, costo\n",
    "results_v1 = [run_react_langgraph(agent_node=agent_node_v1) for _ in range(100)]\n",
    "results_v2 = [run_react_langgraph(agent_node=agent_node_v2) for _ in range(100)]\n",
    "\n",
    "# Comparar metricas\n",
    "print(f\"V1 latency: {mean([r['latency'] for r in results_v1])}s\")\n",
    "print(f\"V2 latency: {mean([r['latency'] for r in results_v2])}s\")\n",
    "```\n",
    "\n",
    "### 5. Migra a Async para Mejor Performance\n",
    "\n",
    "Para produccion, usa invocacion async:\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "\n",
    "async def agent_node_async(state: ReActState) -> ReActState:\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    result = await llm_with_tools.ainvoke(state[\"messages\"])\n",
    "    return {**state, \"messages\": [result]}\n",
    "\n",
    "# Ejecutar multiples requests en paralelo\n",
    "results = await asyncio.gather(\n",
    "    app.ainvoke(state1),\n",
    "    app.ainvoke(state2),\n",
    "    app.ainvoke(state3),\n",
    ")\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Conclusion y Autocritica\n",
    "\n",
    "**Ventajas de ReAct con LangGraph:**\n",
    "\n",
    "1. Visualizacion de arquitectura (grafo PNG) facilita debugging\n",
    "2. ToolNode elimina boilerplate de ejecucion manual de tools\n",
    "3. Routing declarativo hace el flujo mas claro y testeable\n",
    "4. Checkpointing built-in permite recovery en caso de fallos\n",
    "5. Mejor observabilidad (historial completo de messages)\n",
    "\n",
    "**Limitaciones y consideraciones:**\n",
    "\n",
    "1. **Overhead de setup**: LangGraph requiere mas codigo inicial que un loop simple\n",
    "2. **Curva de aprendizaje**: Conceptos de StateGraph, nodos, edges no son inmediatos\n",
    "3. **Latencia**: Cada tool call agrega latencia (API round-trip)\n",
    "4. **Costo**: Multi-turn conversations consumen mas tokens\n",
    "5. **Debugging**: Aunque mejorado vs manual, debuggear agentes sigue siendo complejo\n",
    "\n",
    "**Cuando vale la pena la inversion:**\n",
    "\n",
    "- Pipelines de produccion con requisitos de observabilidad\n",
    "- Agentes complejos con 3+ tools y conditional routing\n",
    "- Necesidad de checkpointing (long-running agents)\n",
    "- Equipos grandes que necesitan visualizacion de arquitectura\n",
    "\n",
    "**Cuando NO vale la pena:**\n",
    "\n",
    "- Prototipos rapidos (usa loop manual)\n",
    "- Agentes simples con 1-2 tools\n",
    "- Casos donde latencia/costo es critico y precision no justifica el overhead\n",
    "\n",
    "**Siguiente notebook**: Implementacion de ReAct para casos de uso avanzados (multi-agent systems, human-in-the-loop).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejemplo 2: Herramientas Especializadas de Coqueteo\n",
    "\n",
    "Ahora demostramos ReAct con **4 herramientas avanzadas** específicas para coqueteo y matching:\n",
    "\n",
    "1. **analizar_compatibilidad**: Evalúa match entre perfiles (gustos, estilos, red flags)\n",
    "2. **generar_icebreaker**: Crea 3 opciones calibradas por tono (conservador/medio/atrevido)\n",
    "3. **predecir_respuesta**: Predice probabilidad de respuesta + mejoras sugeridas\n",
    "4. **escalar_conversacion**: Sugiere próximo paso (profundizar/proponer_cita/mantener_ritmo/retomar)\n",
    "\n",
    "**Objetivo pedagógico**: Mostrar que ReAct puede usar herramientas especializadas de dominio para tomar decisiones más informadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar personas y herramientas para el ejemplo 2\n",
    "from common.coqueteo_personas import (\n",
    "    get_persona_romantico_clasico,\n",
    "    get_persona_moderno_carismatico,\n",
    "    get_match_cientifica_aventurera\n",
    ")\n",
    "\n",
    "# Importar herramientas para inspección\n",
    "from common.coqueteo_tools import COQUETEO_TOOLS\n",
    "\n",
    "print(\"Herramientas especializadas disponibles:\")\n",
    "for tool in COQUETEO_TOOLS:\n",
    "    print(f\"  - {tool.name}: {tool.description[:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2A. El Romántico Clásico con Herramientas Avanzadas\n",
    "\n",
    "**Perfil**: Galán mexicano tradicional\n",
    "\n",
    "**Match**: Neurocientífica aventurera\n",
    "\n",
    "**Hipótesis**: Las herramientas detectarán:\n",
    "- Compatibilidad media-alta (intereses complementarios)\n",
    "- Recomendarán tono conservador para icebreaker\n",
    "- Identificarán que lenguaje poético puede funcionar con perfil intelectual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener personas\n",
    "persona_romantico = get_persona_romantico_clasico()\n",
    "match_cientifica = get_match_cientifica_aventurera()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ESCENARIO: Romántico Clásico -> Neurocientífica Aventurera\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Persona: {persona_romantico['pais_origen']} - {persona_romantico['tipo_persona']}\")\n",
    "print(f\"Match: {match_cientifica['nombre']} - {match_cientifica['profesion']}\")\n",
    "print(f\"\\nIntereses del match: {', '.join(match_cientifica['intereses'][:3])}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Ejecutar ReAct con herramientas especializadas\n",
    "result_romantico_tools = run_react_with_coqueteo_tools(\n",
    "    persona_dict=persona_romantico,\n",
    "    match_dict=match_cientifica,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis: Herramientas en Acción\n",
    "\n",
    "Inspecciona qué herramientas se llamaron y sus outputs:\n",
    "\n",
    "1. **analizar_compatibilidad**: ¿Qué porcentaje de compatibilidad detectó? ¿Qué áreas de conexión identificó?\n",
    "2. **generar_icebreaker**: ¿Qué tono recomendó? ¿Las opciones reflejan el estilo romántico clásico?\n",
    "3. **predecir_respuesta**: ¿Qué probabilidad de respuesta estimó? ¿Qué mejoras sugirió?\n",
    "\n",
    "**Observación clave**: Las herramientas permiten que el agente tome decisiones informadas en vez de generar directamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"INSPECCION DETALLADA: Resultados de Herramientas\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "tool_results = result_romantico_tools['tool_results']\n",
    "\n",
    "# 1. Compatibilidad\n",
    "if 'analizar_compatibilidad' in tool_results:\n",
    "    compat = tool_results['analizar_compatibilidad']\n",
    "    print(f\"\\n1. COMPATIBILIDAD: {compat.get('compatibilidad_porcentaje', 'N/A')}%\")\n",
    "    print(f\"   Areas de conexion:\")\n",
    "    for area in compat.get('areas_conexion', [])[:3]:\n",
    "        print(f\"     - {area}\")\n",
    "    print(f\"   Red flags: {len(compat.get('red_flags_detectadas', []))}\")\n",
    "\n",
    "# 2. Icebreaker\n",
    "if 'generar_icebreaker' in tool_results:\n",
    "    ice = tool_results['generar_icebreaker']\n",
    "    print(f\"\\n2. ICEBREAKER GENERADO\")\n",
    "    for i, opcion in enumerate(ice.get('opciones', [])[:2], 1):\n",
    "        print(f\"   Opcion {i}: {opcion['texto'][:100]}...\")\n",
    "        print(f\"   Probabilidad exito: {opcion['probabilidad_exito']}%\")\n",
    "\n",
    "# 3. Predicción\n",
    "if 'predecir_respuesta' in tool_results:\n",
    "    pred = tool_results['predecir_respuesta']\n",
    "    print(f\"\\n3. PREDICCION DE RESPUESTA: {pred.get('probabilidad_respuesta', 'N/A')}%\")\n",
    "    print(f\"   Factores positivos: {len(pred.get('factores_positivos', []))}\")\n",
    "    print(f\"   Factores negativos: {len(pred.get('factores_negativos', []))}\")\n",
    "    print(f\"   Mejoras sugeridas: {len(pred.get('mejoras_sugeridas', []))}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2B. El Moderno Carismático con Herramientas Avanzadas\n",
    "\n",
    "**Perfil**: Latino colombiano urbano, bilingüe, nomada digital\n",
    "\n",
    "**Match**: Misma neurocientífica aventurera\n",
    "\n",
    "**Hipótesis**: Las herramientas detectarán:\n",
    "- Compatibilidad alta (estilos más alineados: aventura + modernidad)\n",
    "- Recomendarán tono medio-atrevido para icebreaker\n",
    "- Identificarán que humor autoirónico y Spanglish pueden funcionar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener persona moderna\n",
    "persona_moderno = get_persona_moderno_carismatico()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ESCENARIO: Moderno Carismático -> Neurocientífica Aventurera\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Persona: {persona_moderno['pais_origen']} - {persona_moderno['tipo_persona']}\")\n",
    "print(f\"Match: {match_cientifica['nombre']} - {match_cientifica['profesion']}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Ejecutar ReAct\n",
    "result_moderno_tools = run_react_with_coqueteo_tools(\n",
    "    persona_dict=persona_moderno,\n",
    "    match_dict=match_cientifica,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparación: Romántico vs Moderno\n",
    "\n",
    "Comparemos cómo las mismas herramientas generan outputs diferentes para cada arquetipo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPARACION: Romántico Clásico vs Moderno Carismático\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "rom_compat = result_romantico_tools['tool_results'].get('analizar_compatibilidad', {})\n",
    "mod_compat = result_moderno_tools['tool_results'].get('analizar_compatibilidad', {})\n",
    "\n",
    "print(\"\\n1. COMPATIBILIDAD:\")\n",
    "print(f\"   Romántico: {rom_compat.get('compatibilidad_porcentaje', 'N/A')}%\")\n",
    "print(f\"   Moderno:   {mod_compat.get('compatibilidad_porcentaje', 'N/A')}%\")\n",
    "\n",
    "rom_ice = result_romantico_tools['tool_results'].get('generar_icebreaker', {})\n",
    "mod_ice = result_moderno_tools['tool_results'].get('generar_icebreaker', {})\n",
    "\n",
    "print(\"\\n2. ICEBREAKER (Primera Opción):\")\n",
    "if rom_ice.get('opciones'):\n",
    "    print(f\"   Romántico: {rom_ice['opciones'][0]['texto'][:120]}...\")\n",
    "if mod_ice.get('opciones'):\n",
    "    print(f\"   Moderno:   {mod_ice['opciones'][0]['texto'][:120]}...\")\n",
    "\n",
    "rom_pred = result_romantico_tools['tool_results'].get('predecir_respuesta', {})\n",
    "mod_pred = result_moderno_tools['tool_results'].get('predecir_respuesta', {})\n",
    "\n",
    "print(\"\\n3. PROBABILIDAD DE RESPUESTA:\")\n",
    "print(f\"   Romántico: {rom_pred.get('probabilidad_respuesta', 'N/A')}%\")\n",
    "print(f\"   Moderno:   {mod_pred.get('probabilidad_respuesta', 'N/A')}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"INSIGHT CLAVE:\")\n",
    "print(\"Las herramientas especializadas permiten que el agente ReAct tome decisiones\")\n",
    "print(\"basadas en análisis cuantitativo en vez de generar outputs directamente.\")\n",
    "print(\"Esto resulta en estrategias más calibradas y explicables.\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Herramientas como Sistema Experto\n",
    "\n",
    "### Por Qué Usar Herramientas en Vez de Generación Directa\n",
    "\n",
    "**Approach 1: Generación Directa (sin herramientas)**\n",
    "```python\n",
    "prompt = \"Genera un icebreaker para este perfil: {profile}\"\n",
    "response = llm.invoke(prompt)\n",
    "```\n",
    "\n",
    "**Problemas:**\n",
    "- Output es caja negra (no sabemos cómo llegó a esa conclusión)\n",
    "- Difícil de auditar o mejorar\n",
    "- No puedes inyectar conocimiento de dominio\n",
    "- Inconsistente entre runs\n",
    "\n",
    "**Approach 2: ReAct con Herramientas (arquitectura actual)**\n",
    "```python\n",
    "tools = [analizar_compatibilidad, generar_icebreaker, predecir_respuesta]\n",
    "agent = create_react_agent(llm, tools)\n",
    "response = agent.invoke(profile)\n",
    "```\n",
    "\n",
    "**Ventajas:**\n",
    "- **Explicabilidad**: Puedes ver qué herramientas se llamaron y por qué\n",
    "- **Modularidad**: Puedes mejorar/reemplazar herramientas individuales\n",
    "- **Conocimiento de dominio**: Las herramientas encapsulan heurísticas probadas\n",
    "- **Auditabilidad**: Cada decisión tiene trace\n",
    "- **Testing**: Puedes testear herramientas independientemente\n",
    "\n",
    "### Cuándo Usar Herramientas\n",
    "\n",
    "**Usa herramientas cuando:**\n",
    "- La tarea requiere decisiones multi-paso basadas en datos\n",
    "- Necesitas explicabilidad (qué se analizó, qué se decidió, por qué)\n",
    "- Tienes conocimiento de dominio que quieres codificar (scoring, reglas de negocio)\n",
    "- Quieres poder iterar en componentes individuales\n",
    "\n",
    "**NO uses herramientas cuando:**\n",
    "- La tarea es simple y directa (clasificación, extracción)\n",
    "- No necesitas explicabilidad ni auditoría\n",
    "- La latencia es crítica (cada tool call agrega ~1-3s)\n",
    "- El modelo es suficientemente capaz de resolver en un paso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proximos Pasos\n",
    "\n",
    "1. **Crea tus propias herramientas especializadas**: Define tools para tu dominio específico\n",
    "2. **Implementa scoring cuantitativo**: Agrega métricas numéricas a tus herramientas (como compatibilidad_porcentaje)\n",
    "3. **A/B testing de estrategias**: Compara herramientas simples vs complejas\n",
    "4. **Implementa feedback loop**: Usa resultados reales para ajustar heurísticas de herramientas\n",
    "5. **Monitorea tool usage**: Trackea qué herramientas se usan más y su tasa de éxito\n",
    "\n",
    "**Comparación con CoT**: Mientras CoT es ideal para razonamiento explícito paso-a-paso, ReAct brilla cuando necesitas **ejecutar acciones** (buscar, calcular, validar) entre pasos de razonamiento.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brief-ai-vs-software-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}