{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39cc48a1",
   "metadata": {},
   "source": [
    "# CoT con LangChain (Avanzado)\n",
    "\n",
    "## Definición\n",
    "CoT en LangChain explicita pasos de razonamiento y, combinado con salida estructurada, mejora auditabilidad y depuración.\n",
    "\n",
    "## Cuándo usarlo\n",
    "- Cuando necesitas consistencia de razonamiento en tareas ambiguas.\n",
    "- Cuando quieres comparar zero-shot vs few-shot con evidencia.\n",
    "\n",
    "## Cuándo NO usarlo\n",
    "- Tareas triviales/determinísticas donde una función tradicional resuelve mejor.\n",
    "- Contextos de latencia ultra-baja donde el costo de tokens importa demasiado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69047903",
   "metadata": {},
   "source": [
    "## Flujo conceptual\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "A[Context Packet] --> B[Zero-shot CoT]\n",
    "A --> C[Few-shot CoT]\n",
    "C --> D[Evaluar]\n",
    "D --> E[Refinar]\n",
    "E --> F[Seleccionar mejor salida]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2292234f",
   "metadata": {},
   "outputs": [],
   "source": "# Setup de notebook\nfrom __future__ import annotations\n\nimport importlib.util\nimport inspect\nimport json\nimport sys\nfrom pathlib import Path\nfrom IPython.display import Markdown, display\n\n# Add project root to path\nproject_root = Path.cwd()\nwhile not (project_root / \"pyproject.toml\").exists() and project_root.parent != project_root:\n    project_root = project_root.parent\nsys.path.insert(0, str(project_root))\n\ndef load_module(path: Path, module_name: str):\n    spec = importlib.util.spec_from_file_location(module_name, path)\n    if spec is None or spec.loader is None:\n        raise RuntimeError(f\"Cannot load module: {path}\")\n    module = importlib.util.module_from_spec(spec)\n    sys.modules[module_name] = module\n    spec.loader.exec_module(module)\n    return module\n\nROOT = project_root\nprint('Repo root:', ROOT)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52b3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "script = ROOT / '03_langchain_prompting/COT_LangChain/Notebooks/01_cot_langchain_avanzado.py'\n",
    "module = load_module(script, 'cot_langchain_nb')\n",
    "run_fn = module.run_cot_langchain\n",
    "print('Script:', script)\n",
    "print('Firma:', inspect.signature(run_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa06b22a",
   "metadata": {},
   "source": [
    "## Código fuente principal (visible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c76e70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inspect.getsource(run_fn)[:6000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a4aa0a",
   "metadata": {},
   "source": [
    "## Ejemplo 1: caso base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec7711",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = run_fn(verbose=False)\n",
    "print('Modelo:', result_1['__model'])\n",
    "print('Context hash:', result_1['__context_hash'])\n",
    "print('Evaluación final:')\n",
    "print(json.dumps(result_1['selected_eval'], ensure_ascii=False, indent=2))\n",
    "print('Salida final:')\n",
    "print(json.dumps(result_1['selected'], ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1439d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('## Flujo real usado en ejecución'))\n",
    "display(Markdown('```mermaid\\n' + result_1['__flow_mermaid'] + '\\n```'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0fe413",
   "metadata": {},
   "source": [
    "## Ejemplo 2: coqueteo (asistente latino experto en enamorar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82db978",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_coqueteo = {\n",
    "  \"tipo_persona\": \"asistente latino experto en enamorar con elegancia\",\n",
    "  \"gustos\": [\n",
    "    \"salsa romantica\",\n",
    "    \"cafes bohemios\",\n",
    "    \"poesia urbana\",\n",
    "    \"paseos nocturnos\"\n",
    "  ],\n",
    "  \"estilo\": \"carismatico, coqueto, respetuoso, humor picante sutil\",\n",
    "  \"contexto\": \"quiere iniciar una conversacion de coqueteo sin frases prefabricadas\"\n",
    "}\n",
    "result_2 = run_fn(profile=profile_coqueteo, verbose=False)\n",
    "print('Context hash coqueteo:', result_2['__context_hash'])\n",
    "print('Evaluación final coqueteo:')\n",
    "print(json.dumps(result_2['selected_eval'], ensure_ascii=False, indent=2))\n",
    "print('Salida final coqueteo:')\n",
    "print(json.dumps(result_2['selected'], ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e720f",
   "metadata": {},
   "source": [
    "## Errores típicos en producción\n",
    "- Few-shot con ejemplos sesgados: bloquea creatividad y generalización.\n",
    "- Context packet sin deduplicar: sube costo y degrada enfoque.\n",
    "- Feedback loop sin umbral claro: loops caros y poca mejora real.\n",
    "- Rúbrica débil: falsa sensación de calidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603e1786",
   "metadata": {},
   "source": [
    "## Autocrítica\n",
    "- CoT mejora explicabilidad, pero no garantiza verdad factual.\n",
    "- El mayor retorno viene del context engineering, no del truco de prompt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}