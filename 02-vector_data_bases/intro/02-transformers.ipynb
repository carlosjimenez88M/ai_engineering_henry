{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f108864",
   "metadata": {},
   "source": "![Henry Logo](https://www.soyhenry.com/_next/static/media/HenryLogo.bb57fd6f.svg)\n\n# Introducción a las bases de datos vectoriales \n## Clase #2 :Transformers"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09c5ca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55dd48a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "MODEL_NAME = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b81a084b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs de Tokens: [170149, 878, 55219, 26745, 1209, 1334, 6928, 726, 13]\n",
      "Tokens de texto: ['Nunca', ' es', ' demasiado', ' tarde', ' para', ' ser', ' sab', 'io', '.']\n",
      "   Token ID  Token Text\n",
      "0    170149       Nunca\n",
      "1       878          es\n",
      "2     55219   demasiado\n",
      "3     26745       tarde\n",
      "4      1209        para\n",
      "5      1334         ser\n",
      "6      6928         sab\n",
      "7       726          io\n",
      "8        13           .\n"
     ]
    }
   ],
   "source": [
    "text = \"Nunca es demasiado tarde para ser sabio.\"\n",
    "encoding = tiktoken.encoding_for_model(MODEL_NAME)\n",
    "# Convertir texto a tokens (IDs)\n",
    "token_ids = encoding.encode(text)\n",
    "print(f\"IDs de Tokens: {token_ids}\")\n",
    "\n",
    "# Ver los tokens en texto (decodificando uno por uno para inspeccionar)\n",
    "tokens_text = [encoding.decode_single_token_bytes(token).decode('utf-8') for token in token_ids]\n",
    "print(f\"Tokens de texto: {tokens_text}\")\n",
    "\n",
    "# Mostrar tabla comparativa (visualización típica del Cap 3)\n",
    "df_tokens = pd.DataFrame({\"Token ID\": token_ids, \"Token Text\": tokens_text})\n",
    "print(df_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e63dac15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión del vector: 1536\n",
      "Primeros 15 valores: [0.04944195970892906, 0.0063703227788209915, -0.023048294708132744, 0.02860943041741848, 0.0323023721575737, 0.005335756577551365, -0.002712682355195284, 0.03712491691112518, -0.039753422141075134, 0.006033613346517086, 0.01627066358923912, -0.006707032211124897, 0.020007049664855003, -0.018019378185272217, 0.026958467438817024]\n"
     ]
    }
   ],
   "source": [
    "response = client.embeddings.create(\n",
    "    input=text,\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "embedding_vector = response.data[0].embedding\n",
    "print(f\"Dimensión del vector: {len(embedding_vector)}\") \n",
    "print(f\"Primeros 15 valores: {embedding_vector[:15]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fbfa815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: La capital de Argentina es \n",
      "Completado: La capital de Argentina es Buenos Aires.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"La capital de Argentina es \"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    max_tokens=15,\n",
    "    logprobs=True,      # <--- Esto habilita la inspección\n",
    "    top_logprobs=5      # <--- Ver las top 5 opciones para cada token\n",
    ")\n",
    "\n",
    "# Extraer el contenido generado\n",
    "generated_content = response.choices[0].message.content\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Completado: {generated_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc796f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspección de Probabilidades (Looking Inside) ---\n",
      "\n",
      "Paso 1: Token elegido -> 'La' (100.00% confianza)\n",
      "   Otras opciones consideradas:\n",
      "     - 'La': 100.00%\n",
      "     - 'Buenos': 0.00%\n",
      "     - 'la': 0.00%\n",
      "     - ' La': 0.00%\n",
      "     - 'El': 0.00%\n",
      "\n",
      "Paso 2: Token elegido -> ' capital' (100.00% confianza)\n",
      "   Otras opciones consideradas:\n",
      "     - ' capital': 100.00%\n",
      "     - ' Capital': 0.00%\n",
      "     - ' capit': 0.00%\n",
      "     - 'capital': 0.00%\n",
      "     - ' ciudad': 0.00%\n",
      "\n",
      "Paso 3: Token elegido -> ' de' (100.00% confianza)\n",
      "   Otras opciones consideradas:\n",
      "     - ' de': 100.00%\n",
      "     - ' del': 0.00%\n",
      "     - 'de': 0.00%\n",
      "     - ' of': 0.00%\n",
      "     - ' Argentina': 0.00%\n",
      "\n",
      "Paso 4: Token elegido -> ' Argentina' (100.00% confianza)\n",
      "   Otras opciones consideradas:\n",
      "     - ' Argentina': 100.00%\n",
      "     - 'Argentina': 0.00%\n",
      "     - ' argentina': 0.00%\n",
      "     - ' Arg': 0.00%\n",
      "     - ' Argent': 0.00%\n",
      "\n",
      "Paso 5: Token elegido -> ' es' (100.00% confianza)\n",
      "   Otras opciones consideradas:\n",
      "     - ' es': 100.00%\n",
      "     - ' Es': 0.00%\n",
      "     - ' is': 0.00%\n",
      "     - '是': 0.00%\n",
      "     - ',': 0.00%\n",
      "\n",
      "Paso 6: Token elegido -> ' Buenos' (100.00% confianza)\n",
      "   Otras opciones consideradas:\n",
      "     - ' Buenos': 100.00%\n",
      "     - 'Buenos': 0.00%\n",
      "     - ' Ciudad': 0.00%\n",
      "     - ' Bu': 0.00%\n",
      "     - ' la': 0.00%\n",
      "\n",
      "Paso 7: Token elegido -> ' Aires' (100.00% confianza)\n",
      "   Otras opciones consideradas:\n",
      "     - ' Aires': 100.00%\n",
      "     - ' Ai': 0.00%\n",
      "     - ' Aire': 0.00%\n",
      "     - ' AI': 0.00%\n",
      "     - ' Aries': 0.00%\n",
      "\n",
      "Paso 8: Token elegido -> '.' (100.00% confianza)\n",
      "   Otras opciones consideradas:\n",
      "     - '.': 100.00%\n",
      "     - '.\n",
      "': 0.00%\n",
      "     - '.\n",
      "\n",
      "': 0.00%\n",
      "     - '।': 0.00%\n",
      "     - ',': 0.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Inspección de Probabilidades (Looking Inside) ---\")\n",
    "for i, token_data in enumerate(response.choices[0].logprobs.content):\n",
    "    token = token_data.token\n",
    "    prob = np.exp(token_data.logprob) * 100  # Convertir logprob a % real\n",
    "    \n",
    "    print(f\"\\nPaso {i+1}: Token elegido -> '{token}' ({prob:.2f}% confianza)\")\n",
    "    \n",
    "    print(\"   Otras opciones consideradas:\")\n",
    "    for top_k in token_data.top_logprobs:\n",
    "        top_prob = np.exp(top_k.logprob) * 100\n",
    "        print(f\"     - '{top_k.token}': {top_prob:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vector-data-bases",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}