{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d46313",
   "metadata": {},
   "source": [
    "![](https://www.soyhenry.com/_next/static/media/HenryLogo.bb57fd6f.svg)\n",
    "\n",
    "# Introducción a las bases de datos vectoriales \n",
    "## Clase #4 :Rags Y bases de datos Vectoriales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3985a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T22:20:01.582272Z",
     "iopub.status.busy": "2026-02-17T22:20:01.582083Z",
     "iopub.status.idle": "2026-02-17T22:20:04.791298Z",
     "shell.execute_reply": "2026-02-17T22:20:04.790903Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from sklearn.manifold import TSNE\n",
    "from openai import OpenAI\n",
    "from langchain_core.documents import Document ### Este es el bueno!!!\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473eabc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T22:20:04.792329Z",
     "iopub.status.busy": "2026-02-17T22:20:04.792221Z",
     "iopub.status.idle": "2026-02-17T22:20:04.803517Z",
     "shell.execute_reply": "2026-02-17T22:20:04.803176Z"
    }
   },
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaab6324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T22:20:04.804614Z",
     "iopub.status.busy": "2026-02-17T22:20:04.804560Z",
     "iopub.status.idle": "2026-02-17T22:20:04.807790Z",
     "shell.execute_reply": "2026-02-17T22:20:04.807523Z"
    }
   },
   "outputs": [],
   "source": [
    "movies_info = [\n",
    "    {\n",
    "        \"title\": \"RoboCop\",\n",
    "        \"content\": (\n",
    "            \"RoboCop (1987), dirigida por Paul Verhoeven, es una película de ciencia ficción y acción ambientada en un Detroit \"\n",
    "            \"futurista plagado de crimen y controlado por la megacorporación OCP (Omni Consumer Products). \"\n",
    "            \"El oficial de policía Alex Murphy (Peter Weller) es brutalmente asesinado por la banda del criminal Clarence Boddicker \"\n",
    "            \"(Kurtwood Smith) durante una patrulla. OCP recupera su cuerpo y lo transforma en RoboCop, un cíborg policía \"\n",
    "            \"sobrehumano con armadura de titanio, fuerza extraordinaria y puntería perfecta. \"\n",
    "            \"Aunque su memoria ha sido oficialmente borrada, Murphy comienza a experimentar fragmentos de recuerdos de su vida \"\n",
    "            \"pasada: su esposa Ellen, su hijo Jimmy, y el trauma de su propia muerte. \"\n",
    "            \"Mientras lucha contra el crimen callejero, RoboCop descubre una conspiración dentro de OCP liderada por el \"\n",
    "            \"vicepresidente Dick Jones, quien está aliado con Boddicker. La película explora temas de identidad, humanidad vs \"\n",
    "            \"tecnología, corrupción corporativa, privatización de servicios públicos y la lucha por recuperar la esencia humana \"\n",
    "            \"en un mundo dominado por las máquinas y el capitalismo desmedido.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"The Terminator\",\n",
    "        \"content\": (\n",
    "            \"The Terminator (1984), dirigida por James Cameron, es una película de ciencia ficción y acción. \"\n",
    "            \"En el año 2029, la inteligencia artificial Skynet domina el mundo tras una guerra nuclear que casi extermina \"\n",
    "            \"a la humanidad. Para asegurar su victoria, Skynet envía al pasado (1984) un cíborg asesino llamado T-800 \"\n",
    "            \"(Arnold Schwarzenegger), un Terminator con apariencia humana pero esqueleto de metal y fuerza sobrehumana. \"\n",
    "            \"Su misión es eliminar a Sarah Connor (Linda Hamilton), una joven camarera cuyo hijo aún no nacido, John Connor, \"\n",
    "            \"se convertirá en el líder de la resistencia humana. \"\n",
    "            \"Kyle Reese (Michael Biehn), un soldado de la resistencia, es enviado al mismo período para protegerla. \"\n",
    "            \"La película es una persecución implacable por las calles de Los Ángeles donde Sarah pasa de ser una mujer \"\n",
    "            \"ordinaria a una sobreviviente decidida. La película explora temas de destino vs libre albedrío, \"\n",
    "            \"los peligros de la inteligencia artificial, paradojas temporales y la resistencia humana ante fuerzas \"\n",
    "            \"aparentemente invencibles. Es la primera entrega de una de las franquicias más icónicas del cine de acción.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Interstellar\",\n",
    "        \"content\": (\n",
    "            \"Interstellar (2014), dirigida por Christopher Nolan, es una épica de ciencia ficción protagonizada por \"\n",
    "            \"Matthew McConaughey como Cooper, un expiloto de la NASA y granjero. La Tierra se está muriendo: plagas \"\n",
    "            \"destruyen los cultivos y tormentas de polvo asfixian a la humanidad. La NASA, operando en secreto, \"\n",
    "            \"descubre un agujero de gusano cerca de Saturno que conecta con otra galaxia. \"\n",
    "            \"Cooper es reclutado para liderar la misión Endurance junto a la Dra. Amelia Brand (Anne Hathaway), \"\n",
    "            \"Romilly (David Gyasi) y Doyle (Wes Bentley). Visitan tres planetas candidatos: Miller (con olas gigantes \"\n",
    "            \"donde 1 hora equivale a 7 años terrestres), Mann (un mundo helado donde el Dr. Mann, interpretado por \"\n",
    "            \"Matt Damon, los traiciona) y Edmunds. \"\n",
    "            \"La película está fundamentada en la física teórica del premio Nobel Kip Thorne y explora la dilatación \"\n",
    "            \"temporal, los agujeros negros (el icónico Gargantúa), la quinta dimensión y la gravedad cuántica. \"\n",
    "            \"El corazón emocional es la relación entre Cooper y su hija Murph (Jessica Chastain de adulta): \"\n",
    "            \"el sacrificio de un padre que envejece más lento que sus hijos debido a la relatividad. \"\n",
    "            \"Temas principales: amor trascendiendo el espacio-tiempo, sacrificio, supervivencia de la especie, \"\n",
    "            \"y la tensión entre exploración y quedarse con quienes amamos.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"El Número 23\",\n",
    "        \"content\": (\n",
    "            \"El Número 23 (2007), dirigida por Joel Schumacher, es un thriller psicológico protagonizado por Jim Carrey \"\n",
    "            \"en un papel dramático inusual para él. Walter Sparrow (Carrey) es un empleado de control de animales que \"\n",
    "            \"recibe de su esposa Agatha (Virginia Madsen) un misterioso libro titulado 'El Número 23'. \"\n",
    "            \"A medida que lee la novela, Walter descubre paralelismos inquietantes entre la vida del protagonista ficticio, \"\n",
    "            \"el detective Fingerling, y su propia biografía. Comienza a obsesionarse con el número 23, viéndolo en todas \"\n",
    "            \"partes: fechas de nacimiento, direcciones, eventos históricos (cada dato suma 23). \"\n",
    "            \"La obsesión lo consume hasta el punto de la paranoia y el insomnio. Su esposa y su hijo Robin intentan \"\n",
    "            \"ayudarlo, pero Walter se hunde cada vez más. El giro final revela que Walter mismo escribió el libro años \"\n",
    "            \"atrás, durante un episodio traumático que borró de su memoria: un crimen pasional que cometió y que su \"\n",
    "            \"mente reprimió como mecanismo de defensa. El libro era su confesión inconsciente. \"\n",
    "            \"Temas: obsesión numérica, memoria reprimida, culpa, la línea entre ficción y realidad, y cómo el pasado \"\n",
    "            \"que intentamos olvidar siempre encuentra la manera de resurgir.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"El discreto encanto de la burguesía\",\n",
    "        \"content\": (\n",
    "            \"El discreto encanto de la burguesía (1972), dirigida por Luis Buñuel, es una comedia surrealista francesa \"\n",
    "            \"ganadora del Oscar a Mejor Película Extranjera. El reparto incluye a Fernando Rey, Delphine Seyrig, \"\n",
    "            \"Stéphane Audran, Bulle Ogier y Jean-Pierre Cassel. \"\n",
    "            \"La premisa es engañosamente simple: un grupo de amigos burgueses intenta repetidamente reunirse para cenar \"\n",
    "            \"elegantemente, pero cada intento es frustrado por circunstancias cada vez más absurdas. \"\n",
    "            \"Las interrupciones incluyen: llegar al restaurante el día equivocado, una redada militar que convierte \"\n",
    "            \"la cena en un ejercicio de combate, descubrir que el dueño del restaurante acaba de morir, ser arrestados \"\n",
    "            \"sin razón aparente, y un escenario teatral que los expone como actores sin guion. \"\n",
    "            \"La estructura narrativa incluye múltiples capas de sueños dentro de sueños, donde los personajes despiertan \"\n",
    "            \"de una pesadilla solo para descubrir que siguen soñando. Escenas recurrentes muestran al grupo caminando \"\n",
    "            \"por una carretera vacía sin destino aparente, simbolizando su vacío existencial. \"\n",
    "            \"Temas: sátira de la hipocresía burguesa, crítica al colonialismo, la superficialidad de las convenciones \"\n",
    "            \"sociales, la naturaleza ilusoria de la realidad, y la futilidad de los rituales sociales de la clase alta.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Eterno resplandor de una mente sin recuerdos\",\n",
    "        \"content\": (\n",
    "            \"Eterno resplandor de una mente sin recuerdos (Eternal Sunshine of the Spotless Mind, 2004), dirigida por \"\n",
    "            \"Michel Gondry con guion del aclamado Charlie Kaufman (ganador del Oscar por este guion). \"\n",
    "            \"Protagonizada por Jim Carrey como Joel Barish, un hombre introvertido, y Kate Winslet como Clementine \"\n",
    "            \"Kruczynski, una mujer impulsiva y de pelo colorido. Tras una dolorosa ruptura, Joel descubre que Clementine \"\n",
    "            \"se ha sometido a un procedimiento experimental en la clínica del Dr. Howard Mierzwiak (Tom Wilkinson) \"\n",
    "            \"para borrar selectivamente todos los recuerdos de su relación. \"\n",
    "            \"Devastado, Joel decide hacerse el mismo procedimiento. La mayor parte de la película transcurre dentro \"\n",
    "            \"de la mente de Joel durante el borrado: revivimos su relación en orden inverso, desde las peleas amargas \"\n",
    "            \"hasta los momentos más dulces del enamoramiento. A medida que los recuerdos se desvanecen, Joel se da \"\n",
    "            \"cuenta de que no quiere olvidarla e intenta esconder a Clementine en rincones ocultos de su memoria \"\n",
    "            \"(recuerdos de infancia, humillaciones, memorias no relacionadas). \"\n",
    "            \"El elenco secundario incluye a Kirsten Dunst, Mark Ruffalo y Elijah Wood, cada uno con su propia \"\n",
    "            \"subtrama sobre la memoria y el arrepentimiento. \"\n",
    "            \"Temas principales: la memoria como identidad, el dolor como parte esencial del amor, si borrar el \"\n",
    "            \"sufrimiento vale la pena cuando también se pierde la alegría, el determinismo emocional (¿estamos \"\n",
    "            \"condenados a repetir los mismos patrones?), y la belleza de los momentos imperfectos.\"\n",
    "        )\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0a08f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T22:20:04.808743Z",
     "iopub.status.busy": "2026-02-17T22:20:04.808699Z",
     "iopub.status.idle": "2026-02-17T22:20:04.810109Z",
     "shell.execute_reply": "2026-02-17T22:20:04.809861Z"
    }
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    Document(page_content=m[\"content\"], metadata={\"title\": m[\"title\"]})\n",
    "    for m in movies_info\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0262a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d43fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T22:20:04.810862Z",
     "iopub.status.busy": "2026-02-17T22:20:04.810822Z",
     "iopub.status.idle": "2026-02-17T22:20:05.746492Z",
     "shell.execute_reply": "2026-02-17T22:20:05.746086Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Creando base de datos vectorial...\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\") # <- - Este es el que hay que cambiar : small, medium, large\n",
    "\n",
    "# Creamos la base de datos en memoria (Chroma)\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"peliculas_collection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217db407",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T22:20:05.747890Z",
     "iopub.status.busy": "2026-02-17T22:20:05.747817Z",
     "iopub.status.idle": "2026-02-17T22:20:05.769582Z",
     "shell.execute_reply": "2026-02-17T22:20:05.769207Z"
    }
   },
   "outputs": [],
   "source": [
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 2}) # Traer solo las 2 más relevantes\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "template = \"\"\"\n",
    "Eres un experto en cine. Responde la pregunta basándote SOLAMENTE en el siguiente contexto recuperado.\n",
    "Si la respuesta no está en el contexto.\n",
    "\n",
    "Para cada película relevante, menciona:\n",
    "- El nombre de la película\n",
    "- Cómo se relaciona específicamente con la pregunta\n",
    "- Detalles concretos del contexto que lo demuestren (director, personajes, trama)\n",
    "\n",
    "Contexto:\n",
    "{context}\n",
    "\n",
    "Pregunta: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69782674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T22:20:05.770553Z",
     "iopub.status.busy": "2026-02-17T22:20:05.770504Z",
     "iopub.status.idle": "2026-02-17T22:20:05.772231Z",
     "shell.execute_reply": "2026-02-17T22:20:05.771982Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e0d1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T22:20:05.773019Z",
     "iopub.status.busy": "2026-02-17T22:20:05.772967Z",
     "iopub.status.idle": "2026-02-17T22:20:05.774349Z",
     "shell.execute_reply": "2026-02-17T22:20:05.774059Z"
    }
   },
   "outputs": [],
   "source": [
    "query = \"¿Qué peliculas hablan python?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4gm4bnzudv",
   "metadata": {},
   "source": [
    "## Comparación: LLM sin RAG vs con RAG\n",
    "\n",
    "Ahora vamos a hacer un experimento clave: **hacerle la misma pregunta al LLM de dos formas distintas**:\n",
    "\n",
    "1. **Sin RAG (solo títulos):** Le damos al modelo únicamente los **nombres** de las películas de nuestra base de datos, sin descripciones. El modelo debe responder solo con su conocimiento general, que puede ser vago, incorrecto o incompleto sobre estas películas específicas.\n",
    "\n",
    "2. **Con RAG (contexto recuperado):** El retriever busca los 2 documentos más relevantes en la base vectorial y se los pasa al modelo como contexto. El modelo responde con **detalles específicos** de las descripciones almacenadas.\n",
    "\n",
    "Observa la diferencia: el RAG permite respuestas **más detalladas y fundamentadas** porque el modelo tiene acceso a la información concreta de nuestra base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8wtvhjb0f4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T22:20:05.775334Z",
     "iopub.status.busy": "2026-02-17T22:20:05.775269Z",
     "iopub.status.idle": "2026-02-17T22:20:06.971142Z",
     "shell.execute_reply": "2026-02-17T22:20:06.970516Z"
    }
   },
   "outputs": [],
   "source": [
    "# Respuesta SIN RAG: el LLM solo recibe los títulos, NO las descripciones\n",
    "titulos = [m[\"title\"] for m in movies_info]\n",
    "lista_titulos = \", \".join(titulos)\n",
    "\n",
    "response_sin_rag = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": (\n",
    "            \"Eres un experto en cine. Responde la pregunta del usuario considerando \"\n",
    "            f\"SOLAMENTE estas películas: {lista_titulos}. \"\n",
    "            \"No tienes acceso a sinopsis ni descripciones, solo a los títulos.\"\n",
    "        )},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Respuesta SIN RAG (solo títulos, sin descripciones):\")\n",
    "print(\"-\" * 50)\n",
    "respuesta_sin_rag = response_sin_rag.choices[0].message.content\n",
    "print(respuesta_sin_rag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s8rpp1lorge",
   "metadata": {},
   "source": [
    "### Ahora con RAG: el modelo recibe contexto de la base de datos vectorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29a0e7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T22:20:06.972950Z",
     "iopub.status.busy": "2026-02-17T22:20:06.972825Z",
     "iopub.status.idle": "2026-02-17T22:20:08.321709Z",
     "shell.execute_reply": "2026-02-17T22:20:08.321115Z"
    }
   },
   "outputs": [],
   "source": [
    "respuesta_con_rag = rag_chain.invoke(query)\n",
    "print(\"Respuesta CON RAG:\")\n",
    "print(\"-\" * 50)\n",
    "print(respuesta_con_rag)\n",
    "\n",
    "#################\n",
    "## Agentic Rag ##\n",
    "#################\n",
    "\n",
    "# Mostrar los documentos recuperados\n",
    "print(\"\\n\\nDocumentos recuperados por el retriever:\")\n",
    "print(\"=\" * 50)\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"\\n[Doc {i+1}] {doc.metadata['title']}:\")\n",
    "    print(f\"  {doc.page_content[:150]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34kszlewp4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T22:20:08.323632Z",
     "iopub.status.busy": "2026-02-17T22:20:08.323510Z",
     "iopub.status.idle": "2026-02-17T22:20:08.326920Z",
     "shell.execute_reply": "2026-02-17T22:20:08.326494Z"
    }
   },
   "outputs": [],
   "source": [
    "# Comparación lado a lado\n",
    "print(\"=\" * 70)\n",
    "print(\"COMPARACIÓN: SIN RAG vs CON RAG\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nPregunta: {query}\")\n",
    "print(f\"Películas en la base de datos: {lista_titulos}\")\n",
    "print(\"\\n\" + \"─\" * 70)\n",
    "print(\"SIN RAG (solo títulos, sin descripciones de nuestra BD):\")\n",
    "print(\"─\" * 70)\n",
    "print(respuesta_sin_rag)\n",
    "print(\"\\n\" + \"─\" * 70)\n",
    "print(\"CON RAG (con descripciones recuperadas de la BD vectorial):\")\n",
    "print(\"─\" * 70)\n",
    "print(respuesta_con_rag)\n",
    "print(\"\\n\" + \"─\" * 70)\n",
    "print(\"Documentos recuperados de la base vectorial:\")\n",
    "print(\"─\" * 70)\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"  -> {doc.metadata['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ij3l0djhnp",
   "metadata": {},
   "source": [
    "## Visualización del Espacio Vectorial\n",
    "\n",
    "### ¿Qué es un embedding?\n",
    "Un **embedding** es una representación numérica (vector) de un texto. Cada película y la pregunta se convierten en vectores de alta dimensión (1536 dimensiones con el modelo `text-embedding-3-small`).\n",
    "\n",
    "### ¿Por qué importa la distancia?\n",
    "Textos con **significado similar** quedan **cerca** en el espacio vectorial. La **distancia coseno** mide qué tan similares son dos vectores:\n",
    "- **Distancia 0** = idénticos\n",
    "- **Distancia ~1** = completamente diferentes\n",
    "\n",
    "El retriever del RAG selecciona los **k documentos más cercanos** a la pregunta. En el gráfico siguiente:\n",
    "- Los documentos **recuperados** (más cercanos a la pregunta) se muestran en **verde**\n",
    "- Los documentos **no recuperados** se muestran en **gris**\n",
    "- Las **líneas punteadas** muestran la distancia desde la pregunta a cada documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4575d2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T22:20:08.328195Z",
     "iopub.status.busy": "2026-02-17T22:20:08.328099Z",
     "iopub.status.idle": "2026-02-17T22:20:09.293384Z",
     "shell.execute_reply": "2026-02-17T22:20:09.292854Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "all_docs = vector_db.get()\n",
    "doc_embeddings = embeddings.embed_documents(all_docs['documents'])\n",
    "query_embedding = embeddings.embed_query(query)\n",
    "\n",
    "# Calcular distancias coseno entre la query y cada documento\n",
    "doc_embeddings_array = np.array(doc_embeddings)\n",
    "query_embedding_array = np.array(query_embedding).reshape(1, -1)\n",
    "cosine_dists = cosine_distances(query_embedding_array, doc_embeddings_array)[0]\n",
    "\n",
    "# Identificar los títulos de los documentos recuperados (k=2)\n",
    "retrieved_titles = {doc.metadata['title'] for doc in retrieved_docs}\n",
    "titles = [m['title'] for m in all_docs['metadatas']]\n",
    "\n",
    "# Reducción dimensional con t-SNE\n",
    "combined_matrix = np.array(doc_embeddings + [query_embedding])\n",
    "tsne = TSNE(n_components=2, perplexity=3, random_state=42)\n",
    "reduced_vecs = tsne.fit_transform(combined_matrix)\n",
    "\n",
    "doc_coords = reduced_vecs[:-1]\n",
    "query_coord = reduced_vecs[-1]\n",
    "\n",
    "# Graficar\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "for i, title in enumerate(titles):\n",
    "    is_retrieved = title in retrieved_titles\n",
    "    color = '#2ecc71' if is_retrieved else '#95a5a6'\n",
    "    marker_size = 160 if is_retrieved else 100\n",
    "    edge_color = '#27ae60' if is_retrieved else '#7f8c8d'\n",
    "    zorder = 5 if is_retrieved else 3\n",
    "\n",
    "    ax.scatter(doc_coords[i, 0], doc_coords[i, 1],\n",
    "               c=color, s=marker_size, edgecolors=edge_color, linewidths=2, zorder=zorder)\n",
    "\n",
    "    # Línea de distancia desde la query al documento\n",
    "    line_style = '-' if is_retrieved else '--'\n",
    "    line_alpha = 0.8 if is_retrieved else 0.3\n",
    "    line_color = '#2ecc71' if is_retrieved else '#bdc3c7'\n",
    "    ax.plot([query_coord[0], doc_coords[i, 0]],\n",
    "            [query_coord[1], doc_coords[i, 1]],\n",
    "            line_style, color=line_color, alpha=line_alpha, linewidth=1.5, zorder=1)\n",
    "\n",
    "    # Texto de distancia coseno en el punto medio de la línea\n",
    "    mid_x = (query_coord[0] + doc_coords[i, 0]) / 2\n",
    "    mid_y = (query_coord[1] + doc_coords[i, 1]) / 2\n",
    "    dist_text = f\"{cosine_dists[i]:.3f}\"\n",
    "    bbox_color = '#d5f5e3' if is_retrieved else '#f2f3f4'\n",
    "    ax.text(mid_x, mid_y, dist_text, fontsize=8, ha='center', va='center',\n",
    "            bbox=dict(boxstyle='round,pad=0.2', facecolor=bbox_color, edgecolor='gray', alpha=0.9),\n",
    "            zorder=6)\n",
    "\n",
    "    # Etiqueta del título\n",
    "    label = f\"* {title}\" if is_retrieved else title\n",
    "    font_weight = 'bold' if is_retrieved else 'normal'\n",
    "    ax.text(doc_coords[i, 0] + 0.3, doc_coords[i, 1] + 0.3, label,\n",
    "            fontsize=9, fontweight=font_weight, zorder=7)\n",
    "\n",
    "# Query point\n",
    "ax.scatter(query_coord[0], query_coord[1], c='#e74c3c', s=250, marker='X',\n",
    "           edgecolors='#c0392b', linewidths=2, zorder=10, label='Tu Pregunta')\n",
    "\n",
    "ax.set_title(f\"Espacio Vectorial: Documentos más cercanos a la pregunta\\n\\\"{query[:60]}...\\\"\",\n",
    "             fontsize=12, fontweight='bold', pad=15)\n",
    "\n",
    "# Leyenda personalizada\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='X', color='w', markerfacecolor='#e74c3c',\n",
    "           markersize=14, markeredgecolor='#c0392b', label='Pregunta (query)'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#2ecc71',\n",
    "           markersize=10, markeredgecolor='#27ae60', label='Documentos recuperados (k=2)'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#95a5a6',\n",
    "           markersize=10, markeredgecolor='#7f8c8d', label='Documentos no recuperados'),\n",
    "    Line2D([0], [0], linestyle='-', color='#2ecc71', alpha=0.8, label='Distancia (recuperado)'),\n",
    "    Line2D([0], [0], linestyle='--', color='#bdc3c7', alpha=0.5, label='Distancia (no recuperado)'),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='lower right', fontsize=9, framealpha=0.9)\n",
    "ax.grid(True, alpha=0.2, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tabla resumen de distancias\n",
    "print(\"\\nDistancias coseno (menor = más similar):\")\n",
    "print(\"=\" * 55)\n",
    "sorted_indices = np.argsort(cosine_dists)\n",
    "for idx in sorted_indices:\n",
    "    retrieved_mark = \"<- recuperado\" if titles[idx] in retrieved_titles else \"\"\n",
    "    print(f\"  {cosine_dists[idx]:.4f}  |  {titles[idx]:45s} {retrieved_mark}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98vhfmqeum",
   "metadata": {},
   "source": [
    "---\n",
    "## Self-Attention: como un Transformer \"lee\" una frase\n",
    "\n",
    "Antes de que un texto se convierta en un embedding, el modelo Transformer lo procesa con un mecanismo llamado **self-attention**. Este mecanismo es la razon por la que los embeddings capturan significado semantico y no solo frecuencia de palabras (como TF-IDF).\n",
    "\n",
    "### Que hace self-attention?\n",
    "\n",
    "Cuando el modelo lee una frase, **cada palabra mira a todas las demas** para decidir cuales son relevantes para entender su significado en ese contexto:\n",
    "\n",
    "```\n",
    "\"Tenemos los ojos cansados de tanto ver\"\n",
    "\n",
    " ojos --atiende--> ver        (alta relevancia: los ojos son los que ven)\n",
    " ojos --atiende--> cansados   (alta relevancia: los ojos estan cansados)\n",
    " ojos --atiende--> Tenemos    (baja relevancia: palabra funcional)\n",
    "```\n",
    "\n",
    "### Por que importa para RAG?\n",
    "\n",
    "Self-attention es lo que permite que:\n",
    "- \"El felino descansa\" y \"El gato duerme\" tengan embeddings **cercanos** (el modelo entiende que son sinonimos en contexto)\n",
    "- La busqueda semantica funcione mas alla de coincidencia exacta de palabras\n",
    "- Los chunks recuperados sean **semanticamente** relevantes, no solo los que comparten keywords\n",
    "\n",
    "Sin self-attention, los embeddings serian como TF-IDF: bolsas de palabras sin comprension del significado.\n",
    "\n",
    "### Visualizacion con embeddings de OpenAI\n",
    "\n",
    "Vamos a simular self-attention usando embeddings de OpenAI: embebemos cada palabra individualmente y medimos la similitud coseno entre todas las palabras de la frase. Esto nos muestra que palabras \"se ven\" entre si semanticamente, que es exactamente lo que self-attention computa internamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oq1pue4nx6o",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T22:20:09.294836Z",
     "iopub.status.busy": "2026-02-17T22:20:09.294781Z",
     "iopub.status.idle": "2026-02-17T22:20:10.719692Z",
     "shell.execute_reply": "2026-02-17T22:20:10.719412Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cos_sim\n",
    "\n",
    "frase = \"Tenemos los ojos cansados de tanto ver, y los oidos de tanto oir, y el corazon de tanto odiar.\"\n",
    "\n",
    "# Separar en palabras significativas (sin puntuacion ni conectores)\n",
    "palabras = [\"Tenemos\", \"ojos\", \"cansados\", \"tanto\", \"ver\", \"oidos\", \"oir\", \"corazon\", \"odiar\"]\n",
    "\n",
    "# Obtener un embedding por cada palabra usando OpenAI\n",
    "resp = client.embeddings.create(input=palabras, model=\"text-embedding-3-small\")\n",
    "word_embeddings = np.array([e.embedding for e in resp.data])\n",
    "\n",
    "# Matriz de similitud coseno entre todas las palabras\n",
    "sim_matrix = cos_sim(word_embeddings)\n",
    "\n",
    "print(f'Frase: \"{frase}\"')\n",
    "print(f\"Palabras embebidas: {palabras}\")\n",
    "print(f\"Matriz de similitud: {sim_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xgjaw1s9q8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T22:20:10.720752Z",
     "iopub.status.busy": "2026-02-17T22:20:10.720697Z",
     "iopub.status.idle": "2026-02-17T22:20:10.801989Z",
     "shell.execute_reply": "2026-02-17T22:20:10.801712Z"
    }
   },
   "outputs": [],
   "source": [
    "# Heatmap de similitud semantica entre palabras (simula self-attention)\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Enmascarar la diagonal (similitud consigo mismo = 1.0, no es informativa)\n",
    "mask_diag = np.eye(len(palabras), dtype=bool)\n",
    "sim_display = sim_matrix.copy()\n",
    "np.fill_diagonal(sim_display, np.nan)\n",
    "\n",
    "sns.heatmap(\n",
    "    sim_display,\n",
    "    xticklabels=palabras,\n",
    "    yticklabels=palabras,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"YlOrRd\",\n",
    "    ax=ax,\n",
    "    linewidths=1,\n",
    "    linecolor=\"white\",\n",
    "    cbar_kws={\"label\": \"Similitud coseno\"},\n",
    "    mask=mask_diag,\n",
    "    vmin=0,\n",
    "    vmax=0.7,\n",
    ")\n",
    "\n",
    "ax.set_title(\n",
    "    'Similitud semantica entre palabras (OpenAI embeddings)\\n'\n",
    "    f'\"{frase}\"',\n",
    "    fontsize=12, fontweight=\"bold\", pad=15,\n",
    ")\n",
    "\n",
    "plt.xticks(fontsize=11, rotation=45, ha=\"right\")\n",
    "plt.yticks(fontsize=11, rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('La frase tiene estructura paralela: ojos/ver, oidos/oir, corazon/odiar.')\n",
    "print('El heatmap muestra que el modelo captura estas relaciones semanticas.')\n",
    "print('Las celdas mas oscuras indican palabras con mayor relacion.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuwktlmewbl",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T22:20:10.803034Z",
     "iopub.status.busy": "2026-02-17T22:20:10.802988Z",
     "iopub.status.idle": "2026-02-17T22:20:10.850203Z",
     "shell.execute_reply": "2026-02-17T22:20:10.849928Z"
    }
   },
   "outputs": [],
   "source": [
    "# Relevance score global: cuanta similitud acumula cada palabra con TODAS las demas?\n",
    "# Esto simula self-attention: las palabras que mas \"conectan\" con el resto de la frase\n",
    "# son las mas importantes para entender el significado completo.\n",
    "\n",
    "# Sumar similitud con todas las demas palabras (excluyendo consigo misma)\n",
    "relevance = np.zeros(len(palabras))\n",
    "for i in range(len(palabras)):\n",
    "    relevance[i] = sum(sim_matrix[i, j] for j in range(len(palabras)) if j != i)\n",
    "\n",
    "# Normalizar a [0, 1]\n",
    "relevance = relevance / relevance.max()\n",
    "\n",
    "# Ordenar de mayor a menor\n",
    "orden = np.argsort(relevance)[::-1]\n",
    "palabras_ord = [palabras[i] for i in orden]\n",
    "relevance_ord = [relevance[i] for i in orden]\n",
    "\n",
    "# Colores: la mas importante en rojo fuerte, el resto degradado\n",
    "colores = []\n",
    "for i, val in enumerate(relevance_ord):\n",
    "    if i == 0:\n",
    "        colores.append(\"#e74c3c\")\n",
    "    else:\n",
    "        colores.append(plt.cm.YlOrRd(val * 0.7 + 0.15))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "bars = ax.barh(range(len(palabras_ord)), relevance_ord,\n",
    "               color=colores, edgecolor=\"black\", linewidth=0.5, height=0.7)\n",
    "\n",
    "ax.set_yticks(range(len(palabras_ord)))\n",
    "ax.set_yticklabels(palabras_ord, fontsize=13, fontweight=\"bold\")\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"Relevance Score (similitud acumulada, normalizada)\", fontsize=11)\n",
    "ax.set_title(\n",
    "    'Self-Attention: cual es la palabra mas importante de la frase?\\n'\n",
    "    f'\"{frase}\"',\n",
    "    fontsize=13, fontweight=\"bold\", pad=12,\n",
    ")\n",
    "ax.set_xlim(0, 1.18)\n",
    "ax.grid(True, axis=\"x\", alpha=0.2, linestyle=\"--\")\n",
    "\n",
    "# Anotar valores\n",
    "for i, val in enumerate(relevance_ord):\n",
    "    label = f\"  {val:.3f}\"\n",
    "    if i == 0:\n",
    "        label += \"  <-- mas importante\"\n",
    "    ax.text(val + 0.01, i, label, va=\"center\", fontsize=11,\n",
    "            fontweight=\"bold\" if i == 0 else \"normal\",\n",
    "            color=\"#e74c3c\" if i == 0 else \"#333333\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'La palabra mas importante segun self-attention es: \"{palabras_ord[0]}\"')\n",
    "print(f\"Esto tiene sentido: \\\"{palabras_ord[0]}\\\" es el nucleo emocional de la frase.\")\n",
    "print(f\"Las palabras funcionales como \\\"Tenemos\\\" y \\\"tanto\\\" tienen menor relevancia.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc42bq25u5i",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T22:20:10.851315Z",
     "iopub.status.busy": "2026-02-17T22:20:10.851265Z",
     "iopub.status.idle": "2026-02-17T22:20:10.951293Z",
     "shell.execute_reply": "2026-02-17T22:20:10.950959Z"
    }
   },
   "outputs": [],
   "source": [
    "# Todas las combinaciones de pares de palabras con su similitud coseno.\n",
    "# El par con mayor score revela la conexion semantica mas fuerte de la frase.\n",
    "from itertools import combinations\n",
    "\n",
    "pares = []\n",
    "for i, j in combinations(range(len(palabras)), 2):\n",
    "    pares.append((palabras[i], palabras[j], sim_matrix[i, j]))\n",
    "\n",
    "# Ordenar de mayor a menor similitud\n",
    "pares.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# Preparar datos para el grafico\n",
    "labels = [f\"{a}  -  {b}\" for a, b, _ in pares]\n",
    "scores = [s for _, _, s in pares]\n",
    "max_score = scores[0]\n",
    "\n",
    "# Color: el par top en rojo, top 3 en naranja, el resto en gris\n",
    "bar_colors = []\n",
    "for i, s in enumerate(scores):\n",
    "    if i == 0:\n",
    "        bar_colors.append(\"#e74c3c\")\n",
    "    elif i < 3:\n",
    "        bar_colors.append(\"#f39c12\")\n",
    "    else:\n",
    "        bar_colors.append(\"#bdc3c7\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "ax.barh(range(len(pares)), scores,\n",
    "        color=bar_colors, edgecolor=\"black\", linewidth=0.4, height=0.75)\n",
    "\n",
    "ax.set_yticks(range(len(pares)))\n",
    "ax.set_yticklabels(labels, fontsize=11)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"Similitud coseno\", fontsize=11)\n",
    "ax.set_xlim(0, max_score * 1.3)\n",
    "ax.set_title(\n",
    "    'Todas las combinaciones de palabras ordenadas por similitud\\n'\n",
    "    f'\"{frase}\"',\n",
    "    fontsize=13, fontweight=\"bold\", pad=12,\n",
    ")\n",
    "ax.grid(True, axis=\"x\", alpha=0.2, linestyle=\"--\")\n",
    "\n",
    "# Anotar valores\n",
    "for i, (a, b, s) in enumerate(pares):\n",
    "    extra = \"  <-- conexion mas fuerte\" if i == 0 else \"\"\n",
    "    ax.text(s + 0.003, i, f\"{s:.3f}{extra}\", va=\"center\", fontsize=10,\n",
    "            fontweight=\"bold\" if i == 0 else \"normal\",\n",
    "            color=\"#e74c3c\" if i == 0 else \"#555555\")\n",
    "\n",
    "# Leyenda\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor=\"#e74c3c\", edgecolor=\"black\", label=\"Par mas fuerte\"),\n",
    "    Patch(facecolor=\"#f39c12\", edgecolor=\"black\", label=\"Top 3\"),\n",
    "    Patch(facecolor=\"#bdc3c7\", edgecolor=\"black\", label=\"Resto\"),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc=\"lower right\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Resumen\n",
    "print(\"Top 5 conexiones semanticas mas fuertes:\")\n",
    "print(\"=\" * 60)\n",
    "for a, b, s in pares[:5]:\n",
    "    print(f'  {s:.3f}  \"{a}\" <-> \"{b}\"')\n",
    "\n",
    "# Contar en cuantos pares top-5 aparece cada palabra\n",
    "from collections import Counter\n",
    "top_words = Counter()\n",
    "for a, b, _ in pares[:5]:\n",
    "    top_words[a] += 1\n",
    "    top_words[b] += 1\n",
    "winner = top_words.most_common(1)[0]\n",
    "print(f'\\nPalabra que domina las conexiones mas fuertes: \"{winner[0]}\" (aparece en {winner[1]} de los top 5 pares)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ets9tm36il",
   "metadata": {},
   "source": [
    "### Multi-Head Attention: multiples perspectivas simultaneas\n",
    "\n",
    "En un Transformer real, self-attention no se computa una sola vez. Se ejecuta en **multiples cabezas (heads) en paralelo**, cada una aprendiendo a enfocarse en un tipo diferente de relacion:\n",
    "\n",
    "```\n",
    "                        Frase de entrada\n",
    "                              |\n",
    "              +---------------+---------------+\n",
    "              |               |               |\n",
    "          Head 1          Head 2          Head 3\n",
    "       \"Cuerpo\"        \"Accion\"       \"Sentimiento\"\n",
    "    ojos <-> oidos    ver <-> oir    cansados <-> odiar\n",
    "              |               |               |\n",
    "              +---------------+---------------+\n",
    "                              |\n",
    "                     Concatenar + combinar\n",
    "                              |\n",
    "                        Embedding final\n",
    "```\n",
    "\n",
    "Cada head ve la misma frase pero atiende a relaciones distintas. Luego el modelo combina todas las perspectivas en un solo vector.\n",
    "\n",
    "Simulemos esto embebiendo cada palabra **en diferentes contextos semanticos** con OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g1gxo7fkrip",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T22:20:10.952284Z",
     "iopub.status.busy": "2026-02-17T22:20:10.952235Z",
     "iopub.status.idle": "2026-02-17T22:20:12.732246Z",
     "shell.execute_reply": "2026-02-17T22:20:12.731391Z"
    }
   },
   "outputs": [],
   "source": [
    "# Simulacion de Multi-Head Attention con OpenAI embeddings.\n",
    "# Cada \"head\" embebe las palabras en un contexto semantico diferente,\n",
    "# lo que cambia las relaciones de similitud entre ellas.\n",
    "\n",
    "heads = {\n",
    "    \"Head 1: Cuerpo\": \"parte del cuerpo humano: {}\",\n",
    "    \"Head 2: Accion\": \"accion o verbo que se realiza: {}\",\n",
    "    \"Head 3: Sentimiento\": \"sentimiento o estado emocional: {}\",\n",
    "}\n",
    "\n",
    "# Embeber cada palabra en cada contexto\n",
    "head_matrices = {}\n",
    "for head_name, template in heads.items():\n",
    "    contextualized = [template.format(p) for p in palabras]\n",
    "    resp_head = client.embeddings.create(input=contextualized, model=\"text-embedding-3-small\")\n",
    "    embs = np.array([e.embedding for e in resp_head.data])\n",
    "    head_matrices[head_name] = cos_sim(embs)\n",
    "\n",
    "# Visualizar las 3 matrices lado a lado\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "head_colors = [\"Blues\", \"Greens\", \"Reds\"]\n",
    "for ax, (head_name, matrix), cmap in zip(axes, head_matrices.items(), head_colors):\n",
    "    mask_diag = np.eye(len(palabras), dtype=bool)\n",
    "    display = matrix.copy()\n",
    "    np.fill_diagonal(display, np.nan)\n",
    "\n",
    "    sns.heatmap(\n",
    "        display,\n",
    "        xticklabels=palabras,\n",
    "        yticklabels=palabras,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        cmap=cmap,\n",
    "        ax=ax,\n",
    "        linewidths=0.5,\n",
    "        linecolor=\"white\",\n",
    "        mask=mask_diag,\n",
    "        vmin=0.1,\n",
    "        vmax=0.7,\n",
    "        cbar=False,\n",
    "    )\n",
    "    ax.set_title(head_name, fontsize=12, fontweight=\"bold\")\n",
    "    plt.sca(ax)\n",
    "    plt.xticks(fontsize=8, rotation=45, ha=\"right\")\n",
    "    plt.yticks(fontsize=8, rotation=0)\n",
    "\n",
    "fig.suptitle(\n",
    "    'Multi-Head Attention: la misma frase vista desde 3 perspectivas\\n'\n",
    "    f'\"{frase}\"',\n",
    "    fontsize=14, fontweight=\"bold\", y=1.04,\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar el par mas fuerte en cada head\n",
    "print(\"Par mas fuerte por cada head:\")\n",
    "print(\"=\" * 60)\n",
    "for head_name, matrix in head_matrices.items():\n",
    "    best_score = 0\n",
    "    best_pair = (\"\", \"\")\n",
    "    for i in range(len(palabras)):\n",
    "        for j in range(i + 1, len(palabras)):\n",
    "            if matrix[i, j] > best_score:\n",
    "                best_score = matrix[i, j]\n",
    "                best_pair = (palabras[i], palabras[j])\n",
    "    print(f'  {head_name}:  \"{best_pair[0]}\" <-> \"{best_pair[1]}\"  (sim: {best_score:.3f})')\n",
    "\n",
    "print(\"\\nCada head se especializa en un tipo de relacion diferente.\")\n",
    "print(\"El Transformer combina todas las perspectivas para generar el embedding final.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vector-data-bases",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
