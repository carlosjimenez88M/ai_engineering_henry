{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51b10326",
   "metadata": {},
   "source": [
    "# Modulo 2 (Extension): Diseno de Base de Datos Vectorial con Batman\n",
    "\n",
    "## Objetivo\n",
    "Construir una base vectorial desde cero, justificando decisiones de diseno como lo hariamos en un curso de AI Engineering aplicado.\n",
    "\n",
    "## Resultado esperado\n",
    "- Dataset estructurado y chunking reproducible.\n",
    "- Indexacion vectorial en ChromaDB.\n",
    "- Recuperacion semantica con metadata util para filtros y trazabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc87ff8",
   "metadata": {},
   "source": [
    "## Blueprint de diseno (resumen ejecutivo)\n",
    "\n",
    "1. **Modelado de documentos**: cada comic se conserva con `id`, `personaje`, `arco`, `tema`, `titulo`, `contenido`.\n",
    "2. **Chunking**: tamano intermedio (800 chars) con overlap (120) para balancear contexto vs precision.\n",
    "3. **Embeddings**: `text-embedding-3-small` para costo/calidad en produccion educativa.\n",
    "4. **Indice**: ChromaDB persistente para consultas, inspeccion y evaluacion reproducible.\n",
    "5. **Observabilidad**: estadisticas de chunks + inspeccion de retrieval para detectar drift semantico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bwngdxewn8j",
   "source": "## Justificacion teorica de las decisiones de diseno\n\n### Chunk size = 800 caracteres\n\nEl tamano de chunk es una de las decisiones mas impactantes en el diseno de una base vectorial. Consideremos los trade-offs:\n\n| Chunk size | Ventaja | Desventaja |\n|---|---|---|\n| **Pequeno** (200-400 chars) | Alta precision: cada chunk es semanticamente coherente | Pierde contexto narrativo; requiere mas chunks para cubrir una idea completa |\n| **Medio** (600-1000 chars) | Buen balance: contexto suficiente para respuestas coherentes | Puede mezclar ideas en fronteras de parrafo |\n| **Grande** (1500+ chars) | Contexto rico para respuestas complejas | Dilution semantica: el embedding promedia temas heterogeneos, reduce recall |\n\nElegimos **800 chars** (~160 tokens) porque:\n1. Es significativamente menor que el limite del modelo de embedding (`text-embedding-3-small` soporta hasta 8191 tokens ≈ 5000+ chars), lo cual evita truncamiento.\n2. Para textos narrativos como comics, 800 chars captura entre 1-2 parrafos completos — suficiente para que el LLM construya una respuesta coherente sin necesitar multiples chunks del mismo pasaje.\n3. Empiricamente, chunks de este tamano producen un buen ratio precision/recall en retrieval: lo suficientemente especificos para matchear consultas focalizadas, pero con contexto suficiente para no ser fragmentos incoherentes.\n\n### Chunk overlap = 120 caracteres (15% del chunk_size)\n\nEl overlap controla cuanto contenido se repite entre chunks consecutivos. Su funcion es **preservar continuidad semantica** en las fronteras de fragmentacion:\n\n- **Overlap = 0**: riesgo de cortar una idea a la mitad sin que ninguno de los dos chunks la represente completa. Una consulta sobre esa idea no matchearia con ningun chunk.\n- **Overlap demasiado alto (>30%)**: genera duplicacion significativa que infla el indice sin beneficio proporcional, aumenta costos de embedding, y puede sesgar el retrieval hacia contenido repetido.\n- **15% (~120 chars)**: preserva ~1-2 oraciones de contexto entre chunks. Suficiente para que ideas en fronteras de parrafo aparezcan en al menos un chunk con contexto adecuado.\n\n### Modelo de embedding: `text-embedding-3-small`\n\nOpenAI ofrece dos variantes de `text-embedding-3`:\n- `text-embedding-3-small`: 1536 dimensiones, ~5x mas barato que large.\n- `text-embedding-3-large`: 3072 dimensiones, mayor capacidad discriminativa.\n\nPara textos narrativos como los de este laboratorio, `small` ofrece calidad de retrieval comparable a `large` a una fraccion del costo. La diferencia se nota mas en dominios altamente tecnicos con vocabulario especializado. En un contexto educativo y de prototipado, `small` es la eleccion correcta.\n\n### Cosine similarity y HNSW en ChromaDB\n\nChromaDB usa por defecto **cosine similarity** como metrica de distancia en su indice HNSW (Hierarchical Navigable Small World). Implicaciones:\n- Los vectores se comparan por **direccion**, no por magnitud. Dos textos sobre el mismo tema tendran vectores con angulo pequeno (alta similaridad) sin importar su longitud.\n- HNSW es un grafo de proximidad que permite busqueda aproximada en O(log n), haciendo viable el retrieval en tiempo real incluso con miles de chunks.\n- La distancia coseno retornada por ChromaDB esta en rango [0, 2], donde 0 = identico y 2 = opuesto. Valores tipicos para chunks relevantes: 0.2–0.6.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d396d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "from scripts.common import load_comic_records, embed_documents\n",
    "from scripts.vector_store_lab import build_index_from_json\n",
    "\n",
    "DATA_PATH = ROOT / 'data' / 'batman_comics.json'\n",
    "PERSIST_DIR = ROOT / 'outputs' / 'chroma_batman_design'\n",
    "PERSIST_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUTS_DIR = ROOT / 'outputs'\n",
    "OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f'Notebook root: {ROOT}')\n",
    "print(f'Data path: {DATA_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deaa5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = load_comic_records(DATA_PATH)\n",
    "records_df = pd.DataFrame(records)\n",
    "print(f'Total records: {len(records_df)}')\n",
    "records_df[['id', 'personaje', 'arco', 'tema']].head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cdfee7",
   "metadata": {},
   "source": [
    "## Discusion tecnica: decisiones de arquitectura\n",
    "\n",
    "| Componente | Decision | Justificacion aplicada |\n",
    "|---|---|---|\n",
    "| Unidad de indexacion | Chunk por fragmento narrativo | Reduce dilution semantica en documentos largos |\n",
    "| Metadata minima | `personaje`, `arco`, `tema`, `titulo`, `source_id`, `chunk_index` | Permite filtros, auditoria y debugging de retrieval |\n",
    "| Store | ChromaDB persistente | Simplicidad operativa para laboratorio y prototipos |\n",
    "| Embeddings | `text-embedding-3-small` | Buen trade-off costo/recall para contenido textual denso |\n",
    "| Eval inicial | Muestra de queries + distancias | Detecta huecos de cobertura antes del tuning fino |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e8d8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "db, chunks, index_stats, chunk_stats = build_index_from_json(\n",
    "    json_path=DATA_PATH,\n",
    "    persist_dir=PERSIST_DIR,\n",
    "    collection_name='batman_design_lab',\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=120,\n",
    "    embedding_model='text-embedding-3-small',\n",
    ")\n",
    "\n",
    "print('Index stats:')\n",
    "print(index_stats)\n",
    "print('\\nChunk stats:')\n",
    "print(chunk_stats)\n",
    "\n",
    "chunks_df = pd.DataFrame([\n",
    "    {\n",
    "        'id': chunk['id'],\n",
    "        'chars': len(chunk['text']),\n",
    "        'tema': chunk['metadata']['tema'],\n",
    "        'arco': chunk['metadata']['arco'],\n",
    "    }\n",
    "    for chunk in chunks\n",
    "])\n",
    "chunks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaf22b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_queries = [\n",
    "    'Como inicia Batman su carrera en Gotham?',\n",
    "    'Que estrategia usa Bane para derrotar a Batman en Knightfall?',\n",
    "    'Que rol cumple Batman dentro de la Liga de la Justicia?',\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for query in sample_queries:\n",
    "    results, provider = db.query(query_text=query, n_results=3, embedding_model='text-embedding-3-small')\n",
    "    for item in results:\n",
    "        rows.append({\n",
    "            'query': query,\n",
    "            'rank': item['rank'],\n",
    "            'distance': round(item['distance'], 4),\n",
    "            'tema': item['metadata'].get('tema'),\n",
    "            'arco': item['metadata'].get('arco'),\n",
    "            'snippet': item['text'][:160] + '...',\n",
    "            'retrieval_provider': provider,\n",
    "        })\n",
    "\n",
    "retrieval_df = pd.DataFrame(rows)\n",
    "retrieval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222724ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts = [chunk['text'] for chunk in chunks[:60]]\n",
    "sample_meta = [chunk['metadata'] for chunk in chunks[:60]]\n",
    "vectors, embedding_provider = embed_documents(sample_texts, model='text-embedding-3-small')\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "projection = pca.fit_transform(vectors)\n",
    "\n",
    "proj_df = pd.DataFrame({\n",
    "    'x': projection[:, 0],\n",
    "    'y': projection[:, 1],\n",
    "    'tema': [meta['tema'] for meta in sample_meta],\n",
    "})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "for tema, subset in proj_df.groupby('tema'):\n",
    "    ax.scatter(subset['x'], subset['y'], label=tema, alpha=0.75)\n",
    "\n",
    "ax.set_title(f'Proyeccion de embeddings (provider={embedding_provider})')\n",
    "ax.set_xlabel('PCA-1')\n",
    "ax.set_ylabel('PCA-2')\n",
    "ax.grid(alpha=0.3)\n",
    "ax.legend(loc='best', fontsize=8)\n",
    "\n",
    "plot_path = OUTPUTS_DIR / 'vector_db_design_projection.png'\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_path, dpi=150)\n",
    "plt.close(fig)\n",
    "\n",
    "print(f'Saved: {plot_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e828987b",
   "metadata": {},
   "source": "## Cierre didactico\n\n### Conceptos clave de esta notebook\n\n- **Chunking no es trivial**: el tamano y overlap de fragmentos afectan directamente la calidad del retrieval. No hay valores universales — dependen del dominio, la longitud de los documentos y el tipo de consultas esperadas. Los valores elegidos (800/120) son un punto de partida razonable que debe validarse empiricamente.\n- **Metadata es infraestructura de observabilidad**: campos como `personaje`, `arco`, `tema` y `source_id` no son decorativos — permiten filtrar, auditar y debuggear el comportamiento del retrieval en produccion.\n- **El embedding model importa menos de lo que se piensa** (dentro de la misma generacion): para la mayoria de casos de uso con texto en espanol/ingles, `text-embedding-3-small` produce resultados comparables a `large` a una fraccion del costo.\n- **La visualizacion PCA de embeddings** es una herramienta de diagnostico, no de evaluacion. Si los clusters tematicos son visibles en 2D, el modelo de embedding esta capturando estructura semantica util. Si no, puede indicar que los chunks son demasiado homogeneos o el chunking es demasiado agresivo.\n\n### Conexion con la siguiente notebook\n\nCon la base vectorial operativa y auditada, en la siguiente notebook la usamos para comparar **Vanilla RAG** vs **Agentic RAG** con metricas cuantitativas (groundedness, latencia) y graficas comparativas. La pregunta central sera: *cuando justifica la complejidad adicional de un pipeline agentico?*"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}