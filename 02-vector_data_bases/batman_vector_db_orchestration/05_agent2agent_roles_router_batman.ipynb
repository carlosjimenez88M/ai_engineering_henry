{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab20b4dd",
   "metadata": {},
   "source": [
    "![Henry Logo](https://www.soyhenry.com/_next/static/media/HenryLogo.bb57fd6f.svg)\n",
    "\n",
    "# Agent2Agent Especializado con Router Interno (Batman)\n",
    "\n",
    "## Objetivo\n",
    "Extender el ejercicio agent2agent con una arquitectura de roles especializados:\n",
    "- **RouterAgent**: clasifica la consulta en una ruta semantica.\n",
    "- **SpecialistAgent** (timeline, villains, strategy, general): recupera evidencia y responde.\n",
    "\n",
    "Si la primera respuesta sale con grounding bajo, el orquestador pide una segunda opinion al agente `general`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e8dcf",
   "metadata": {},
   "source": [
    "## Flujo\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "  A[\"User Query\"] --> B[\"RouterAgent\"]\n",
    "  B --> C[\"SpecialistAgent (ruta seleccionada)\"]\n",
    "  C --> D[\"Grounding Check\"]\n",
    "  D -->|\"bajo\"| E[\"General Specialist (segunda opinion)\"]\n",
    "  D -->|\"ok\"| F[\"Final Answer\"]\n",
    "  E --> F\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bpaf7e25oyd",
   "metadata": {},
   "source": [
    "## Marco teorico: Especializacion por roles\n",
    "\n",
    "### Por que especializar agentes\n",
    "\n",
    "Cada `SpecialistAgent` en esta arquitectura tiene un **system prompt optimizado para su dominio**:\n",
    "- `TimelineAgent`: prioriza orden temporal y transiciones narrativas.\n",
    "- `VillainsAgent`: prioriza motivaciones, metodos y conflicto heroe-villano.\n",
    "- `StrategyAgent`: prioriza decisiones tacticas y trade-offs operativos.\n",
    "- `GeneralAgent`: prioriza una explicacion balanceada de hechos canonicos.\n",
    "\n",
    "La especializacion tiene un beneficio fundamental: **un LLM con un system prompt focalizado produce respuestas mas coherentes y relevantes que uno con un prompt generico**. Esto es analogo al principio de \"single responsibility\" en ingenieria de software — cada agente hace una cosa bien.\n",
    "\n",
    "Ademas, el `RouterAgent` en esta arquitectura **no es un LLM** — es un router heuristico basado en keywords. Esto tiene dos ventajas operativas:\n",
    "1. **Latencia reducida**: el routing es O(n) con n = numero de keywords, negligible comparado con un forward pass de LLM.\n",
    "2. **Costo cero de API**: no consume tokens de la API para decidir la ruta.\n",
    "\n",
    "### El patron de \"segunda opinion\"\n",
    "\n",
    "Cuando el agente primario produce una respuesta con grounding bajo (`< 0.2`), el orquestador consulta al agente `general` como fallback. Este patron tiene analogias en multiple dominios:\n",
    "\n",
    "- **Mixture of Experts (MoE)**: en redes neuronales, diferentes \"expertos\" se especializan en subconjuntos de datos, con un gating network que decide cual activar. Aqui el router es el gate y los specialists son los expertos.\n",
    "- **Sistemas de segunda opinion medica**: cuando el diagnostico del especialista es incierto, se consulta a un generalista para validar o complementar.\n",
    "- **Escalamiento en soporte tecnico**: si el agente de nivel 2 no resuelve, se escala al nivel 3 (mas general pero con mas contexto).\n",
    "\n",
    "### Threshold 0.2 vs 0.18\n",
    "\n",
    "En la notebook anterior (Agent2Agent simple), el threshold de grounding era **0.18**. Aqui usamos **0.2**. La razon:\n",
    "- Los agentes especializados deberian producir respuestas de **mayor calidad** dentro de su dominio, porque su system prompt esta optimizado para esa tarea.\n",
    "- Si un agente especializado no alcanza 0.2 de grounding, es una senal mas fuerte de que algo salio mal (query fuera de dominio, documentos insuficientes, etc.).\n",
    "- Un threshold ligeramente mas alto para agentes especializados actua como un **quality gate mas estricto**, lo cual es deseable cuando tienes un fallback disponible (el agente general)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8b66232",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T22:18:15.936942Z",
     "iopub.status.busy": "2026-02-19T22:18:15.936645Z",
     "iopub.status.idle": "2026-02-19T22:18:19.870016Z",
     "shell.execute_reply": "2026-02-19T22:18:19.869632Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlosdaniel/Documents/Projects/labor_projects/Henry/2026/01-introduction_ai_engineering/ai_engineering_henry/02-vector_data_bases/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "from scripts.common import generate_answer\n",
    "from scripts.evaluation import groundedness_score\n",
    "from scripts.vector_store_lab import build_index_from_json\n",
    "\n",
    "OUTPUTS_DIR = ROOT / 'outputs'\n",
    "OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DATA_PATH = ROOT / 'data' / 'batman_comics.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aed6e8df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T22:18:19.871771Z",
     "iopub.status.busy": "2026-02-19T22:18:19.871628Z",
     "iopub.status.idle": "2026-02-19T22:18:19.953253Z",
     "shell.execute_reply": "2026-02-19T22:18:19.952950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index stats: {'collection': 'agent2agent_specialized_batman', 'indexed_chunks': 38, 'embedding_provider': 'local:hash-embedding'}\n",
      "Chunk stats: {'chunk_count': 38, 'unique_sources': 12, 'avg_chars_per_chunk': 682.5, 'max_chars_per_chunk': 792, 'themes_distribution': {'origen': 3, 'villanos': 3, 'legado': 3, 'conspiracion': 3, 'derrota': 3, 'misterio': 3, 'relaciones': 3, 'equipo': 3, 'escenario': 3, 'mentoria': 4, 'recursos': 4, 'filosofia': 3}, 'hero_distribution': {'batman': 38}}\n"
     ]
    }
   ],
   "source": [
    "db, chunks, index_stats, chunk_stats = build_index_from_json(\n",
    "    json_path=DATA_PATH,\n",
    "    persist_dir=OUTPUTS_DIR / 'chroma_agent2agent_specialized',\n",
    "    collection_name='agent2agent_specialized_batman',\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=120,\n",
    "    embedding_model='text-embedding-3-small',\n",
    ")\n",
    "\n",
    "print('Index stats:', index_stats)\n",
    "print('Chunk stats:', chunk_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eea89af9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T22:18:19.954310Z",
     "iopub.status.busy": "2026-02-19T22:18:19.954248Z",
     "iopub.status.idle": "2026-02-19T22:18:19.956104Z",
     "shell.execute_reply": "2026-02-19T22:18:19.955815Z"
    }
   },
   "outputs": [],
   "source": [
    "ROUTE_CONFIG = {\n",
    "    'timeline': {\n",
    "        'focus_hint': 'Prioriza orden temporal, etapas y transiciones narrativas.',\n",
    "        'system_prompt': (\n",
    "            'Eres TimelineAgent. Responde como historiador tecnico del canon de Batman. '\n",
    "            'Usa evidencia concreta y citas [D#].'\n",
    "        ),\n",
    "    },\n",
    "    'villains': {\n",
    "        'focus_hint': 'Prioriza motivaciones, metodos y dano psicologico de antagonistas.',\n",
    "        'system_prompt': (\n",
    "            'Eres VillainsAgent. Analiza conflicto heroe-villano, patrones de amenaza y riesgos. '\n",
    "            'Usa solo el contexto y cita [D#].'\n",
    "        ),\n",
    "    },\n",
    "    'strategy': {\n",
    "        'focus_hint': 'Prioriza tacticas, contingencias, trade-offs y decisiones operativas.',\n",
    "        'system_prompt': (\n",
    "            'Eres StrategyAgent. Explica decisiones estrategicas de Batman con precision operativa. '\n",
    "            'Usa evidencia y cita [D#].'\n",
    "        ),\n",
    "    },\n",
    "    'general': {\n",
    "        'focus_hint': 'Prioriza una explicacion balanceada de hechos canonicos verificables.',\n",
    "        'system_prompt': (\n",
    "            'Eres GeneralAgent. Sintetiza de forma rigurosa y didactica sin inventar datos. '\n",
    "            'Usa contexto y cita [D#].'\n",
    "        ),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0e999b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T22:18:19.956885Z",
     "iopub.status.busy": "2026-02-19T22:18:19.956838Z",
     "iopub.status.idle": "2026-02-19T22:18:19.961151Z",
     "shell.execute_reply": "2026-02-19T22:18:19.960894Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RouterAgent:\n",
    "    def route(self, query: str) -> str:\n",
    "        q = query.lower()\n",
    "        if any(term in q for term in ['orden', 'cronologia', 'timeline', 'inicio', 'evolucion', 'despues']):\n",
    "            return 'timeline'\n",
    "        if any(term in q for term in ['joker', 'bane', 'hush', 'villano', 'enemigo', 'tribunal', 'owls']):\n",
    "            return 'villains'\n",
    "        if any(term in q for term in ['estrategia', 'tactica', 'plan', 'contingencia', 'liga', 'justicia']):\n",
    "            return 'strategy'\n",
    "        return 'general'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SpecialistAgent:\n",
    "    route: str\n",
    "    vector_db: object\n",
    "    model: str = 'gpt-5-mini'\n",
    "    embedding_model: str = 'text-embedding-3-small'\n",
    "    k: int = 6\n",
    "\n",
    "    def run(self, query: str) -> dict:\n",
    "        cfg = ROUTE_CONFIG[self.route]\n",
    "        rewritten_query = f\"{query} {cfg['focus_hint']}\"\n",
    "        docs, retrieval_provider = self.vector_db.query(\n",
    "            query_text=rewritten_query,\n",
    "            n_results=self.k,\n",
    "            embedding_model=self.embedding_model,\n",
    "        )\n",
    "        answer, llm_provider = generate_answer(\n",
    "            query=query,\n",
    "            contexts=[str(doc.get('text', '')) for doc in docs],\n",
    "            model=self.model,\n",
    "            system_prompt=cfg['system_prompt'],\n",
    "        )\n",
    "        grounding = groundedness_score(answer, [doc.get('text', '') for doc in docs])\n",
    "        return {\n",
    "            'route': self.route,\n",
    "            'answer': answer,\n",
    "            'groundedness': grounding,\n",
    "            'retrieved_docs': len(docs),\n",
    "            'llm_provider': llm_provider,\n",
    "            'retrieval_provider': retrieval_provider,\n",
    "            'rewritten_query': rewritten_query,\n",
    "        }\n",
    "\n",
    "\n",
    "class SpecializedAgent2AgentOrchestrator:\n",
    "    def __init__(self, router: RouterAgent, specialists: dict[str, SpecialistAgent], threshold: float = 0.2) -> None:\n",
    "        self.router = router\n",
    "        self.specialists = specialists\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def run(self, query: str) -> dict:\n",
    "        t0 = time.perf_counter()\n",
    "        trace = []\n",
    "\n",
    "        route = self.router.route(query)\n",
    "        trace.append({'agent': 'RouterAgent', 'message': f'Ruta seleccionada: {route}'})\n",
    "\n",
    "        primary = self.specialists[route].run(query)\n",
    "        trace.append({\n",
    "            'agent': f'SpecialistAgent[{route}]',\n",
    "            'message': f\"Grounding={primary['groundedness']}, docs={primary['retrieved_docs']}\",\n",
    "        })\n",
    "\n",
    "        selected = primary\n",
    "        second_opinion_used = False\n",
    "        if primary['groundedness'] < self.threshold and route != 'general':\n",
    "            backup = self.specialists['general'].run(query)\n",
    "            trace.append({\n",
    "                'agent': 'SpecialistAgent[general]',\n",
    "                'message': f\"Second opinion grounding={backup['groundedness']}\",\n",
    "            })\n",
    "            if backup['groundedness'] >= primary['groundedness']:\n",
    "                selected = backup\n",
    "                second_opinion_used = True\n",
    "\n",
    "        latency = round(time.perf_counter() - t0, 4)\n",
    "        return {\n",
    "            'query': query,\n",
    "            'selected_route': route,\n",
    "            'final_answer': selected['answer'],\n",
    "            'final_groundedness': selected['groundedness'],\n",
    "            'retrieved_docs': selected['retrieved_docs'],\n",
    "            'llm_provider': selected['llm_provider'],\n",
    "            'retrieval_provider': selected['retrieval_provider'],\n",
    "            'second_opinion_used': second_opinion_used,\n",
    "            'latency_seconds': latency,\n",
    "            'trace': trace,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9641c7df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T22:18:19.962156Z",
     "iopub.status.busy": "2026-02-19T22:18:19.962115Z",
     "iopub.status.idle": "2026-02-19T22:18:19.963715Z",
     "shell.execute_reply": "2026-02-19T22:18:19.963471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specialized agent2agent orchestrator ready.\n"
     ]
    }
   ],
   "source": [
    "router_agent = RouterAgent()\n",
    "specialists = {\n",
    "    route: SpecialistAgent(route=route, vector_db=db, model='gpt-5-mini', embedding_model='text-embedding-3-small', k=6)\n",
    "    for route in ROUTE_CONFIG\n",
    "}\n",
    "orchestrator = SpecializedAgent2AgentOrchestrator(router=router_agent, specialists=specialists, threshold=0.2)\n",
    "print('Specialized agent2agent orchestrator ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "305ae7d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T22:18:19.964479Z",
     "iopub.status.busy": "2026-02-19T22:18:19.964425Z",
     "iopub.status.idle": "2026-02-19T22:18:19.972139Z",
     "shell.execute_reply": "2026-02-19T22:18:19.971797Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RouterAgent</td>\n",
       "      <td>Ruta seleccionada: timeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SpecialistAgent[timeline]</td>\n",
       "      <td>Grounding=0.9146, docs=6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       agent                      message\n",
       "0                RouterAgent  Ruta seleccionada: timeline\n",
       "1  SpecialistAgent[timeline]     Grounding=0.9146, docs=6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_query = 'Compara la evolucion tactica de Batman desde Year One hasta su enfrentamiento con Bane.'\n",
    "test_result = orchestrator.run(test_query)\n",
    "pd.DataFrame(test_result['trace'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09f115ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T22:18:19.973006Z",
     "iopub.status.busy": "2026-02-19T22:18:19.972961Z",
     "iopub.status.idle": "2026-02-19T22:18:19.974615Z",
     "shell.execute_reply": "2026-02-19T22:18:19.974320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      "Compara la evolucion tactica de Batman desde Year One hasta su enfrentamiento con Bane.\n",
      "\n",
      "Selected route: timeline\n",
      "Second opinion used: False\n",
      "Groundedness: 0.9146\n",
      "\n",
      "Answer:\n",
      "\n",
      "Respuesta local fallback (sin llamada a OpenAI):\n",
      "- El Batimovil ha evolucionado a lo largo de los anos: desde un auto deportivo modificado hasta un vehiculo blindado con turbina capaz de alcanzar 300 km/h, equipado con sistema de conduccion autonoma, contramedidas electronicas, y un modo de expulsion que permite a Batman salir catapultado [D4]\n",
      "- Jason resucito anos despues como Red Hood, un vigilante que mata criminales, la encarnacion de lo que Batman seria si rompiera su regla de no matar [D1]\n",
      "- El traje de Batman es una obra de ingenieria: la capa tiene memoria de forma que se rigidiza con corriente electrica para funcionar como ala delta [D4]\n"
     ]
    }
   ],
   "source": [
    "print('Query:')\n",
    "print(test_result['query'])\n",
    "print('\\nSelected route:', test_result['selected_route'])\n",
    "print('Second opinion used:', test_result['second_opinion_used'])\n",
    "print('Groundedness:', test_result['final_groundedness'])\n",
    "print('\\nAnswer:\\n')\n",
    "print(test_result['final_answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd25365b",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "\n",
    "Corre este batch y revisa como el router distribuye queries por especialista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31e83a39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T22:18:19.975386Z",
     "iopub.status.busy": "2026-02-19T22:18:19.975346Z",
     "iopub.status.idle": "2026-02-19T22:18:19.982636Z",
     "shell.execute_reply": "2026-02-19T22:18:19.982288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>selected_route</th>\n",
       "      <th>final_groundedness</th>\n",
       "      <th>retrieved_docs</th>\n",
       "      <th>second_opinion_used</th>\n",
       "      <th>latency_seconds</th>\n",
       "      <th>llm_provider</th>\n",
       "      <th>retrieval_provider</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ordena cronologicamente los hitos clave de Bat...</td>\n",
       "      <td>timeline</td>\n",
       "      <td>0.8852</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>local:fallback-summary</td>\n",
       "      <td>local:hash-embedding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Que diferencia hay entre la metodologia de Ban...</td>\n",
       "      <td>villains</td>\n",
       "      <td>0.8906</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>local:fallback-summary</td>\n",
       "      <td>local:hash-embedding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Por que Batman diseña planes de contingencia c...</td>\n",
       "      <td>strategy</td>\n",
       "      <td>0.8929</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>local:fallback-summary</td>\n",
       "      <td>local:hash-embedding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Que revela Court of Owls sobre los puntos cieg...</td>\n",
       "      <td>villains</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>local:fallback-summary</td>\n",
       "      <td>local:hash-embedding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Resume el rol de Robin en la evolucion del enf...</td>\n",
       "      <td>timeline</td>\n",
       "      <td>0.8689</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>local:fallback-summary</td>\n",
       "      <td>local:hash-embedding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query selected_route  \\\n",
       "0  Ordena cronologicamente los hitos clave de Bat...       timeline   \n",
       "1  Que diferencia hay entre la metodologia de Ban...       villains   \n",
       "2  Por que Batman diseña planes de contingencia c...       strategy   \n",
       "3  Que revela Court of Owls sobre los puntos cieg...       villains   \n",
       "4  Resume el rol de Robin en la evolucion del enf...       timeline   \n",
       "\n",
       "   final_groundedness  retrieved_docs  second_opinion_used  latency_seconds  \\\n",
       "0              0.8852               6                False           0.0008   \n",
       "1              0.8906               6                False           0.0006   \n",
       "2              0.8929               6                False           0.0006   \n",
       "3              0.9048               6                False           0.0005   \n",
       "4              0.8689               6                False           0.0005   \n",
       "\n",
       "             llm_provider    retrieval_provider  \n",
       "0  local:fallback-summary  local:hash-embedding  \n",
       "1  local:fallback-summary  local:hash-embedding  \n",
       "2  local:fallback-summary  local:hash-embedding  \n",
       "3  local:fallback-summary  local:hash-embedding  \n",
       "4  local:fallback-summary  local:hash-embedding  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = [\n",
    "    'Ordena cronologicamente los hitos clave de Batman entre Year One y Dark Knight Returns.',\n",
    "    'Que diferencia hay entre la metodologia de Bane y la del Joker para quebrar a Batman?',\n",
    "    'Por que Batman diseña planes de contingencia contra la Liga de la Justicia?',\n",
    "    'Que revela Court of Owls sobre los puntos ciegos de Bruce Wayne?',\n",
    "    'Resume el rol de Robin en la evolucion del enfoque de Batman.',\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for q in queries:\n",
    "    out = orchestrator.run(q)\n",
    "    rows.append({\n",
    "        'query': q,\n",
    "        'selected_route': out['selected_route'],\n",
    "        'final_groundedness': out['final_groundedness'],\n",
    "        'retrieved_docs': out['retrieved_docs'],\n",
    "        'second_opinion_used': out['second_opinion_used'],\n",
    "        'latency_seconds': out['latency_seconds'],\n",
    "        'llm_provider': out['llm_provider'],\n",
    "        'retrieval_provider': out['retrieval_provider'],\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(rows)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4f42a14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T22:18:19.983460Z",
     "iopub.status.busy": "2026-02-19T22:18:19.983417Z",
     "iopub.status.idle": "2026-02-19T22:18:19.989557Z",
     "shell.execute_reply": "2026-02-19T22:18:19.989242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selected_route</th>\n",
       "      <th>queries</th>\n",
       "      <th>avg_groundedness</th>\n",
       "      <th>second_opinion_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>strategy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8929</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>timeline</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8770</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>villains</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8977</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  selected_route  queries  avg_groundedness  second_opinion_rate\n",
       "0       strategy        1            0.8929                  0.0\n",
       "1       timeline        2            0.8770                  0.0\n",
       "2       villains        2            0.8977                  0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route_summary = (\n",
    "    results_df.groupby('selected_route', as_index=False)\n",
    "    .agg(\n",
    "        queries=('query', 'count'),\n",
    "        avg_groundedness=('final_groundedness', 'mean'),\n",
    "        second_opinion_rate=('second_opinion_used', 'mean'),\n",
    "    )\n",
    "    .round(4)\n",
    ")\n",
    "route_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "549d2a30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T22:18:19.990387Z",
     "iopub.status.busy": "2026-02-19T22:18:19.990337Z",
     "iopub.status.idle": "2026-02-19T22:18:19.993364Z",
     "shell.execute_reply": "2026-02-19T22:18:19.993048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/carlosdaniel/Documents/Projects/labor_projects/Henry/2026/01-introduction_ai_engineering/ai_engineering_henry/02-vector_data_bases/batman_vector_db_orchestration/outputs/agent2agent_specialized_router_results.csv\n"
     ]
    }
   ],
   "source": [
    "csv_path = OUTPUTS_DIR / 'agent2agent_specialized_router_results.csv'\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "print(f'Saved: {csv_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2da6ba9",
   "metadata": {},
   "source": [
    "## Cierre didactico\n",
    "\n",
    "### Conceptos clave de esta notebook\n",
    "\n",
    "- **Especializacion mejora calidad dentro del dominio**: un agente con un system prompt focalizado produce respuestas mas coherentes que uno generico, siempre que la query haya sido correctamente ruteada.\n",
    "- **El router heuristico como gate no-LLM reduce costos y latencia**: no toda decision requiere un LLM. Para routing, un clasificador basado en reglas es suficiente cuando los dominios son bien separados.\n",
    "- **El patron de segunda opinion agrega resiliencia**: en vez de fallar silenciosamente cuando el agente primario tiene bajo grounding, el sistema busca una perspectiva alternativa. Esto es especialmente util para queries que caen en fronteras entre dominios.\n",
    "- **Los thresholds deben adaptarse al nivel de especializacion**: agentes especializados merecen un quality gate mas estricto (0.2) que agentes generalistas (0.18), porque se espera que sean mas precisos en su dominio.\n",
    "\n",
    "### Recapitulacion del modulo completo\n",
    "\n",
    "A lo largo de las 5 notebooks hemos construido una progresion pedagogica:\n",
    "\n",
    "1. **NB01**: Diseno de base vectorial — chunking, embeddings, indexacion.\n",
    "2. **NB02**: Vanilla RAG vs Agentic RAG — metricas comparativas y groundedness.\n",
    "3. **NB03**: Routing entre dominios — orquestacion simple con pipelines especializados.\n",
    "4. **NB04**: Agent2Agent — separacion de responsabilidades entre retriever y synthesizer.\n",
    "5. **NB05**: Especializacion por roles — multiples agentes con router y segunda opinion.\n",
    "\n",
    "Cada notebook agrega complejidad arquitectonica, pero la pregunta de ingenieria siempre es la misma: **esta complejidad adicional produce mejoras medibles para mi caso de uso?** Si no, el sistema mas simple es el correcto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
