{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab20b4dd",
   "metadata": {},
   "source": [
    "# Agent2Agent Especializado con Router Interno (Batman)\n",
    "\n",
    "## Objetivo\n",
    "Extender el ejercicio agent2agent con una arquitectura de roles especializados:\n",
    "- **RouterAgent**: clasifica la consulta en una ruta semantica.\n",
    "- **SpecialistAgent** (timeline, villains, strategy, general): recupera evidencia y responde.\n",
    "\n",
    "Si la primera respuesta sale con grounding bajo, el orquestador pide una segunda opinion al agente `general`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e8dcf",
   "metadata": {},
   "source": [
    "## Flujo\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "  A[\"User Query\"] --> B[\"RouterAgent\"]\n",
    "  B --> C[\"SpecialistAgent (ruta seleccionada)\"]\n",
    "  C --> D[\"Grounding Check\"]\n",
    "  D -->|\"bajo\"| E[\"General Specialist (segunda opinion)\"]\n",
    "  D -->|\"ok\"| F[\"Final Answer\"]\n",
    "  E --> F\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bpaf7e25oyd",
   "source": "## Marco teorico: Especializacion por roles\n\n### Por que especializar agentes\n\nCada `SpecialistAgent` en esta arquitectura tiene un **system prompt optimizado para su dominio**:\n- `TimelineAgent`: prioriza orden temporal y transiciones narrativas.\n- `VillainsAgent`: prioriza motivaciones, metodos y conflicto heroe-villano.\n- `StrategyAgent`: prioriza decisiones tacticas y trade-offs operativos.\n- `GeneralAgent`: prioriza una explicacion balanceada de hechos canonicos.\n\nLa especializacion tiene un beneficio fundamental: **un LLM con un system prompt focalizado produce respuestas mas coherentes y relevantes que uno con un prompt generico**. Esto es analogo al principio de \"single responsibility\" en ingenieria de software — cada agente hace una cosa bien.\n\nAdemas, el `RouterAgent` en esta arquitectura **no es un LLM** — es un router heuristico basado en keywords. Esto tiene dos ventajas operativas:\n1. **Latencia reducida**: el routing es O(n) con n = numero de keywords, negligible comparado con un forward pass de LLM.\n2. **Costo cero de API**: no consume tokens de la API para decidir la ruta.\n\n### El patron de \"segunda opinion\"\n\nCuando el agente primario produce una respuesta con grounding bajo (`< 0.2`), el orquestador consulta al agente `general` como fallback. Este patron tiene analogias en multiple dominios:\n\n- **Mixture of Experts (MoE)**: en redes neuronales, diferentes \"expertos\" se especializan en subconjuntos de datos, con un gating network que decide cual activar. Aqui el router es el gate y los specialists son los expertos.\n- **Sistemas de segunda opinion medica**: cuando el diagnostico del especialista es incierto, se consulta a un generalista para validar o complementar.\n- **Escalamiento en soporte tecnico**: si el agente de nivel 2 no resuelve, se escala al nivel 3 (mas general pero con mas contexto).\n\n### Threshold 0.2 vs 0.18\n\nEn la notebook anterior (Agent2Agent simple), el threshold de grounding era **0.18**. Aqui usamos **0.2**. La razon:\n- Los agentes especializados deberian producir respuestas de **mayor calidad** dentro de su dominio, porque su system prompt esta optimizado para esa tarea.\n- Si un agente especializado no alcanza 0.2 de grounding, es una senal mas fuerte de que algo salio mal (query fuera de dominio, documentos insuficientes, etc.).\n- Un threshold ligeramente mas alto para agentes especializados actua como un **quality gate mas estricto**, lo cual es deseable cuando tienes un fallback disponible (el agente general).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b66232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "from scripts.common import generate_answer\n",
    "from scripts.evaluation import groundedness_score\n",
    "from scripts.vector_store_lab import build_index_from_json\n",
    "\n",
    "OUTPUTS_DIR = ROOT / 'outputs'\n",
    "OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DATA_PATH = ROOT / 'data' / 'batman_comics.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed6e8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "db, chunks, index_stats, chunk_stats = build_index_from_json(\n",
    "    json_path=DATA_PATH,\n",
    "    persist_dir=OUTPUTS_DIR / 'chroma_agent2agent_specialized',\n",
    "    collection_name='agent2agent_specialized_batman',\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=120,\n",
    "    embedding_model='text-embedding-3-small',\n",
    ")\n",
    "\n",
    "print('Index stats:', index_stats)\n",
    "print('Chunk stats:', chunk_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea89af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUTE_CONFIG = {\n",
    "    'timeline': {\n",
    "        'focus_hint': 'Prioriza orden temporal, etapas y transiciones narrativas.',\n",
    "        'system_prompt': (\n",
    "            'Eres TimelineAgent. Responde como historiador tecnico del canon de Batman. '\n",
    "            'Usa evidencia concreta y citas [D#].'\n",
    "        ),\n",
    "    },\n",
    "    'villains': {\n",
    "        'focus_hint': 'Prioriza motivaciones, metodos y dano psicologico de antagonistas.',\n",
    "        'system_prompt': (\n",
    "            'Eres VillainsAgent. Analiza conflicto heroe-villano, patrones de amenaza y riesgos. '\n",
    "            'Usa solo el contexto y cita [D#].'\n",
    "        ),\n",
    "    },\n",
    "    'strategy': {\n",
    "        'focus_hint': 'Prioriza tacticas, contingencias, trade-offs y decisiones operativas.',\n",
    "        'system_prompt': (\n",
    "            'Eres StrategyAgent. Explica decisiones estrategicas de Batman con precision operativa. '\n",
    "            'Usa evidencia y cita [D#].'\n",
    "        ),\n",
    "    },\n",
    "    'general': {\n",
    "        'focus_hint': 'Prioriza una explicacion balanceada de hechos canonicos verificables.',\n",
    "        'system_prompt': (\n",
    "            'Eres GeneralAgent. Sintetiza de forma rigurosa y didactica sin inventar datos. '\n",
    "            'Usa contexto y cita [D#].'\n",
    "        ),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e999b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RouterAgent:\n",
    "    def route(self, query: str) -> str:\n",
    "        q = query.lower()\n",
    "        if any(term in q for term in ['orden', 'cronologia', 'timeline', 'inicio', 'evolucion', 'despues']):\n",
    "            return 'timeline'\n",
    "        if any(term in q for term in ['joker', 'bane', 'hush', 'villano', 'enemigo', 'tribunal', 'owls']):\n",
    "            return 'villains'\n",
    "        if any(term in q for term in ['estrategia', 'tactica', 'plan', 'contingencia', 'liga', 'justicia']):\n",
    "            return 'strategy'\n",
    "        return 'general'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SpecialistAgent:\n",
    "    route: str\n",
    "    vector_db: object\n",
    "    model: str = 'gpt-5-mini'\n",
    "    embedding_model: str = 'text-embedding-3-small'\n",
    "    k: int = 6\n",
    "\n",
    "    def run(self, query: str) -> dict:\n",
    "        cfg = ROUTE_CONFIG[self.route]\n",
    "        rewritten_query = f\"{query} {cfg['focus_hint']}\"\n",
    "        docs, retrieval_provider = self.vector_db.query(\n",
    "            query_text=rewritten_query,\n",
    "            n_results=self.k,\n",
    "            embedding_model=self.embedding_model,\n",
    "        )\n",
    "        answer, llm_provider = generate_answer(\n",
    "            query=query,\n",
    "            contexts=[str(doc.get('text', '')) for doc in docs],\n",
    "            model=self.model,\n",
    "            system_prompt=cfg['system_prompt'],\n",
    "        )\n",
    "        grounding = groundedness_score(answer, [doc.get('text', '') for doc in docs])\n",
    "        return {\n",
    "            'route': self.route,\n",
    "            'answer': answer,\n",
    "            'groundedness': grounding,\n",
    "            'retrieved_docs': len(docs),\n",
    "            'llm_provider': llm_provider,\n",
    "            'retrieval_provider': retrieval_provider,\n",
    "            'rewritten_query': rewritten_query,\n",
    "        }\n",
    "\n",
    "\n",
    "class SpecializedAgent2AgentOrchestrator:\n",
    "    def __init__(self, router: RouterAgent, specialists: dict[str, SpecialistAgent], threshold: float = 0.2) -> None:\n",
    "        self.router = router\n",
    "        self.specialists = specialists\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def run(self, query: str) -> dict:\n",
    "        t0 = time.perf_counter()\n",
    "        trace = []\n",
    "\n",
    "        route = self.router.route(query)\n",
    "        trace.append({'agent': 'RouterAgent', 'message': f'Ruta seleccionada: {route}'})\n",
    "\n",
    "        primary = self.specialists[route].run(query)\n",
    "        trace.append({\n",
    "            'agent': f'SpecialistAgent[{route}]',\n",
    "            'message': f\"Grounding={primary['groundedness']}, docs={primary['retrieved_docs']}\",\n",
    "        })\n",
    "\n",
    "        selected = primary\n",
    "        second_opinion_used = False\n",
    "        if primary['groundedness'] < self.threshold and route != 'general':\n",
    "            backup = self.specialists['general'].run(query)\n",
    "            trace.append({\n",
    "                'agent': 'SpecialistAgent[general]',\n",
    "                'message': f\"Second opinion grounding={backup['groundedness']}\",\n",
    "            })\n",
    "            if backup['groundedness'] >= primary['groundedness']:\n",
    "                selected = backup\n",
    "                second_opinion_used = True\n",
    "\n",
    "        latency = round(time.perf_counter() - t0, 4)\n",
    "        return {\n",
    "            'query': query,\n",
    "            'selected_route': route,\n",
    "            'final_answer': selected['answer'],\n",
    "            'final_groundedness': selected['groundedness'],\n",
    "            'retrieved_docs': selected['retrieved_docs'],\n",
    "            'llm_provider': selected['llm_provider'],\n",
    "            'retrieval_provider': selected['retrieval_provider'],\n",
    "            'second_opinion_used': second_opinion_used,\n",
    "            'latency_seconds': latency,\n",
    "            'trace': trace,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9641c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_agent = RouterAgent()\n",
    "specialists = {\n",
    "    route: SpecialistAgent(route=route, vector_db=db, model='gpt-5-mini', embedding_model='text-embedding-3-small', k=6)\n",
    "    for route in ROUTE_CONFIG\n",
    "}\n",
    "orchestrator = SpecializedAgent2AgentOrchestrator(router=router_agent, specialists=specialists, threshold=0.2)\n",
    "print('Specialized agent2agent orchestrator ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305ae7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = 'Compara la evolucion tactica de Batman desde Year One hasta su enfrentamiento con Bane.'\n",
    "test_result = orchestrator.run(test_query)\n",
    "pd.DataFrame(test_result['trace'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f115ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Query:')\n",
    "print(test_result['query'])\n",
    "print('\\nSelected route:', test_result['selected_route'])\n",
    "print('Second opinion used:', test_result['second_opinion_used'])\n",
    "print('Groundedness:', test_result['final_groundedness'])\n",
    "print('\\nAnswer:\\n')\n",
    "print(test_result['final_answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd25365b",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "\n",
    "Corre este batch y revisa como el router distribuye queries por especialista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e83a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    'Ordena cronologicamente los hitos clave de Batman entre Year One y Dark Knight Returns.',\n",
    "    'Que diferencia hay entre la metodologia de Bane y la del Joker para quebrar a Batman?',\n",
    "    'Por que Batman diseña planes de contingencia contra la Liga de la Justicia?',\n",
    "    'Que revela Court of Owls sobre los puntos ciegos de Bruce Wayne?',\n",
    "    'Resume el rol de Robin en la evolucion del enfoque de Batman.',\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for q in queries:\n",
    "    out = orchestrator.run(q)\n",
    "    rows.append({\n",
    "        'query': q,\n",
    "        'selected_route': out['selected_route'],\n",
    "        'final_groundedness': out['final_groundedness'],\n",
    "        'retrieved_docs': out['retrieved_docs'],\n",
    "        'second_opinion_used': out['second_opinion_used'],\n",
    "        'latency_seconds': out['latency_seconds'],\n",
    "        'llm_provider': out['llm_provider'],\n",
    "        'retrieval_provider': out['retrieval_provider'],\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(rows)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f42a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_summary = (\n",
    "    results_df.groupby('selected_route', as_index=False)\n",
    "    .agg(\n",
    "        queries=('query', 'count'),\n",
    "        avg_groundedness=('final_groundedness', 'mean'),\n",
    "        second_opinion_rate=('second_opinion_used', 'mean'),\n",
    "    )\n",
    "    .round(4)\n",
    ")\n",
    "route_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549d2a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = OUTPUTS_DIR / 'agent2agent_specialized_router_results.csv'\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "print(f'Saved: {csv_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2da6ba9",
   "metadata": {},
   "source": "## Cierre didactico\n\n### Conceptos clave de esta notebook\n\n- **Especializacion mejora calidad dentro del dominio**: un agente con un system prompt focalizado produce respuestas mas coherentes que uno generico, siempre que la query haya sido correctamente ruteada.\n- **El router heuristico como gate no-LLM reduce costos y latencia**: no toda decision requiere un LLM. Para routing, un clasificador basado en reglas es suficiente cuando los dominios son bien separados.\n- **El patron de segunda opinion agrega resiliencia**: en vez de fallar silenciosamente cuando el agente primario tiene bajo grounding, el sistema busca una perspectiva alternativa. Esto es especialmente util para queries que caen en fronteras entre dominios.\n- **Los thresholds deben adaptarse al nivel de especializacion**: agentes especializados merecen un quality gate mas estricto (0.2) que agentes generalistas (0.18), porque se espera que sean mas precisos en su dominio.\n\n### Recapitulacion del modulo completo\n\nA lo largo de las 5 notebooks hemos construido una progresion pedagogica:\n\n1. **NB01**: Diseno de base vectorial — chunking, embeddings, indexacion.\n2. **NB02**: Vanilla RAG vs Agentic RAG — metricas comparativas y groundedness.\n3. **NB03**: Routing entre dominios — orquestacion simple con pipelines especializados.\n4. **NB04**: Agent2Agent — separacion de responsabilidades entre retriever y synthesizer.\n5. **NB05**: Especializacion por roles — multiples agentes con router y segunda opinion.\n\nCada notebook agrega complejidad arquitectonica, pero la pregunta de ingenieria siempre es la misma: **esta complejidad adicional produce mejoras medibles para mi caso de uso?** Si no, el sistema mas simple es el correcto."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}