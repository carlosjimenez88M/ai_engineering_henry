![](https://www.soyhenry.com/_next/static/media/HenryLogo.bb57fd6f.svg)

# AI Engineering - Henry 

Bienvenido al curso de AI Engineering de Henry. Este repositorio contiene material prÃ¡ctico diseÃ±ado para estudiantes que quieren entender las diferencias fundamentales entre Software Engineering tradicional y AI Engineering moderno, siguiendo los principios de **Chip Huyen** ("Designing Machine Learning Systems" y "AI Engineering").

## Â¿Por quÃ© este curso?

En la industria tech actual, no basta con saber usar un LLM API. Los mejores AI Engineers entienden:
- CÃ³mo diseÃ±ar sistemas que sean **reproducibles, testeables y observables**
- CuÃ¡ndo usar AI vs software tradicional (y cuÃ¡ndo combinarlos)
- CÃ³mo medir costos, latencia y calidad en sistemas AI
- Patrones de producciÃ³n que separan prototipos de sistemas reales

Este curso te prepara para construir sistemas AI que escalan en producciÃ³n, no solo demos que funcionan una vez.

## Estructura del Curso

El curso se divide en 4 clases progresivas:

### **Clase 1: Software vs AI Engineering** 
**Estado:** Completa y lista para usar

Contenido:
- ComparaciÃ³n crÃ­tica: Â¿CuÃ¡ndo usar quÃ©?
- Ejemplo prÃ¡ctico: Sistema de brief generation con OpenAI
- Testing, validaciÃ³n, mÃ©tricas y observabilidad
- Trade-offs y anti-patrones comunes

**UbicaciÃ³n:** `01_class/`

### **Clase 2: Prompting aplicado (CoT + ReAct)** 
**Estado:** Completa y lista para usar

Contenido:
- Estrategias Chain of Thought: Zero-shot y Few-shot
- Estrategias ReAct: razonamiento + acciÃ³n con herramientas
- Feedback loop y auto-crÃ­tica con rÃºbrica
- Notebooks ejecutables con OpenAI API

**UbicaciÃ³n:** `02-prompting/`

### **Clase 3: LangChain Prompting Avanzado (CoT + ReAct + Context Engineering)** 
**Estado:** Completa y lista para usar

Contenido:
- QuÃ© es LangChain y cuÃ¡ndo usarlo en problemas reales
- MigraciÃ³n de tÃ©cnicas de `02-prompting` a `ChatPromptTemplate`, `FewShot` y salida estructurada
- ReAct con tools, guardrails y trazabilidad de estado
- Context engineering aplicado para mejorar calidad/costo/latencia
- Notebooks ejecutables con validaciÃ³n automÃ¡tica

**UbicaciÃ³n:** `03_langchain_prompting/`

### **Clase 4: LangGraph Workflows y Agents** 
**Estado:** Completa y lista para usar

Contenido:
- Workflows oficiales de LangGraph aplicados: prompt chaining, parallelization, routing
- Arquitecturas avanzadas: orchestrator-worker y evaluator-optimizer
- Agent con tools y feedback loop de calidad
- Notebooks ejecutables por arquitectura

**UbicaciÃ³n:** `04_langchain_langgraph/`

## Comenzando

### Requisitos Previos

- **Python 3.10 o superior**
- **Cuenta de OpenAI** con API key activa ([obtener aquÃ­](https://platform.openai.com/api-keys))
- **uv** instalado ([instrucciones de instalaciÃ³n](https://github.com/astral-sh/uv))
- Conocimientos bÃ¡sicos de:
  - Python (funciones, clases, imports)
  - Terminal/CLI
  - Git (opcional pero recomendado)

### InstalaciÃ³n Paso a Paso

1. **Clona el repositorio:**
   ```bash
   git clone https://github.com/yourusername/ai_engineering_henry.git
   cd ai_engineering_henry
   ```

2. **Instala dependencias con uv:**
   ```bash
   make install
   # o directamente: uv sync
   ```

3. **Configura tu API key de OpenAI:**

   Crea un archivo `.env` en la raÃ­z del proyecto:
   ```bash
   cp .env.example .env
   ```

   Edita `.env` y agrega tu API key:
   ```
   OPENAI_API_KEY=sk-proj-tu-api-key-aqui
   OPENAI_MODEL=gpt-4o-mini  # opcional, default: gpt-4o-mini
   ```

4. **Verifica la instalaciÃ³n:**
   ```bash
   make test-se
   ```

   Si ves tests pasando, Â¡estÃ¡s listo! 

### Primer Comando

Genera tu primer brief comparativo:
```bash
make run-ai
```

El brief se guardarÃ¡ en `01_class/ai_engineering/briefs/software_vs_ai_engineering.md`.

Con contexto personalizado:
```bash
make run-ai-context CONTEXT="Startup de fintech B2B"
```

## FilosofÃ­a del Curso

Este curso sigue los principios de **Chip Huyen** sobre sistemas AI en producciÃ³n:

### 1. **Reproducibilidad**
- Versionamos prompts en Git
- Trackeamos model version, temperature y parÃ¡metros
- Logs detallados para debugging

### 2. **Modularidad**
- SeparaciÃ³n clara de concerns (config, prompts, validation, metrics)
- Componentes reusables y testeables
- No "God functions" que hacen todo

### 3. **Testing Riguroso**
- Tests unitarios para lÃ³gica de negocio
- Tests de integraciÃ³n con mocks de APIs
- ValidaciÃ³n de inputs y outputs
- Target: 85%+ code coverage

### 4. **Observabilidad**
- MÃ©tricas de costo por request
- Latency tracking
- Quality checks automatizados
- Error logging estructurado

### 5. **Error Handling Resiliente**
- Retry logic con exponential backoff
- Excepciones especÃ­ficas (no "catch all")
- Graceful degradation cuando sea posible

### 6. **Budget Awareness**
- EstimaciÃ³n de costos antes de ejecutar
- Logs de tokens y USD por operaciÃ³n
- Alertas cuando se exceden thresholds

## Fundamentos de Prompt Engineering

### Premisa Central: Los Agentes Dependen del Contexto

**Principio fundamental**: La calidad del razonamiento de un agente es directamente proporcional a la claridad y completitud del contexto que recibe.

- **Agente** = Sistema LLM + Herramientas + Contexto + Ciclo de retroalimentaciÃ³n
- **Buen contexto** = comportamiento consistente, predecible, eficiente en costos
- **Contexto vago** = alucinaciones, inconsistencia, explosiÃ³n de costos

**Ejemplo:**
-  Contexto dÃ©bil: "AquÃ­ hay info del usuario"
-  Contexto fuerte: "Usuario: 28 aÃ±os, preferencias: [jazz, fotografÃ­a], estilo conversacional: inteligente y ligero, contexto: primer mensaje tras match"

### AnatomÃ­a de un Prompt de ProducciÃ³n

Todo prompt efectivo sigue esta estructura de 5 capas:

**1. ROLE (QuiÃ©n es el agente)**
```
"Eres un coach conversacional elegante, respetuoso y prÃ¡ctico."
```
- Define identidad, expertise, valores
- Establece tono y lÃ­mites Ã©ticos
- Siempre explÃ­cito, nunca implÃ­cito

**2. TASK (QuÃ© debe hacer)**
```
"DiseÃ±a una recomendaciÃ³n de conversaciÃ³n personalizada basada en el perfil del usuario."
```
- Objetivo especÃ­fico y medible
- Sin ambigÃ¼edad en el alcance
- Descomponer tareas complejas en subtareas

**3. OUTPUT FORMAT (Estructura requerida)**
```json
{
  "opener": "mensaje inicial",
  "follow_up": "pregunta de seguimiento",
  "tone_notes": ["observaciÃ³n 1", "observaciÃ³n 2"]
}
```
- JSON schema o Pydantic BaseModel
- Valida automÃ¡ticamente
- Facilita integraciÃ³n downstream

**4. EXAMPLES (Comportamiento esperado - opcional)**
```
"Ejemplo de buen opener: 'Â¿QuÃ© cafÃ©s de Palermo recomendarÃ­as para...?'"
```
- Few-shot learning: 1-3 ejemplos de calidad
- Trade-off: +consistencia, +tokens/costo
- Usar cuando calidad > costo

**5. CONTEXT (InformaciÃ³n especÃ­fica)**
```python
profile = {
  "tipo_persona": "arquitecta apasionada por fotografÃ­a urbana",
  "gustos": ["cafÃ©s tranquilos", "jazz", "viajes cortos"],
  "contexto": "match reciente, primera interacciÃ³n"
}
```
- Datos estructurados, no narrativos
- Incluir meta-informaciÃ³n (fuente, confianza)
- Filtrar ruido, priorizar seÃ±ales

**AplicaciÃ³n en este curso:**
- **Clase 1**: brief_builder usa ROLE + TASK + FORMAT implÃ­citamente
- **Clase 2**: COT aÃ±ade razonamiento explÃ­cito; ReAct aÃ±ade herramientas y ciclos
- **Clase 3**: LangChain formaliza prompts, tools y salida estructurada
- **Clase 4**: LangGraph lleva esta estructura a arquitecturas de orquestaciÃ³n

### Mejores PrÃ¡cticas de AI Engineering

**1. Instrucciones Claras y No Ambiguas**
- Usa lenguaje imperativo: "Devuelve", "Analiza", "Genera"
- Evita lenguaje condicional vago: "tal vez", "podrÃ­a"
- Especifica lÃ­mites: longitud mÃ¡xima, formato exacto, restricciones

**2. Siempre Define el Rol del Agente**
- Sin rol = agente asume personalidad genÃ©rica
- Rol explÃ­cito = comportamiento consistente
- Incluye valores Ã©ticos en el rol (respeto, consentimiento)

**3. Divide Tareas Complejas en Subtareas**
- Una tarea = una responsabilidad
- Cadena subtareas con estado explÃ­cito
- Ejemplo: ANALIZAR â†’ GENERAR â†’ AUDITAR â†’ RESPONDER

**4. Especifica Formato de Salida Estrictamente**
- JSON schema con campos requeridos
- Pydantic BaseModel con validaciÃ³n (producciÃ³n)
- Incluye tipos de datos y rangos permitidos

**5. Seguridad y Restricciones Ã‰ticas**
- Restricciones upfront en ROLE y TASK
- AuditorÃ­a automÃ¡tica de salidas (ver ReAct/audit)
- Nunca asumas que el modelo "sabe" Ã©tica implÃ­citamente

**6. Proceso Iterativo con EvaluaciÃ³n**
- Primera versiÃ³n â†’ EvaluaciÃ³n con rÃºbrica â†’ Feedback â†’ RegeneraciÃ³n
- MÃ©tricas objetivas (ver rubrica.py)
- Itera hasta alcanzar umbral de calidad

### Errores Comunes y DiagnÃ³stico

**Error 1: AmbigÃ¼edad en Instrucciones**
-  Problema: "Genera un mensaje simpÃ¡tico"
-  SoluciÃ³n: "Genera un mensaje de 15-25 palabras que incluya una pregunta sobre [tema del perfil]"
- **Impacto**: Inconsistencia, outputs impredecibles, debugging difÃ­cil

**Error 2: Contradicciones en el Prompt**
-  Problema: "SÃ© breve" + "Explica detalladamente"
-  SoluciÃ³n: Prioriza explÃ­citamente o separa en dos llamadas
- **Impacto**: Modelo elige arbitrariamente, resultados varÃ­an por ejecuciÃ³n

**Error 3: Asumir que el LLM "Lee la Mente"**
-  Problema: "El usuario quiere algo interesante"
-  SoluciÃ³n: Proporciona gustos explÃ­citos del perfil como contexto estructurado
- **Impacto**: Alucinaciones, outputs genÃ©ricos, baja personalizaciÃ³n

**Error 4: Falta de ValidaciÃ³n de Salidas**
-  Problema: Asumir que la API siempre devuelve formato correcto
-  SoluciÃ³n: Valida con JSON schema o Pydantic antes de usar
- **Impacto**: Errores en sistemas downstream, fallos silenciosos

**Error 5: Prompt Injection**
-  Problema: Concatenar input del usuario directamente en prompts
-  SoluciÃ³n: Sanitiza inputs, usa delimitadores claros, valida antes de insertar
- **Impacto**: Usuarios maliciosos pueden alterar comportamiento del agente

**Error 6: ExplosiÃ³n de Contexto**
-  Problema: Meter documentos completos sin procesar
-  SoluciÃ³n: Resume, extrae hechos clave, estructura jerÃ¡rquicamente
- **Impacto**: Costos inmanejables, timeouts, degradaciÃ³n de calidad

**Error 7: Temperatura Incorrecta**
-  Problema: Usar temperature=1.5 para tareas determinÃ­sticas
-  SoluciÃ³n: 0.1-0.3 para consistencia, 0.7+ para creatividad
- **Impacto**: Variabilidad impredecible, costos mÃ¡s altos por reintentos

**Error 8: No Estimar Costos Antes de ProducciÃ³n**
-  Problema: Desplegar sin calcular tokens/request tÃ­pico
-  SoluciÃ³n: Calcula (input_tokens + output_tokens) Ã— precio Ã— volumen_esperado
- **Impacto**: Sobrecostos, necesidad de rediseÃ±o de emergencia

### ConexiÃ³n con Clases del Curso

Esta estructura se aplica progresivamente:

- **Clase 1** (brief_builder): Prompt simple con ROLE + TASK + FORMAT
- **Clase 2** (CoT/ReAct): AÃ±ade razonamiento explÃ­cito y herramientas
  - COT: Descompone razonamiento en pasos visibles
  - ReAct: AÃ±ade ciclo Thought â†’ Action â†’ Observation
- **Clase 3** (LangChain): OrquestaciÃ³n con templates, tools y context engineering
- **Clase 4** (LangGraph): Patrones de workflows y agents para sistemas compuestos

Ver `02-prompting/`, `03_langchain_prompting/` y `04_langchain_langgraph/` para aplicaciÃ³n prÃ¡ctica de estos conceptos.

## DistribuciÃ³n del Repositorio

```
ai_engineering_henry/
â”œâ”€â”€ 01_class/                    # Clase 1: Software vs AI Engineering
â”‚   â”œâ”€â”€ ai_engineering/          # Ejemplo de AI Engineering
â”‚   â”‚   â”œâ”€â”€ brief_builder/       # Sistema de generaciÃ³n de briefs
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py         # Entry point con CLI
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py       # ConfiguraciÃ³n y secrets
â”‚   â”‚   â”‚   â”œâ”€â”€ prompts.py      # Prompts versionados
â”‚   â”‚   â”‚   â”œâ”€â”€ validator.py    # ValidaciÃ³n de inputs/outputs
â”‚   â”‚   â”‚   â”œâ”€â”€ exceptions.py   # Excepciones especÃ­ficas
â”‚   â”‚   â”‚   â”œâ”€â”€ retry.py        # Retry logic con backoff
â”‚   â”‚   â”‚   â”œâ”€â”€ metrics.py      # Tracking de costos/latencia
â”‚   â”‚   â”‚   â””â”€â”€ logger.py       # Logging estructurado
â”‚   â”‚   â”œâ”€â”€ tests/              # Tests del sistema AI
â”‚   â”‚   â”œâ”€â”€ briefs/             # Briefs generados
â”‚   â”‚   â””â”€â”€ README.md           # GuÃ­a detallada de Clase 1
â”‚   â”‚
â”‚   â””â”€â”€ python_software_engineering/  # Ejemplo de Software tradicional
â”‚       â”œâ”€â”€ src/app.py          # LÃ³gica de negocio determinista
â”‚       â””â”€â”€ tests/test_app.py   # Tests unitarios
â”‚
â”œâ”€â”€ Makefile                    # Comandos para desarrollo
â”œâ”€â”€ pyproject.toml             # Dependencias y configuraciÃ³n
â”œâ”€â”€ .env.example               # Template para variables de entorno
â””â”€â”€ README.md                  # Este archivo
```

## Comandos Disponibles

### Desarrollo
```bash
make install        # Instalar dependencias
make install-prompting  # Instalar entorno de Clase 02 con uv
make run-ai         # Generar brief bÃ¡sico
make run-ai-context CONTEXT="texto"  # Brief con contexto
make run-se         # Ejecutar ejemplo de software clÃ¡sico
make run-cot        # Ejecutar ejemplos CoT
make run-react      # Ejecutar ejemplos ReAct
make run-notebooks  # Ejecutar notebooks de Clase 02
```

### Testing
```bash
make test-se        # Tests de software engineering
make test-ai        # Tests de AI engineering
make test-all       # Todos los tests
make test-ai-cov    # Tests con reporte de cobertura
```

### Utilidades
```bash
make check          # Verificar sintaxis Python
make clean          # Limpiar artefactos
```

## Recursos Adicionales

### Libros Recomendados
- ğŸ“š **"Designing Machine Learning Systems"** - Chip Huyen
  - CapÃ­tulos clave: 5 (Model Development), 7 (Monitoring), 8 (Data Distribution Shifts)
- ğŸ“š **"AI Engineering"** - Chip Huyen
  - Especialmente: Resilient Systems, Evaluation, Production Patterns

### ArtÃ­culos y Referencias
- [Rules of Machine Learning](https://developers.google.com/machine-learning/guides/rules-of-ml) - Google
- [OpenAI API Best Practices](https://platform.openai.com/docs/guides/production-best-practices)
- [The Twelve-Factor App](https://12factor.net/) - MetodologÃ­a para aplicaciones modernas

### Comunidad Henry
- ğŸ’¬ **Slack:** Canal #ai-engineering
- ğŸ“§ **Email:** ai-support@soyhenry.com
-  **Office Hours:** Consulta el calendario interno

## Notas de Seguridad

###  IMPORTANTE: Nunca subas secretos a Git

El `.gitignore` estÃ¡ configurado para prevenir:
-  Claves API (`.env`, archivos `secrets.*`)
-  Certificados y llaves privadas (`.pem`, `.key`)
-  Entornos virtuales (`.venv/`, `venv/`)
-  Artefactos de desarrollo (`__pycache__`, `.pytest_cache`)

### Buenas PrÃ¡cticas

1. **Usa `.env` para secrets** (nunca hardcodees API keys)
2. **Rotate API keys** si sospechas exposiciÃ³n
3. **Limita permisos** de API keys (solo los necesarios)
4. **Monitorea uso** en el dashboard de OpenAI
5. **Set spending limits** en tu cuenta de OpenAI

### Â¿QuÃ© hacer si expones un secret?

1. **Inmediatamente:** Revoca la API key en OpenAI dashboard
2. **Genera nueva key** y actualiza tu `.env`
3. **Reporta** al equipo si fue en repo compartido
4. **Aprende:** Usa `git-secrets` o pre-commit hooks

## Contribuyendo

Este es un curso en evoluciÃ³n. Si encuentras:
- ğŸ› Bugs o errores
- ğŸ“ DocumentaciÃ³n poco clara
- ğŸ’¡ Ideas para mejorar
- ğŸ¯ Ejemplos adicionales que ayudarÃ­an

Por favor abre un issue o pull request. Todas las contribuciones son bienvenidas.

## Licencia

Este material es propiedad de Henry Academy y estÃ¡ disponible para estudiantes del programa. No redistribuir sin autorizaciÃ³n.

---

## PrÃ³ximos Pasos

1.  Completa la **Clase 1** siguiendo `01_class/README.md`
2. ğŸ§ª Experimenta con diferentes valores de `temperature` y observa los resultados
3.  Revisa los archivos `.metrics.json` para entender costos
4. ğŸ§ Lee el brief generado y compÃ¡ralo con el prompt
5. ğŸ” Explora el cÃ³digo en `brief_builder/` para ver los patrones

**Â¿Listo para empezar?** â†’ Ve a `01_class/README.md`

---

**Made with â¤ï¸ by Henry Academy**

*"The best way to predict the future is to build it."* - Alan Kay
