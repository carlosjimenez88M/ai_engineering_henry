{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 02: Patrones de Produccion para AI/ML\n",
    "\n",
    "**Notebook 7 de la serie Python Extra Class** | Tiempo estimado: 90-120 min\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "\n",
    "Al completar este notebook seras capaz de:\n",
    "\n",
    "1. **Implementar context managers** para gestion segura de recursos (timers, archivos temporales, estado)\n",
    "2. **Usar generadores** para procesamiento eficiente de datos grandes sin agotar memoria\n",
    "3. **Configurar logging estructurado** para observabilidad en produccion\n",
    "4. **Combinar patrones** en pipelines robustos de AI/ML\n",
    "\n",
    "---\n",
    "\n",
    "### Contexto\n",
    "\n",
    "Este notebook **combina los mejores patrones de los ejemplos ejecutables del curso**:\n",
    "\n",
    "| Ejemplo | Patron | Lo que aprendimos |\n",
    "|---------|--------|--------------------|\n",
    "| `01_excepciones.py` | Excepciones personalizadas | Errores con contexto y metadata |\n",
    "| `02_context_managers.py` | Context managers | Gestion segura de recursos |\n",
    "| `03_generadores.py` | Generadores | Procesamiento lazy y eficiente |\n",
    "| `04_logging_config.py` | Logging estructurado | Observabilidad en produccion |\n",
    "| `05_comprehensions.py` | Comprehensions | Rendimiento y legibilidad |\n",
    "| `06_combinados.py` | Pipelines completos | Integracion de patrones |\n",
    "\n",
    "Aqui los integramos en un flujo realista de produccion para AI/ML.\n",
    "\n",
    "> **Requisitos:** Solo biblioteca estandar de Python. Sin dependencias externas."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================\n",
    "# SETUP - Importaciones y verificacion del entorno\n",
    "# =============================================================\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import tempfile\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "from contextlib import contextmanager\n",
    "from typing import Iterator, Generator, Any, Optional\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SETUP COMPLETO - Patrones de Produccion\")\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Fecha:  {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(\"=\" * 60)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Seccion 1: Context Managers - Gestion de Recursos\n",
    "\n",
    "Un **context manager** garantiza que los recursos se inicialicen y se liberen\n",
    "correctamente, incluso si ocurre una excepcion.\n",
    "\n",
    "### Flujo de ejecucion\n",
    "\n",
    "```\n",
    "with recurso as r:         # __enter__() se ejecuta\n",
    "    |                      #\n",
    "    |  codigo del bloque   # Tu codigo aqui\n",
    "    |                      #\n",
    "    v                      # __exit__() se ejecuta SIEMPRE\n",
    "                           #   - sin error: exc_type = None\n",
    "                           #   - con error: exc_type = tipo de excepcion\n",
    "```\n",
    "\n",
    "### Diagrama: Ciclo de vida\n",
    "\n",
    "```\n",
    "  __enter__()          Bloque with          __exit__()\n",
    " +-----------+      +---------------+     +-----------+\n",
    " | Adquirir  | ---> | Usar recurso  | --> | Liberar   |\n",
    " | recurso   |      | (tu codigo)   |     | recurso   |\n",
    " +-----------+      +---------------+     +-----------+\n",
    "       |                   |                    |\n",
    "       |              Si hay error:             |\n",
    "       |              exc_type != None          |\n",
    "       |                   |                    |\n",
    "       +------- GARANTIZADO: siempre pasa ------+\n",
    "```\n",
    "\n",
    "### Por que importa en produccion\n",
    "\n",
    "| Recurso | Si no se limpia... | Solucion con context manager |\n",
    "|---------|-------------------|------------------------------|\n",
    "| Archivo | Datos corruptos, file locks | `with open(...)` cierra siempre |\n",
    "| Conexion DB | Connection pool agotado | `with db.connect()` libera conexion |\n",
    "| Timer | No sabes que es lento | `with Timer()` mide automaticamente |\n",
    "| Estado temporal | Config corrupta permanente | `with TemporaryState()` restaura |\n",
    "| Directorio temp | Disco lleno en servidor | `with tempdir()` elimina archivos |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================\n",
    "# Context Manager basado en clase: Timer\n",
    "# =============================================================\n",
    "\n",
    "class Timer:\n",
    "    \"\"\"Mide el tiempo de ejecucion de un bloque de codigo.\n",
    "    \n",
    "    Uso:\n",
    "        with Timer(\"mi operacion\") as t:\n",
    "            # codigo a medir\n",
    "        print(t.elapsed)  # tiempo en segundos\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, label: str = \"Operacion\"):\n",
    "        self.label = label\n",
    "        self.elapsed: float = 0.0\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self._start = time.perf_counter()\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.elapsed = time.perf_counter() - self._start\n",
    "        status = \"ERROR\" if exc_type else \"OK\"\n",
    "        print(f\"[Timer] {self.label}: {self.elapsed:.4f}s ({status})\")\n",
    "        return False  # No suprimimos excepciones\n",
    "\n",
    "\n",
    "# --- Demo: Comparar list comprehension vs loop ---\n",
    "\n",
    "N = 500_000\n",
    "\n",
    "with Timer(\"List comprehension\") as t1:\n",
    "    resultado_comp = [x ** 2 for x in range(N)]\n",
    "\n",
    "with Timer(\"Loop tradicional\") as t2:\n",
    "    resultado_loop = []\n",
    "    for x in range(N):\n",
    "        resultado_loop.append(x ** 2)\n",
    "\n",
    "print(f\"\\nComparacion:\")\n",
    "print(f\"  Comprehension: {t1.elapsed:.4f}s\")\n",
    "print(f\"  Loop:          {t2.elapsed:.4f}s\")\n",
    "if t2.elapsed > 0:\n",
    "    ratio = t2.elapsed / t1.elapsed\n",
    "    print(f\"  Ratio:         {ratio:.2f}x mas lento el loop\")\n",
    "print(f\"  Resultados iguales: {resultado_comp == resultado_loop}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================\n",
    "# Context Manager: TemporaryState\n",
    "# Guarda y restaura atributos de un objeto\n",
    "# =============================================================\n",
    "\n",
    "class TemporaryState:\n",
    "    \"\"\"Temporalmente modifica atributos de un objeto y los restaura al salir.\n",
    "    \n",
    "    Ideal para cambiar configuracion de modelos durante inferencia/evaluacion.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, obj, **overrides):\n",
    "        self.obj = obj\n",
    "        self.overrides = overrides\n",
    "        self._saved: dict = {}\n",
    "    \n",
    "    def __enter__(self):\n",
    "        for key, value in self.overrides.items():\n",
    "            self._saved[key] = getattr(self.obj, key)\n",
    "            setattr(self.obj, key, value)\n",
    "        return self.obj\n",
    "    \n",
    "    def __exit__(self, *args):\n",
    "        for key, value in self._saved.items():\n",
    "            setattr(self.obj, key, value)\n",
    "        return False\n",
    "\n",
    "\n",
    "# --- Demo: Configuracion temporal de modelo ---\n",
    "\n",
    "class ModelConfig:\n",
    "    \"\"\"Simulacion de configuracion de un modelo LLM.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.temperature = 0.7\n",
    "        self.max_tokens = 1024\n",
    "        self.top_p = 0.9\n",
    "        self.model_name = \"gpt-4\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return (f\"ModelConfig(temperature={self.temperature}, \"\n",
    "                f\"max_tokens={self.max_tokens}, top_p={self.top_p})\")\n",
    "\n",
    "\n",
    "config = ModelConfig()\n",
    "print(f\"ANTES:   {config}\")\n",
    "\n",
    "# Temporalmente cambiar para evaluacion (temperatura 0 = deterministico)\n",
    "with TemporaryState(config, temperature=0.0, max_tokens=256) as cfg:\n",
    "    print(f\"DURANTE: {cfg}\")\n",
    "    # Aqui harias la evaluacion del modelo...\n",
    "    assert cfg.temperature == 0.0\n",
    "    assert cfg.max_tokens == 256\n",
    "\n",
    "print(f\"DESPUES: {config}\")\n",
    "\n",
    "# Verificar que se restauro correctamente\n",
    "assert config.temperature == 0.7\n",
    "assert config.max_tokens == 1024\n",
    "print(\"\\nEstado restaurado correctamente!\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================\n",
    "# Context Manager con @contextmanager (basado en generador)\n",
    "# =============================================================\n",
    "# Mas conciso que la version con clase. Ideal para casos simples.\n",
    "\n",
    "@contextmanager\n",
    "def timer(label: str = \"Operacion\"):\n",
    "    \"\"\"Version con decorador del Timer. Mas conciso.\"\"\"\n",
    "    start = time.perf_counter()\n",
    "    elapsed = {\"value\": 0.0}  # dict mutable para poder modificar desde fuera\n",
    "    try:\n",
    "        yield elapsed\n",
    "    finally:\n",
    "        elapsed[\"value\"] = time.perf_counter() - start\n",
    "        print(f\"[timer] {label}: {elapsed['value']:.4f}s\")\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def temporary_directory(prefix: str = \"ml_pipeline_\"):\n",
    "    \"\"\"Crea un directorio temporal y lo elimina al salir.\n",
    "    \n",
    "    Util para: checkpoints temporales, datos intermedios, cache de inferencia.\n",
    "    \"\"\"\n",
    "    tmpdir = tempfile.mkdtemp(prefix=prefix)\n",
    "    print(f\"[tmpdir] Creado: {tmpdir}\")\n",
    "    try:\n",
    "        yield tmpdir\n",
    "    finally:\n",
    "        # Limpiar todos los archivos y el directorio\n",
    "        for f in os.listdir(tmpdir):\n",
    "            os.remove(os.path.join(tmpdir, f))\n",
    "        os.rmdir(tmpdir)\n",
    "        print(f\"[tmpdir] Eliminado: {tmpdir}\")\n",
    "\n",
    "\n",
    "# --- Demo: Ambos context managers en accion ---\n",
    "\n",
    "print(\"=== Comparacion: clase vs decorador ===\")\n",
    "print()\n",
    "\n",
    "# Version clase\n",
    "with Timer(\"clase\") as t:\n",
    "    sum(range(100_000))\n",
    "\n",
    "# Version decorador\n",
    "with timer(\"decorador\") as t:\n",
    "    sum(range(100_000))\n",
    "\n",
    "print()\n",
    "print(\"=== Directorio temporal ===\")\n",
    "print()\n",
    "\n",
    "with temporary_directory(\"checkpoint_\") as tmpdir:\n",
    "    # Simular guardar un checkpoint\n",
    "    checkpoint_file = os.path.join(tmpdir, \"model_epoch_5.json\")\n",
    "    with open(checkpoint_file, \"w\") as f:\n",
    "        json.dump({\"epoch\": 5, \"loss\": 0.023, \"accuracy\": 0.97}, f)\n",
    "    \n",
    "    print(f\"  Archivo creado: {os.path.basename(checkpoint_file)}\")\n",
    "    print(f\"  Contenido dir: {os.listdir(tmpdir)}\")\n",
    "    print(f\"  Existe: {os.path.exists(checkpoint_file)}\")\n",
    "\n",
    "# Despues del with, el directorio ya no existe\n",
    "print(f\"  Existe despues: {os.path.exists(tmpdir)}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Seccion 2: Generadores para Procesamiento Eficiente\n",
    "\n",
    "Los **generadores** producen valores uno a la vez (lazy evaluation), en lugar\n",
    "de cargar todo en memoria. Esto es critico cuando trabajas con datasets grandes\n",
    "en ML.\n",
    "\n",
    "### Lista vs Generador: Uso de memoria\n",
    "\n",
    "```\n",
    "  LISTA (carga todo en memoria):\n",
    "  +-----+-----+-----+-----+-----+-----+-----+-----+\n",
    "  | r0  | r1  | r2  | r3  | r4  | ... | rN-1| rN  |  <-- TODO en RAM\n",
    "  +-----+-----+-----+-----+-----+-----+-----+-----+\n",
    "  Memoria: O(N)\n",
    "\n",
    "  GENERADOR (produce uno a la vez):\n",
    "  +-----+\n",
    "  | r_i | --> procesar --> siguiente\n",
    "  +-----+\n",
    "  Memoria: O(1)\n",
    "```\n",
    "\n",
    "### Por que importa en AI/ML\n",
    "\n",
    "```\n",
    "  Dataset de 10GB de textos para entrenar un LLM:\n",
    "\n",
    "  MAL (lista):     cargar_todo() --> [10GB en RAM] --> OOM Error!\n",
    "  BIEN (generador): stream()     --> [1 batch]     --> procesar --> siguiente\n",
    "```\n",
    "\n",
    "| Caso de uso | Sin generador | Con generador |\n",
    "|-------------|---------------|---------------|\n",
    "| Leer 1M de registros | `list(read_all())` = 8GB RAM | `yield` = ~KB RAM |\n",
    "| Batches de training | `all_batches = [...]` | `yield batch` |\n",
    "| Paginacion de API | Cargar todas las paginas | `yield page` |\n",
    "| Preprocesar texto | Lista de documentos | Stream de documentos |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================\n",
    "# Generadores: batch_iterator\n",
    "# =============================================================\n",
    "\n",
    "def batch_iterator(data, batch_size: int = 32) -> Generator:\n",
    "    \"\"\"Divide datos en batches del tamano especificado.\n",
    "    \n",
    "    Patron fundamental en ML: DataLoader, training loops, inferencia batch.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        yield data[i:i + batch_size]\n",
    "\n",
    "\n",
    "# --- Demo ---\n",
    "\n",
    "# Simular 1000 muestras de entrenamiento\n",
    "dataset = [f\"muestra_{i}\" for i in range(1000)]\n",
    "\n",
    "print(f\"Dataset: {len(dataset)} muestras\")\n",
    "print(f\"Batch size: 100\")\n",
    "print()\n",
    "\n",
    "# Iterar por batches\n",
    "batches = list(batch_iterator(dataset, batch_size=100))\n",
    "print(f\"Total batches: {len(batches)}\")\n",
    "print(f\"Tamano primer batch: {len(batches[0])}\")\n",
    "print(f\"Primeros 3 del batch 0: {batches[0][:3]}\")\n",
    "print(f\"Primeros 3 del batch 5: {batches[5][:3]}\")\n",
    "print()\n",
    "\n",
    "# Uso tipico en un training loop\n",
    "print(\"Simulando training loop:\")\n",
    "for epoch in range(2):\n",
    "    total = 0\n",
    "    for batch_idx, batch in enumerate(batch_iterator(dataset, 100)):\n",
    "        total += len(batch)\n",
    "    print(f\"  Epoch {epoch + 1}: {batch_idx + 1} batches, {total} muestras procesadas\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================\n",
    "# Comparacion de memoria: Lista vs Generador\n",
    "# =============================================================\n",
    "\n",
    "def generate_records(n: int) -> Generator:\n",
    "    \"\"\"Genera n registros simulados de ML (lazy).\"\"\"\n",
    "    for i in range(n):\n",
    "        yield {\"id\": i, \"score\": i * 0.001, \"label\": i % 10}\n",
    "\n",
    "\n",
    "def sliding_window(data, window_size: int = 3) -> Generator:\n",
    "    \"\"\"Genera ventanas deslizantes sobre una secuencia.\n",
    "    \n",
    "    Util para: series temporales, n-gramas en NLP, features secuenciales.\n",
    "    \"\"\"\n",
    "    for i in range(len(data) - window_size + 1):\n",
    "        yield data[i:i + window_size]\n",
    "\n",
    "\n",
    "# --- Comparacion de memoria ---\n",
    "\n",
    "N = 100_000\n",
    "\n",
    "# Enfoque 1: Lista completa\n",
    "with Timer(\"Lista completa\"):\n",
    "    lista = [{'id': i, 'score': i * 0.001, 'label': i % 10} for i in range(N)]\n",
    "    size_lista = sys.getsizeof(lista)\n",
    "\n",
    "# Enfoque 2: Generador\n",
    "with Timer(\"Generador (creacion)\"):\n",
    "    gen = generate_records(N)\n",
    "    size_gen = sys.getsizeof(gen)\n",
    "\n",
    "print()\n",
    "print(\"+\" + \"-\" * 42 + \"+\")\n",
    "print(f\"| {'Metodo':<20} | {'Memoria':>18} |\")\n",
    "print(\"+\" + \"-\" * 42 + \"+\")\n",
    "print(f\"| {'Lista (100K recs)':<20} | {size_lista:>14,} bytes |\")\n",
    "print(f\"| {'Generador':<20} | {size_gen:>14,} bytes |\")\n",
    "print(\"+\" + \"-\" * 42 + \"+\")\n",
    "if size_gen > 0:\n",
    "    print(f\"| {'Ratio':<20} | {size_lista / size_gen:>15.0f}x mas |\")\n",
    "    print(\"+\" + \"-\" * 42 + \"+\")\n",
    "\n",
    "# Limpiar\n",
    "del lista\n",
    "\n",
    "# --- Demo: Sliding window ---\n",
    "print()\n",
    "print(\"=== Sliding Window (ventana deslizante) ===\")\n",
    "serie_temporal = [10, 20, 30, 40, 50, 60, 70, 80]\n",
    "print(f\"Datos: {serie_temporal}\")\n",
    "print(f\"Ventanas (tamano=3):\")\n",
    "for i, ventana in enumerate(sliding_window(serie_temporal, 3)):\n",
    "    promedio = sum(ventana) / len(ventana)\n",
    "    print(f\"  Ventana {i}: {ventana} -> promedio movil: {promedio:.1f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================\n",
    "# Pipeline de Generadores: ETL encadenado\n",
    "# =============================================================\n",
    "# Cada funcion es un generador que consume del anterior.\n",
    "# Los datos fluyen registro por registro, sin cargar todo en memoria.\n",
    "\n",
    "def read_records(raw_data: list) -> Generator:\n",
    "    \"\"\"Etapa 1: Leer y limpiar registros crudos.\"\"\"\n",
    "    for line in raw_data:\n",
    "        yield line.strip()\n",
    "\n",
    "\n",
    "def filter_valid(records: Generator) -> Generator:\n",
    "    \"\"\"Etapa 2: Filtrar registros vacios y comentarios.\"\"\"\n",
    "    for r in records:\n",
    "        if r and not r.startswith(\"#\"):\n",
    "            yield r\n",
    "\n",
    "\n",
    "def parse_json_records(records: Generator) -> Generator:\n",
    "    \"\"\"Etapa 3: Parsear JSON. Omitir registros malformados.\"\"\"\n",
    "    for r in records:\n",
    "        try:\n",
    "            yield json.loads(r)\n",
    "        except json.JSONDecodeError:\n",
    "            continue  # Saltar registros invalidos\n",
    "\n",
    "\n",
    "def enrich(records: Generator) -> Generator:\n",
    "    \"\"\"Etapa 4: Enriquecer con metadata de procesamiento.\"\"\"\n",
    "    for r in records:\n",
    "        r[\"processed_at\"] = datetime.now().isoformat()\n",
    "        r[\"pipeline_version\"] = \"1.0\"\n",
    "        yield r\n",
    "\n",
    "\n",
    "# --- Datos de ejemplo (simulan lecturas de un archivo/API) ---\n",
    "\n",
    "raw_data = [\n",
    "    '  {\"user\": \"alice\", \"score\": 0.95, \"model\": \"bert\"}  ',\n",
    "    '# Este es un comentario',\n",
    "    '',\n",
    "    '{\"user\": \"bob\", \"score\": 0.82, \"model\": \"gpt-4\"}',\n",
    "    'esto no es JSON valido!!!',\n",
    "    '{\"user\": \"carol\", \"score\": 0.91, \"model\": \"bert\"}',\n",
    "    '  ',\n",
    "    '{\"user\": \"dave\", \"score\": 0.78, \"model\": \"gpt-4\"}',\n",
    "    '# Otro comentario',\n",
    "    '{\"user\": \"eve\", \"score\": 0.99, \"model\": \"claude\"}',\n",
    "]\n",
    "\n",
    "# --- Encadenar el pipeline ---\n",
    "\n",
    "print(\"=== Pipeline de Generadores ===\")\n",
    "print(f\"Registros crudos: {len(raw_data)}\")\n",
    "print()\n",
    "\n",
    "# Crear la cadena (lazy - nada se ejecuta aun!)\n",
    "pipeline = enrich(\n",
    "    parse_json_records(\n",
    "        filter_valid(\n",
    "            read_records(raw_data)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Ahora si consumimos el pipeline\n",
    "resultados = []\n",
    "for i, record in enumerate(pipeline):\n",
    "    resultados.append(record)\n",
    "    print(f\"  Registro {i + 1}: {record['user']:>6} | \"\n",
    "          f\"score={record['score']:.2f} | \"\n",
    "          f\"modelo={record['model']}\")\n",
    "\n",
    "print(f\"\\nRegistros procesados exitosamente: {len(resultados)} de {len(raw_data)}\")\n",
    "print(f\"Filtrados/invalidos: {len(raw_data) - len(resultados)}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Seccion 3: Logging Estructurado\n",
    "\n",
    "El modulo `logging` de Python es la forma estandar de registrar eventos en produccion.\n",
    "**Nunca uses `print()` en codigo de produccion.** Logging te da niveles, formato,\n",
    "destinos multiples y filtrado.\n",
    "\n",
    "### Los 5 niveles de logging\n",
    "\n",
    "```\n",
    " Nivel      | Valor | Cuando usarlo\n",
    " -----------|-------|------------------------------------------\n",
    " DEBUG      |  10   | Detalle tecnico para diagnostico\n",
    " INFO       |  20   | Confirmacion de que todo funciona bien\n",
    " WARNING    |  30   | Algo inesperado, pero el programa continua\n",
    " ERROR      |  40   | Error serio, una funcion fallo\n",
    " CRITICAL   |  50   | Error fatal, el programa no puede continuar\n",
    "```\n",
    "\n",
    "### Guia de decision\n",
    "\n",
    "```\n",
    " Quieres registrar...              --> Usa\n",
    " -------------------------------------------------------\n",
    " Valor de variables para debug     --> logger.debug()\n",
    " \"Pipeline iniciado\", \"Batch OK\"   --> logger.info()\n",
    " Dato faltante pero hay default    --> logger.warning()\n",
    " Fallo al procesar un registro     --> logger.error()\n",
    " DB caida, sin disco, OOM          --> logger.critical()\n",
    " Excepcion con traceback           --> logger.exception()\n",
    "```\n",
    "\n",
    "### Jerarquia de loggers\n",
    "\n",
    "```\n",
    "  root logger\n",
    "  +-- ml_pipeline                 (logger padre)\n",
    "  |   +-- ml_pipeline.loader      (logger hijo - hereda config)\n",
    "  |   +-- ml_pipeline.model       (logger hijo)\n",
    "  |   +-- ml_pipeline.evaluator   (logger hijo)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================\n",
    "# Logging profesional para notebooks\n",
    "# =============================================================\n",
    "# Usamos un StringIO handler para capturar la salida en el notebook.\n",
    "\n",
    "def setup_logger(name: str, level=logging.DEBUG) -> tuple:\n",
    "    \"\"\"Configura un logger que escribe a un StringIO (visible en notebook).\n",
    "    \n",
    "    Returns:\n",
    "        (logger, stream) - el logger y el stream para leer la salida\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level)\n",
    "    logger.handlers.clear()  # Evitar duplicados en re-ejecuciones\n",
    "    \n",
    "    stream = io.StringIO()\n",
    "    handler = logging.StreamHandler(stream)\n",
    "    handler.setLevel(level)\n",
    "    \n",
    "    formatter = logging.Formatter(\n",
    "        \"%(asctime)s | %(levelname)-8s | %(name)s | %(message)s\",\n",
    "        datefmt=\"%H:%M:%S\"\n",
    "    )\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    \n",
    "    return logger, stream\n",
    "\n",
    "\n",
    "# --- Demo: Los 5 niveles ---\n",
    "\n",
    "logger, stream = setup_logger(\"ml_pipeline.demo\")\n",
    "\n",
    "logger.debug(\"Cargando dataset desde /data/train.jsonl\")\n",
    "logger.info(\"Pipeline iniciado con %d registros\", 10000)  # Lazy formatting (CORRECTO)\n",
    "logger.warning(\"Campo 'label' faltante en 23 registros, usando default=0\")\n",
    "logger.error(\"Fallo al conectar con API de embeddings: timeout 30s\")\n",
    "logger.critical(\"Sin espacio en disco: /models/ esta lleno\")\n",
    "\n",
    "# Logging de excepcion (captura traceback automaticamente)\n",
    "try:\n",
    "    result = 1 / 0\n",
    "except ZeroDivisionError:\n",
    "    logger.exception(\"Error en calculo de metricas\")\n",
    "\n",
    "# Mostrar toda la salida\n",
    "print(\"=== Salida del Logger ===\")\n",
    "print(stream.getvalue())\n",
    "\n",
    "# --- Anti-patron vs patron correcto ---\n",
    "print(\"=\" * 50)\n",
    "print(\"IMPORTANTE: Lazy formatting\")\n",
    "print()\n",
    "print(\"CORRECTO (lazy - solo formatea si el nivel esta activo):\")\n",
    "print('  logger.info(\"Procesados %d de %d\", count, total)')\n",
    "print()\n",
    "print(\"INCORRECTO (f-string - siempre formatea, desperdicia CPU):\")\n",
    "print('  logger.info(f\"Procesados {count} de {total}\")  # NO!')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================\n",
    "# Logging Estructurado: Formato JSON\n",
    "# =============================================================\n",
    "# En produccion, los logs en JSON son parseables por herramientas\n",
    "# como ELK, Datadog, CloudWatch, etc.\n",
    "\n",
    "class JSONFormatter(logging.Formatter):\n",
    "    \"\"\"Formatea logs como JSON estructurado.\n",
    "    \n",
    "    Ventajas:\n",
    "    - Parseable automaticamente por herramientas de monitoreo\n",
    "    - Busquedas por campo (level=ERROR, module=loader)\n",
    "    - Alertas automaticas basadas en patrones\n",
    "    - Dashboards en tiempo real\n",
    "    \"\"\"\n",
    "    \n",
    "    def format(self, record: logging.LogRecord) -> str:\n",
    "        log_data = {\n",
    "            \"timestamp\": self.formatTime(record),\n",
    "            \"level\": record.levelname,\n",
    "            \"message\": record.getMessage(),\n",
    "            \"module\": record.module,\n",
    "            \"function\": record.funcName,\n",
    "            \"line\": record.lineno,\n",
    "        }\n",
    "        if record.exc_info and record.exc_info[0]:\n",
    "            log_data[\"exception\"] = self.formatException(record.exc_info)\n",
    "        # Campos extra personalizados\n",
    "        if hasattr(record, \"extra_data\"):\n",
    "            log_data[\"extra\"] = record.extra_data\n",
    "        return json.dumps(log_data, ensure_ascii=False)\n",
    "\n",
    "\n",
    "# --- Setup con JSON formatter ---\n",
    "\n",
    "json_logger = logging.getLogger(\"ml_pipeline.json\")\n",
    "json_logger.setLevel(logging.DEBUG)\n",
    "json_logger.handlers.clear()\n",
    "\n",
    "json_stream = io.StringIO()\n",
    "json_handler = logging.StreamHandler(json_stream)\n",
    "json_handler.setFormatter(JSONFormatter())\n",
    "json_logger.addHandler(json_handler)\n",
    "\n",
    "# --- Simular eventos de un pipeline ---\n",
    "\n",
    "json_logger.info(\"Pipeline iniciado\")\n",
    "json_logger.info(\"Cargados %d registros en %.2fs\", 50000, 1.23)\n",
    "json_logger.warning(\"Batch 42 tiene %d registros vacios\", 15)\n",
    "\n",
    "try:\n",
    "    raise ValueError(\"Score fuera de rango: -0.5\")\n",
    "except ValueError:\n",
    "    json_logger.exception(\"Error en validacion\")\n",
    "\n",
    "json_logger.info(\"Pipeline completado: %d registros procesados\", 49985)\n",
    "\n",
    "# --- Mostrar salida ---\n",
    "\n",
    "print(\"=== Logs en formato JSON ===\")\n",
    "print()\n",
    "for line in json_stream.getvalue().strip().split(\"\\n\"):\n",
    "    # Pretty print cada linea JSON\n",
    "    parsed = json.loads(line)\n",
    "    print(json.dumps(parsed, indent=2, ensure_ascii=False))\n",
    "    print()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Seccion 4: Combinando Patrones - Mini Pipeline de Produccion\n",
    "\n",
    "Ahora integramos **todos los patrones** en un pipeline realista:\n",
    "\n",
    "```\n",
    " +------------------+    +------------------+    +------------------+\n",
    " | 1. INGESTION     |    | 2. VALIDACION    |    | 3. TRANSFORMACION|\n",
    " |                  |    |                  |    |                  |\n",
    " | - Context mgr    |--->| - Excepciones    |--->| - Generadores   |\n",
    " |   (timer)        |    |   personalizadas |    |   (lazy ETL)    |\n",
    " | - Logging INFO   |    | - Logging WARN   |    | - Logging DEBUG |\n",
    " +------------------+    +------------------+    +------------------+\n",
    "          |                       |                       |\n",
    "          v                       v                       v\n",
    " +------------------+    +------------------+    +------------------+\n",
    " | 4. AGREGACION    |    | 5. REPORTE       |    | 6. CLEANUP       |\n",
    " |                  |    |                  |    |                  |\n",
    " | - Comprehensions |--->| - Estadisticas   |--->| - Context mgr   |\n",
    " | - defaultdict    |    | - Logging INFO   |    |   (temp files)  |\n",
    " +------------------+    +------------------+    +------------------+\n",
    "```\n",
    "\n",
    "### Patrones integrados\n",
    "\n",
    "- **Excepciones personalizadas**: errores con contexto y metadata\n",
    "- **Context managers**: Timer para medir cada fase, temp dirs para cleanup\n",
    "- **Generadores**: procesamiento lazy registro por registro\n",
    "- **Logging**: observabilidad en cada etapa\n",
    "- **Comprehensions**: agregacion eficiente de resultados"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================\n",
    "# Mini Pipeline de Produccion: Todos los patrones combinados\n",
    "# =============================================================\n",
    "\n",
    "# --- Excepciones personalizadas ---\n",
    "\n",
    "class PipelineError(Exception):\n",
    "    \"\"\"Error base del pipeline.\"\"\"\n",
    "    def __init__(self, message: str, stage: str, details: Optional[dict] = None):\n",
    "        super().__init__(message)\n",
    "        self.stage = stage\n",
    "        self.details = details or {}\n",
    "\n",
    "\n",
    "class ValidationError(PipelineError):\n",
    "    \"\"\"Error de validacion de datos.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class TransformError(PipelineError):\n",
    "    \"\"\"Error en la transformacion de datos.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "# --- Pipeline completo ---\n",
    "\n",
    "class DataPipeline:\n",
    "    \"\"\"Pipeline de procesamiento de datos con todos los patrones de produccion.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str = \"default\"):\n",
    "        self.name = name\n",
    "        self.stats = defaultdict(int)\n",
    "        self.timings = {}\n",
    "        \n",
    "        # Setup logger\n",
    "        self.logger = logging.getLogger(f\"pipeline.{name}\")\n",
    "        self.logger.setLevel(logging.DEBUG)\n",
    "        self.logger.handlers.clear()\n",
    "        \n",
    "        self._log_stream = io.StringIO()\n",
    "        handler = logging.StreamHandler(self._log_stream)\n",
    "        handler.setFormatter(logging.Formatter(\n",
    "            \"%(asctime)s | %(levelname)-8s | %(message)s\",\n",
    "            datefmt=\"%H:%M:%S\"\n",
    "        ))\n",
    "        self.logger.addHandler(handler)\n",
    "    \n",
    "    @contextmanager\n",
    "    def _timed_stage(self, stage_name: str):\n",
    "        \"\"\"Context manager que mide y registra el tiempo de cada etapa.\"\"\"\n",
    "        self.logger.info(\"Etapa '%s' iniciada\", stage_name)\n",
    "        start = time.perf_counter()\n",
    "        try:\n",
    "            yield\n",
    "        except PipelineError:\n",
    "            raise  # Re-lanzar errores del pipeline\n",
    "        except Exception as e:\n",
    "            self.logger.exception(\"Error inesperado en etapa '%s'\", stage_name)\n",
    "            raise PipelineError(str(e), stage=stage_name) from e\n",
    "        finally:\n",
    "            elapsed = time.perf_counter() - start\n",
    "            self.timings[stage_name] = elapsed\n",
    "            self.logger.info(\"Etapa '%s' completada en %.4fs\", stage_name, elapsed)\n",
    "    \n",
    "    def _validate(self, records: Generator) -> Generator:\n",
    "        \"\"\"Generador: valida cada registro.\"\"\"\n",
    "        for record in records:\n",
    "            self.stats[\"total\"] += 1\n",
    "            \n",
    "            # Validar campos requeridos\n",
    "            required = [\"user\", \"score\"]\n",
    "            missing = [f for f in required if f not in record]\n",
    "            if missing:\n",
    "                self.stats[\"invalid\"] += 1\n",
    "                self.logger.warning(\n",
    "                    \"Registro %d: campos faltantes %s - omitido\",\n",
    "                    self.stats[\"total\"], missing\n",
    "                )\n",
    "                continue\n",
    "            \n",
    "            # Validar rango de score\n",
    "            if not (0.0 <= record[\"score\"] <= 1.0):\n",
    "                self.stats[\"invalid\"] += 1\n",
    "                self.logger.warning(\n",
    "                    \"Registro %d: score=%.2f fuera de [0,1] - omitido\",\n",
    "                    self.stats[\"total\"], record[\"score\"]\n",
    "                )\n",
    "                continue\n",
    "            \n",
    "            self.stats[\"valid\"] += 1\n",
    "            yield record\n",
    "    \n",
    "    def _transform(self, records: Generator) -> Generator:\n",
    "        \"\"\"Generador: transforma cada registro.\"\"\"\n",
    "        for record in records:\n",
    "            record[\"score_pct\"] = round(record[\"score\"] * 100, 1)\n",
    "            record[\"category\"] = (\n",
    "                \"excelente\" if record[\"score\"] >= 0.9\n",
    "                else \"bueno\" if record[\"score\"] >= 0.7\n",
    "                else \"regular\"\n",
    "            )\n",
    "            record[\"processed_at\"] = datetime.now().isoformat()\n",
    "            self.stats[\"transformed\"] += 1\n",
    "            self.logger.debug(\"Transformado: %s -> %s\", record[\"user\"], record[\"category\"])\n",
    "            yield record\n",
    "    \n",
    "    def run(self, raw_data: list) -> list:\n",
    "        \"\"\"Ejecuta el pipeline completo.\"\"\"\n",
    "        self.logger.info(\"=\" * 50)\n",
    "        self.logger.info(\"Pipeline '%s' iniciado con %d registros crudos\", self.name, len(raw_data))\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # Etapa 1: Ingestion\n",
    "        with self._timed_stage(\"ingestion\"):\n",
    "            parsed = []\n",
    "            for line in raw_data:\n",
    "                line = line.strip()\n",
    "                if not line or line.startswith(\"#\"):\n",
    "                    self.stats[\"skipped\"] += 1\n",
    "                    continue\n",
    "                try:\n",
    "                    parsed.append(json.loads(line))\n",
    "                except json.JSONDecodeError:\n",
    "                    self.stats[\"parse_errors\"] += 1\n",
    "                    self.logger.warning(\"JSON invalido: %s\", line[:50])\n",
    "        \n",
    "        # Etapa 2: Validacion + Transformacion (generadores encadenados)\n",
    "        with self._timed_stage(\"validacion_y_transformacion\"):\n",
    "            pipeline = self._transform(self._validate(iter(parsed)))\n",
    "            results = list(pipeline)\n",
    "        \n",
    "        # Etapa 3: Agregacion\n",
    "        with self._timed_stage(\"agregacion\"):\n",
    "            por_categoria = defaultdict(list)\n",
    "            for r in results:\n",
    "                por_categoria[r[\"category\"]].append(r[\"user\"])\n",
    "            \n",
    "            self.stats[\"output\"] = len(results)\n",
    "            for cat, users in por_categoria.items():\n",
    "                self.logger.info(\"Categoria '%s': %d registros\", cat, len(users))\n",
    "        \n",
    "        # Reporte final\n",
    "        self.logger.info(\"=\" * 50)\n",
    "        self.logger.info(\"PIPELINE COMPLETADO\")\n",
    "        for key, val in sorted(self.stats.items()):\n",
    "            self.logger.info(\"  %-20s: %d\", key, val)\n",
    "        \n",
    "        total_time = sum(self.timings.values())\n",
    "        self.logger.info(\"  %-20s: %.4fs\", \"TIEMPO_TOTAL\", total_time)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_logs(self) -> str:\n",
    "        \"\"\"Retorna todos los logs generados.\"\"\"\n",
    "        return self._log_stream.getvalue()\n",
    "\n",
    "\n",
    "# --- Ejecutar con datos de ejemplo ---\n",
    "\n",
    "sample_data = [\n",
    "    '{\"user\": \"alice\", \"score\": 0.95, \"model\": \"bert\"}',\n",
    "    '{\"user\": \"bob\", \"score\": 0.82, \"model\": \"gpt-4\"}',\n",
    "    '# Comentario ignorado',\n",
    "    '',\n",
    "    '{\"user\": \"carol\", \"score\": 0.91, \"model\": \"bert\"}',\n",
    "    'esto no es JSON',\n",
    "    '{\"user\": \"dave\", \"score\": 1.5, \"model\": \"gpt-4\"}',\n",
    "    '{\"user\": \"eve\", \"score\": 0.99, \"model\": \"claude\"}',\n",
    "    '{\"score\": 0.50}',\n",
    "    '{\"user\": \"frank\", \"score\": 0.65, \"model\": \"bert\"}',\n",
    "    '{\"user\": \"grace\", \"score\": 0.88, \"model\": \"claude\"}',\n",
    "    '{\"user\": \"hank\", \"score\": -0.1, \"model\": \"gpt-4\"}',\n",
    "]\n",
    "\n",
    "pipeline = DataPipeline(name=\"evaluacion_modelos\")\n",
    "results = pipeline.run(sample_data)\n",
    "\n",
    "print(\"=== LOG COMPLETO DEL PIPELINE ===\")\n",
    "print(pipeline.get_logs())\n",
    "\n",
    "print(\"=== RESULTADOS ===\")\n",
    "for r in results:\n",
    "    print(f\"  {r['user']:>8} | score={r['score_pct']:>5}% | {r['category']}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================\n",
    "# Pipeline manejando errores criticos\n",
    "# =============================================================\n",
    "# Demostrar como el pipeline maneja datos problematicos de forma\n",
    "# elegante: warnings para errores recuperables, excepciones para criticos.\n",
    "\n",
    "print(\"=== Caso 1: Errores recuperables (el pipeline continua) ===\")\n",
    "print()\n",
    "\n",
    "datos_mixtos = [\n",
    "    '{\"user\": \"ok_user\", \"score\": 0.85}',       # OK\n",
    "    '{malformado!!!}',                              # Parse error (warning)\n",
    "    '{\"user\": \"sin_score\"}',                       # Validacion falla (warning)\n",
    "    '{\"user\": \"score_malo\", \"score\": 999}',       # Score fuera de rango (warning)\n",
    "    '{\"user\": \"otro_ok\", \"score\": 0.72}',         # OK\n",
    "]\n",
    "\n",
    "p1 = DataPipeline(name=\"test_recuperable\")\n",
    "resultados = p1.run(datos_mixtos)\n",
    "print(p1.get_logs())\n",
    "print(f\"Resultado: {len(resultados)} registros procesados de {len(datos_mixtos)} crudos\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "print(\"=== Caso 2: Error critico en una etapa (pipeline se detiene limpiamente) ===\")\n",
    "print()\n",
    "\n",
    "class StrictPipeline(DataPipeline):\n",
    "    \"\"\"Pipeline que falla si hay demasiados errores.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, max_error_rate: float = 0.5):\n",
    "        super().__init__(name)\n",
    "        self.max_error_rate = max_error_rate\n",
    "    \n",
    "    def run(self, raw_data: list) -> list:\n",
    "        \"\"\"Ejecuta y verifica tasa de error.\"\"\"\n",
    "        results = super().run(raw_data)\n",
    "        \n",
    "        total = self.stats.get(\"total\", 0)\n",
    "        invalid = self.stats.get(\"invalid\", 0)\n",
    "        \n",
    "        if total > 0:\n",
    "            error_rate = invalid / total\n",
    "            if error_rate > self.max_error_rate:\n",
    "                raise ValidationError(\n",
    "                    f\"Tasa de error {error_rate:.0%} excede limite {self.max_error_rate:.0%}\",\n",
    "                    stage=\"post_validacion\",\n",
    "                    details={\"error_rate\": error_rate, \"total\": total, \"invalid\": invalid}\n",
    "                )\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "# Datos donde la mayoria son invalidos\n",
    "datos_malos = [\n",
    "    '{\"user\": \"unico_bueno\", \"score\": 0.9}',\n",
    "    '{\"sin_campos\": true}',\n",
    "    '{\"user\": \"x\", \"score\": -5}',\n",
    "    '{\"user\": \"y\", \"score\": 100}',\n",
    "    '{\"otra_cosa\": 123}',\n",
    "]\n",
    "\n",
    "p2 = StrictPipeline(name=\"test_critico\", max_error_rate=0.5)\n",
    "\n",
    "try:\n",
    "    resultados = p2.run(datos_malos)\n",
    "except ValidationError as e:\n",
    "    print(p2.get_logs())\n",
    "    print(f\"EXCEPCION CAPTURADA:\")\n",
    "    print(f\"  Tipo:     {type(e).__name__}\")\n",
    "    print(f\"  Mensaje:  {e}\")\n",
    "    print(f\"  Etapa:    {e.stage}\")\n",
    "    print(f\"  Detalles: {e.details}\")\n",
    "    print()\n",
    "    print(\"El pipeline se detuvo limpiamente con toda la informacion necesaria.\")\n",
    "    print(\"Los timings y logs ya estan registrados para diagnostico.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cuando usar cada patron\n",
    "\n",
    "| Situacion | Patron | Ejemplo concreto |\n",
    "|-----------|--------|------------------|\n",
    "| Recurso que necesita cleanup | **Context Manager** | Conexiones DB, archivos temporales, timers, locks |\n",
    "| Datos grandes o streaming | **Generador** | Archivos de log, paginacion de API, batches de training |\n",
    "| Observabilidad en produccion | **Logging** | Cada modulo, cada error, eventos clave del pipeline |\n",
    "| Errores con contexto | **Excepciones personalizadas** | Errores de dominio con metadata (stage, details) |\n",
    "| Transformacion de colecciones | **Comprehensions** | Filtrado, mapeo, agregacion de datos |\n",
    "\n",
    "### Reglas de oro\n",
    "\n",
    "1. **Si adquieres un recurso, usa `with`** - nunca confies en que tu codigo llegara al `close()`\n",
    "2. **Si procesas muchos datos, usa `yield`** - la memoria es finita, los generadores no\n",
    "3. **Si esta en produccion, usa `logging`** - `print()` es para notebooks, no para servidores\n",
    "4. **Si el error tiene contexto, crea una excepcion** - `ValueError` no dice que paso ni donde\n",
    "5. **Si combinas patrones, hazlo en capas** - cada capa tiene una responsabilidad clara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejercicios\n",
    "\n",
    "Completa los siguientes ejercicios para practicar los patrones de produccion.\n",
    "Cada ejercicio indica que patrones debes usar."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================\n",
    "# EJERCICIO 1: Context Manager - DatabaseConnection\n",
    "# =============================================================\n",
    "#\n",
    "# Crea un context manager (basado en clase) llamado DatabaseConnection que:\n",
    "#\n",
    "# 1. __init__: recibe host (str) y database (str)\n",
    "# 2. __enter__: \n",
    "#    - Simula conectar (print \"Conectando a {host}/{database}\")\n",
    "#    - Inicializa una lista self.operations = [] para rastrear operaciones\n",
    "#    - Retorna self\n",
    "# 3. Metodo execute(query): agrega el query a self.operations\n",
    "# 4. __exit__:\n",
    "#    - Si NO hubo excepcion: print \"COMMIT: {n} operaciones\"\n",
    "#    - Si SI hubo excepcion: print \"ROLLBACK por: {tipo_error}\"\n",
    "#    - Siempre: print \"Desconectando de {host}/{database}\"\n",
    "#    - Retorna False (no suprimir excepciones)\n",
    "#\n",
    "# Prueba con:\n",
    "#   with DatabaseConnection(\"localhost\", \"ml_models\") as db:\n",
    "#       db.execute(\"INSERT INTO results VALUES (0.95, 'bert')\")\n",
    "#       db.execute(\"UPDATE models SET status='active'\")\n",
    "#   # Deberia mostrar COMMIT\n",
    "#\n",
    "#   with DatabaseConnection(\"localhost\", \"ml_models\") as db:\n",
    "#       db.execute(\"INSERT INTO results VALUES (0.8, 'gpt')\")\n",
    "#       raise ValueError(\"Score invalido\")\n",
    "#   # Deberia mostrar ROLLBACK\n",
    "\n",
    "class DatabaseConnection:\n",
    "    pass\n",
    "\n",
    "\n",
    "# Descomenta para probar:\n",
    "# with DatabaseConnection(\"localhost\", \"ml_models\") as db:\n",
    "#     db.execute(\"INSERT INTO results VALUES (0.95, 'bert')\")\n",
    "#     db.execute(\"UPDATE models SET status='active'\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================\n",
    "# EJERCICIO 2: Pipeline de Generadores con Logging\n",
    "# =============================================================\n",
    "#\n",
    "# Crea un pipeline de generadores para procesar predicciones de un modelo.\n",
    "# Cada funcion debe ser un generador (usar yield).\n",
    "#\n",
    "# Funciones a implementar:\n",
    "#\n",
    "# 1. leer_predicciones(datos: list) -> Generator:\n",
    "#    - Recibe una lista de strings JSON\n",
    "#    - Parsea cada uno con json.loads\n",
    "#    - Si falla el parseo, loguea WARNING y continua\n",
    "#    - Yield de cada dict parseado\n",
    "#\n",
    "# 2. filtrar_confianza(preds: Generator, umbral: float = 0.8) -> Generator:\n",
    "#    - Solo yield de predicciones donde pred[\"confidence\"] >= umbral\n",
    "#    - Loguea DEBUG para cada prediccion filtrada\n",
    "#\n",
    "# 3. agrupar_por_batch(preds: Generator, batch_size: int = 3) -> Generator:\n",
    "#    - Acumula predicciones en batches de tamano batch_size\n",
    "#    - Yield de cada batch (lista)\n",
    "#    - No olvidar el ultimo batch si es mas pequeno\n",
    "#\n",
    "# Datos de prueba:\n",
    "datos_predicciones = [\n",
    "    '{\"id\": 1, \"label\": \"gato\", \"confidence\": 0.95}',\n",
    "    '{\"id\": 2, \"label\": \"perro\", \"confidence\": 0.60}',\n",
    "    '{\"id\": 3, \"label\": \"gato\", \"confidence\": 0.88}',\n",
    "    '{INVALIDO}',\n",
    "    '{\"id\": 5, \"label\": \"pajaro\", \"confidence\": 0.92}',\n",
    "    '{\"id\": 6, \"label\": \"perro\", \"confidence\": 0.45}',\n",
    "    '{\"id\": 7, \"label\": \"gato\", \"confidence\": 0.99}',\n",
    "    '{\"id\": 8, \"label\": \"pajaro\", \"confidence\": 0.81}',\n",
    "]\n",
    "#\n",
    "# Encadenar: leer -> filtrar -> agrupar\n",
    "# Imprimir cada batch resultante.\n",
    "\n",
    "def leer_predicciones(datos: list) -> Generator:\n",
    "    pass\n",
    "\n",
    "\n",
    "def filtrar_confianza(preds, umbral: float = 0.8) -> Generator:\n",
    "    pass\n",
    "\n",
    "\n",
    "def agrupar_por_batch(preds, batch_size: int = 3) -> Generator:\n",
    "    pass\n",
    "\n",
    "\n",
    "# Descomenta para probar:\n",
    "# pipeline = agrupar_por_batch(filtrar_confianza(leer_predicciones(datos_predicciones)))\n",
    "# for batch in pipeline:\n",
    "#     print(f\"Batch: {batch}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================\n",
    "# EJERCICIO 3: Mini-ETL Completo (todos los patrones)\n",
    "# =============================================================\n",
    "#\n",
    "# Construye un mini pipeline ETL que combine TODOS los patrones:\n",
    "#\n",
    "# Clase: MLExperimentPipeline\n",
    "#\n",
    "# __init__(self, experiment_name: str):\n",
    "#   - Configurar logger con nombre \"experiment.{experiment_name}\"\n",
    "#   - Inicializar self.timings = {} y self.stats = defaultdict(int)\n",
    "#\n",
    "# Metodo context manager (con @contextmanager):\n",
    "#   timed_phase(self, phase_name: str):\n",
    "#   - Mide tiempo de cada fase\n",
    "#   - Loguea inicio y fin con tiempo\n",
    "#   - Guarda timing en self.timings\n",
    "#\n",
    "# Generador:\n",
    "#   process_results(self, raw_results: list) -> Generator:\n",
    "#   - Parsea JSON, valida campos (\"model\", \"accuracy\", \"dataset\")\n",
    "#   - Filtra accuracy < 0 o > 1\n",
    "#   - Enriquece con timestamp y experiment_name\n",
    "#   - Loguea cada paso, cuenta stats\n",
    "#\n",
    "# Metodo principal:\n",
    "#   run(self, raw_data: list) -> dict:\n",
    "#   - Fase \"ingestion\": parsear datos con timed_phase\n",
    "#   - Fase \"processing\": usar generador con timed_phase\n",
    "#   - Fase \"analysis\": calcular mejor modelo, promedio por modelo\n",
    "#   - Retorna dict con \"results\", \"stats\", \"timings\", \"best_model\"\n",
    "#\n",
    "# Datos de prueba:\n",
    "datos_experimento = [\n",
    "    '{\"model\": \"bert\", \"accuracy\": 0.92, \"dataset\": \"squad\"}',\n",
    "    '{\"model\": \"gpt-4\", \"accuracy\": 0.95, \"dataset\": \"squad\"}',\n",
    "    '{\"model\": \"bert\", \"accuracy\": 0.88, \"dataset\": \"mnli\"}',\n",
    "    '{INVALIDO}',\n",
    "    '{\"model\": \"claude\", \"accuracy\": 0.97, \"dataset\": \"squad\"}',\n",
    "    '{\"model\": \"gpt-4\", \"accuracy\": 1.5, \"dataset\": \"error\"}',\n",
    "    '{\"model\": \"claude\", \"accuracy\": 0.93, \"dataset\": \"mnli\"}',\n",
    "]\n",
    "\n",
    "class MLExperimentPipeline:\n",
    "    pass\n",
    "\n",
    "\n",
    "# Descomenta para probar:\n",
    "# exp = MLExperimentPipeline(\"benchmark_q1_2026\")\n",
    "# report = exp.run(datos_experimento)\n",
    "# print(f\"Mejor modelo: {report['best_model']}\")\n",
    "# print(f\"Timings: {report['timings']}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Checklist de Consolidacion\n",
    "\n",
    "Marca cada item cuando lo hayas comprendido y puedas implementarlo sin mirar ejemplos:\n",
    "\n",
    "- [ ] **Context managers con clase**: implementar `__enter__` y `__exit__`, saber que `__exit__` recibe info de excepcion\n",
    "- [ ] **Context managers con `@contextmanager`**: usar `yield` en un bloque `try/finally`, saber cuando preferir este enfoque\n",
    "- [ ] **Generadores con `yield`**: crear funciones generadoras, entender lazy evaluation y ahorro de memoria\n",
    "- [ ] **Encadenar generadores**: construir pipelines donde cada generador consume del anterior\n",
    "- [ ] **`batch_iterator`**: dividir datos en batches para procesamiento por lotes\n",
    "- [ ] **Logging con niveles**: usar DEBUG/INFO/WARNING/ERROR/CRITICAL apropiadamente\n",
    "- [ ] **Lazy formatting en logging**: usar `%s` y `%d` en lugar de f-strings\n",
    "- [ ] **JSON formatter**: crear logs estructurados parseables por herramientas de monitoreo\n",
    "- [ ] **Excepciones personalizadas**: crear jerarquias con metadata (stage, details)\n",
    "- [ ] **Combinar patrones**: integrar context managers + generadores + logging + excepciones en un pipeline\n",
    "\n",
    "---\n",
    "\n",
    "### Resumen de la serie Python Extra Class (7 notebooks)\n",
    "\n",
    "| Notebook | Tema | Patron clave |\n",
    "|----------|------|--------------|\n",
    "| 01 | Fundamentos de Python para AI | Tipos, funciones, estructuras |\n",
    "| 02 | Estructuras de datos avanzadas | Listas, dicts, sets, comprehensions |\n",
    "| 03 | Programacion orientada a objetos | Clases, herencia, polimorfismo |\n",
    "| 04 | Manejo de archivos y datos | I/O, JSON, CSV, paths |\n",
    "| 05 | Testing y debugging | unittest, assert, pdb |\n",
    "| 06 | Concurrencia basica | threading, asyncio |\n",
    "| **07** | **Patrones de produccion** | **Context managers, generadores, logging, pipelines** |\n",
    "\n",
    "---\n",
    "\n",
    "**Con estos patrones, estas listo para construir pipelines de AI/ML robustos y mantenibles.**\n",
    "\n",
    "Los mismos patrones que usamos aqui son los que encontraras en frameworks como:\n",
    "- **LangChain**: context managers para callbacks, generadores para streaming\n",
    "- **PyTorch**: DataLoader usa generadores, logging integrado\n",
    "- **FastAPI**: context managers para lifespan, excepciones HTTP personalizadas\n",
    "- **MLflow**: context managers para tracking de experimentos\n",
    "\n",
    "Dominar estos fundamentos te permitira aprender cualquier framework rapidamente\n",
    "porque ya entiendes los patrones subyacentes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}