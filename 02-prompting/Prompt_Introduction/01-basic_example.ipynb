{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4238cef9",
   "metadata": {},
   "source": [
    "## Introducción al diseño de estrategias de prompting\n",
    "\n",
    "* Institución : Henry\n",
    "* Objetivo : Dar un roadmap que permita entender y abstraer como crear prompts, darles Rol, tareas, contexto y funcionalidad de manera estructurada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85c36848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias necesarias para el proyecto \n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from enum import Enum\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3029036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargando las variables de entorno \n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "986be547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diseñando una Clase para manejar diferentes tipos de modelos \n",
    "# Nos enfocaremos en OpenAI\n",
    "\n",
    "class OpenAIModels(str,Enum): # Str -> Para que los valores sean cadenas de texto # Enum -> Para crear una enumeración\n",
    "    GPT_4o = \"gpt-4o\"\n",
    "    GPT_4o_mini = \"gpt-4o-mini\"\n",
    "    GPT_5_mini = \"gpt-5-mini\"\n",
    "\n",
    "MODEL = OpenAIModels.GPT_5_mini # Seleccionando el modelo a utilizar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3345519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una funcion wrapper para tener el llamado de OPenAI y sus componentes orquestados \n",
    "\n",
    "def get_completion(system_prompt, # Define el comportamiento del modelo\n",
    "                   user_prompt,  # Es ;la solicitud del usuario\n",
    "                   model=MODEL):\n",
    "\n",
    "    # Construcción de los mensajes \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "    if system_prompt is not None:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            *messages,\n",
    "        ]\n",
    "    try:\n",
    "        # LLamado a la API de OpenAI\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=None, # Controla la creatividad de las respuestas\n",
    "        )\n",
    "        return response.choices[0].message.content # DEvuelve solo el cuerpo de la respuesta , no toda la metadata\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "774b1756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_responses(*args):\n",
    "    \"\"\"AYuda visual en formato markdown para comparar los modelos.\"\"\"\n",
    "    markdown_string = \"<table><tr>\"\n",
    "    for arg in args:\n",
    "        markdown_string += f\"<th>System Prompt:<br />{arg['system_prompt']}<br /><br />\"\n",
    "        markdown_string += f\"User Prompt:<br />{arg['user_prompt']}</th>\"\n",
    "    markdown_string += \"</tr>\"\n",
    "    markdown_string += \"<tr>\"\n",
    "    for arg in args:\n",
    "        markdown_string += f\"<td>Response:<br />{arg['response']}</td>\"\n",
    "    markdown_string += \"</tr></table>\"\n",
    "    display(Markdown(markdown_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae414753",
   "metadata": {},
   "source": [
    "### Estrategias y comparativas de Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b298216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Enviar solicitud al modelo:  OpenAIModels.GPT_5_mini\n",
      "================================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<table><tr><th>System Prompt:<br />Eres un asistente útil y creativo , en temas de coqueteo y relaciones amorosas respetuosas.<br /><br />User Prompt:<br />Escribe un mensaje coqueto para invitar a salir a alguien que te gusta.</th></tr><tr><td>Response:<br />An error occurred: Error code: 400 - {'error': {'message': \"Unsupported value: 'temperature' does not support 0.2 with this model. Only the default (1) value is supported.\", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_prompt = \"Eres un asistente útil y creativo , en temas de coqueteo y relaciones amorosas respetuosas.\"\n",
    "user_prompt = \"Escribe un mensaje coqueto para invitar a salir a alguien que te gusta.\"\n",
    "\n",
    "print('=='*32)\n",
    "print(f'Enviar solicitud al modelo:  {MODEL}')\n",
    "baseline_response = get_completion(system_prompt, user_prompt)\n",
    "print('=='*32)\n",
    "display_responses({\n",
    "    \"system_prompt\": system_prompt,\n",
    "    \"user_prompt\": user_prompt, \n",
    "    \"response\": baseline_response\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e7aac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eff5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brief-ai-vs-software-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
