{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 — Workflows vs Agentes\n",
    "\n",
    "**Objetivo**: Comparar el patron workflow (lineal, predecible) con el patron agente (dinamico, autonomo) y entender cuando usar cada uno.\n",
    "\n",
    "## Contenido\n",
    "1. Workflow lineal: translate → summarize → format\n",
    "2. Agente dinamico con tool calling\n",
    "3. Comparacion side-by-side\n",
    "4. Taxonomia de Anthropic (6 patrones)\n",
    "5. Arbol de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "MODEL = \"gpt-5-mini\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"WORKFLOWS vs AGENTES\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Workflow Lineal (Prompt Chaining)\n",
    "\n",
    "Un workflow es una secuencia fija de pasos. Cada paso recibe la salida del anterior.\n",
    "\n",
    "```\n",
    "Input → [Traducir] → [Resumir] → [Formatear] → Output\n",
    "```\n",
    "\n",
    "Ventajas: predecible, debuggeable, costo fijo.\n",
    "Desventaja: no se adapta a inputs variados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# WORKFLOW LINEAL: Translate → Summarize → Format\n",
    "# ============================================================\n",
    "\n",
    "def workflow_lineal(texto: str) -> dict:\n",
    "    \"\"\"\n",
    "    Pipeline lineal de 3 pasos.\n",
    "\n",
    "    Args:\n",
    "        texto: Texto de entrada en cualquier idioma.\n",
    "\n",
    "    Returns:\n",
    "        Dict con resultado de cada paso y metricas.\n",
    "    \"\"\"\n",
    "    pasos = []\n",
    "    total_tokens = 0\n",
    "    t_start = time.time()\n",
    "\n",
    "    # Paso 1: Traducir a español\n",
    "    r1 = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Traduce el siguiente texto al español. Solo devuelve la traduccion.\"},\n",
    "            {\"role\": \"user\", \"content\": texto}\n",
    "        ],\n",
    "    )\n",
    "    traduccion = r1.choices[0].message.content\n",
    "    total_tokens += r1.usage.total_tokens\n",
    "    pasos.append({\"paso\": \"traducir\", \"resultado\": traduccion})\n",
    "\n",
    "    # Paso 2: Resumir\n",
    "    r2 = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Resume el siguiente texto en 2-3 oraciones. Solo devuelve el resumen.\"},\n",
    "            {\"role\": \"user\", \"content\": traduccion}\n",
    "        ],\n",
    "    )\n",
    "    resumen = r2.choices[0].message.content\n",
    "    total_tokens += r2.usage.total_tokens\n",
    "    pasos.append({\"paso\": \"resumir\", \"resultado\": resumen})\n",
    "\n",
    "    # Paso 3: Formatear\n",
    "    r3 = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Formatea el siguiente texto como bullet points en markdown. Solo devuelve los bullet points.\"},\n",
    "            {\"role\": \"user\", \"content\": resumen}\n",
    "        ],\n",
    "    )\n",
    "    formateado = r3.choices[0].message.content\n",
    "    total_tokens += r3.usage.total_tokens\n",
    "    pasos.append({\"paso\": \"formatear\", \"resultado\": formateado})\n",
    "\n",
    "    latencia_ms = (time.time() - t_start) * 1000\n",
    "    costo = total_tokens * 0.375 / 1_000_000  # promedio input/output\n",
    "\n",
    "    return {\n",
    "        \"tipo\": \"workflow\",\n",
    "        \"pasos\": pasos,\n",
    "        \"resultado_final\": formateado,\n",
    "        \"metricas\": {\n",
    "            \"num_pasos\": 3,\n",
    "            \"total_tokens\": total_tokens,\n",
    "            \"latencia_ms\": round(latencia_ms, 1),\n",
    "            \"costo_usd\": round(costo, 6),\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "texto_prueba = \"\"\"\n",
    "Artificial intelligence agents represent a paradigm shift in how we build software.\n",
    "Instead of hardcoding every decision path, we let a language model decide what to do next.\n",
    "This introduces both flexibility and unpredictability.\n",
    "The key challenge is balancing autonomy with control.\n",
    "\"\"\"\n",
    "\n",
    "resultado_wf = workflow_lineal(texto_prueba)\n",
    "\n",
    "print(\"WORKFLOW LINEAL — Resultados:\")\n",
    "for paso in resultado_wf[\"pasos\"]:\n",
    "    print(f\"\\n  [{paso['paso'].upper()}]\")\n",
    "    print(f\"  {paso['resultado'][:150]}\")\n",
    "\n",
    "print(f\"\\nMetricas: {resultado_wf['metricas']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Agente Dinamico\n",
    "\n",
    "El agente recibe el mismo input pero decide autonomamente que pasos tomar.\n",
    "Puede traducir, resumir, formatear, o hacer algo completamente diferente segun el input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# AGENTE DINAMICO con herramientas\n",
    "# ============================================================\n",
    "\n",
    "AGENT_TOOLS = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"traducir\",\n",
    "            \"description\": \"Traduce texto al español.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\"texto\": {\"type\": \"string\", \"description\": \"Texto a traducir\"}},\n",
    "                \"required\": [\"texto\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"resumir\",\n",
    "            \"description\": \"Resume texto en 2-3 oraciones.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\"texto\": {\"type\": \"string\", \"description\": \"Texto a resumir\"}},\n",
    "                \"required\": [\"texto\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"formatear_bullets\",\n",
    "            \"description\": \"Formatea texto como bullet points en markdown.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\"texto\": {\"type\": \"string\", \"description\": \"Texto a formatear\"}},\n",
    "                \"required\": [\"texto\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "def ejecutar_tool(name: str, args: dict) -> str:\n",
    "    \"\"\"Ejecuta herramientas del agente via LLM.\"\"\"\n",
    "    prompts = {\n",
    "        \"traducir\": \"Traduce al español. Solo la traduccion:\",\n",
    "        \"resumir\": \"Resume en 2-3 oraciones. Solo el resumen:\",\n",
    "        \"formatear_bullets\": \"Formatea como bullet points markdown. Solo los bullets:\",\n",
    "    }\n",
    "    r = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompts[name]},\n",
    "            {\"role\": \"user\", \"content\": args[\"texto\"]}\n",
    "        ],\n",
    "    )\n",
    "    return r.choices[0].message.content, r.usage.total_tokens\n",
    "\n",
    "\n",
    "def agente_dinamico(texto: str, max_steps: int = 6) -> dict:\n",
    "    \"\"\"\n",
    "    Agente que decide autonomamente que herramientas usar.\n",
    "\n",
    "    Args:\n",
    "        texto: Input del usuario.\n",
    "        max_steps: Maximo de iteraciones.\n",
    "\n",
    "    Returns:\n",
    "        Dict con resultado y metricas.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Eres un asistente. Procesa el texto del usuario: traducelo al español, resumelo, y formatealo como bullets. Usa las herramientas disponibles. Responde en español.\"},\n",
    "        {\"role\": \"user\", \"content\": texto},\n",
    "    ]\n",
    "\n",
    "    pasos = []\n",
    "    total_tokens = 0\n",
    "    t_start = time.time()\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL, messages=messages, tools=AGENT_TOOLS, tool_choice=\"auto\",\n",
    "        )\n",
    "        msg = response.choices[0].message\n",
    "        total_tokens += response.usage.total_tokens\n",
    "\n",
    "        if not msg.tool_calls:\n",
    "            pasos.append({\"paso\": f\"respuesta_final\", \"resultado\": msg.content})\n",
    "            break\n",
    "\n",
    "        messages.append(msg)\n",
    "        for tc in msg.tool_calls:\n",
    "            fn_name = tc.function.name\n",
    "            fn_args = json.loads(tc.function.arguments)\n",
    "            resultado_tool, tokens_tool = ejecutar_tool(fn_name, fn_args)\n",
    "            total_tokens += tokens_tool\n",
    "            pasos.append({\"paso\": fn_name, \"resultado\": resultado_tool[:200]})\n",
    "            messages.append({\"role\": \"tool\", \"tool_call_id\": tc.id, \"content\": resultado_tool})\n",
    "\n",
    "    latencia_ms = (time.time() - t_start) * 1000\n",
    "    costo = total_tokens * 0.375 / 1_000_000\n",
    "\n",
    "    return {\n",
    "        \"tipo\": \"agente\",\n",
    "        \"pasos\": pasos,\n",
    "        \"resultado_final\": pasos[-1][\"resultado\"] if pasos else \"Sin resultado\",\n",
    "        \"metricas\": {\n",
    "            \"num_pasos\": len(pasos),\n",
    "            \"total_tokens\": total_tokens,\n",
    "            \"latencia_ms\": round(latencia_ms, 1),\n",
    "            \"costo_usd\": round(costo, 6),\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "resultado_ag = agente_dinamico(texto_prueba)\n",
    "\n",
    "print(\"AGENTE DINAMICO — Resultados:\")\n",
    "for paso in resultado_ag[\"pasos\"]:\n",
    "    print(f\"\\n  [{paso['paso'].upper()}]\")\n",
    "    print(f\"  {paso['resultado'][:150]}\")\n",
    "\n",
    "print(f\"\\nMetricas: {resultado_ag['metricas']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparacion Side-by-Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comparacion = pd.DataFrame([\n",
    "    {\n",
    "        \"Tipo\": r[\"tipo\"],\n",
    "        \"Pasos\": r[\"metricas\"][\"num_pasos\"],\n",
    "        \"Tokens\": r[\"metricas\"][\"total_tokens\"],\n",
    "        \"Latencia (ms)\": r[\"metricas\"][\"latencia_ms\"],\n",
    "        \"Costo (USD)\": f\"${r['metricas']['costo_usd']:.6f}\",\n",
    "        \"Predecible\": \"Si\" if r[\"tipo\"] == \"workflow\" else \"No\",\n",
    "    }\n",
    "    for r in [resultado_wf, resultado_ag]\n",
    "])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARACION: WORKFLOW vs AGENTE\")\n",
    "print(\"=\" * 60)\n",
    "print(comparacion.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Taxonomia de Patrones (Anthropic)\n",
    "\n",
    "Anthropic define 6 patrones de sistemas con LLMs, ordenados de menor a mayor autonomia:\n",
    "\n",
    "| Patron | Descripcion | Autonomia | Ejemplo |\n",
    "|--------|-------------|-----------|--------|\n",
    "| **Prompt Chaining** | Pasos fijos secuenciales | Baja | Traducir → Resumir → Formatear |\n",
    "| **Routing** | Clasificar input y dirigir a especialista | Baja-Media | Ticket → soporte tecnico o ventas |\n",
    "| **Parallelization** | Ejecutar multiples tareas simultaneas | Media | Analizar sentimiento + extraer entidades |\n",
    "| **Orchestrator-Workers** | Un LLM descompone y delega | Media-Alta | \"Investiga X\" → buscar, leer, sintetizar |\n",
    "| **Evaluator-Optimizer** | Generar + evaluar + mejorar | Alta | Generar codigo → testear → corregir |\n",
    "| **Autonomous Agent** | Loop abierto con herramientas | Muy Alta | Agente de investigacion autonomo |\n",
    "\n",
    "### Regla practica\n",
    "> **Usa workflows cuando el camino es conocido. Usa agentes cuando el camino depende del input.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Arbol de Decision\n",
    "\n",
    "```\n",
    "¿El flujo es siempre el mismo?\n",
    "├── SI → Workflow (Prompt Chaining)\n",
    "│   ¿Hay pasos paralelizables?\n",
    "│   ├── SI → Parallelization\n",
    "│   └── NO → Chaining puro\n",
    "│\n",
    "└── NO → ¿Cuantas rutas posibles?\n",
    "    ├── Pocas (2-5) → Routing\n",
    "    └── Muchas/Desconocidas → ¿Necesita auto-correccion?\n",
    "        ├── SI → Evaluator-Optimizer\n",
    "        └── NO → ¿Subtareas independientes?\n",
    "            ├── SI → Orchestrator-Workers\n",
    "            └── NO → Autonomous Agent\n",
    "```\n",
    "\n",
    "### Takeaways\n",
    "1. La mayoria de problemas reales se resuelven con **workflows** (70-80% de los casos)\n",
    "2. Los agentes autonomos son poderosos pero mas caros, lentos e impredecibles\n",
    "3. Empezar con el patron mas simple y escalar solo si es necesario\n",
    "4. El costo de un agente es O(n) en numero de pasos; un workflow es O(1) fijo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}