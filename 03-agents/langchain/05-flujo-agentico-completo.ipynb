{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# 05 — Flujo Agentico Completo\n",
    "\n",
    "**Objetivo**: Construir un agente completo \"Experto en Comics\" con 4 herramientas, router, especialistas, y validador. Multi-step reasoning con trazabilidad completa.\n",
    "\n",
    "## Contenido\n",
    "1. Herramientas del agente\n",
    "2. Arquitectura completa del grafo\n",
    "3. Multi-step reasoning demo\n",
    "4. Trazabilidad: cada nodo, tool, costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import TypedDict, Annotated, Literal\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from pydantic import BaseModel, Field\n",
    "import chromadb\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-5-mini\", temperature=0)\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FLUJO AGENTICO COMPLETO — Experto en Comics\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SETUP: Cargar datos en ChromaDB\n",
    "# ============================================================\n",
    "\n",
    "def cargar_comics(ruta: str) -> list[dict]:\n",
    "    with open(ruta) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "batman_comics = cargar_comics(\"../data/batman_comics.json\")\n",
    "spider_comics = cargar_comics(\"../data/spiderman_comics.json\")\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "# Crear colecciones separadas por personaje\n",
    "for personaje, comics in [(\"batman\", batman_comics), (\"spiderman\", spider_comics)]:\n",
    "    chunks, metas = [], []\n",
    "    for comic in comics:\n",
    "        for i, chunk in enumerate(splitter.split_text(comic[\"contenido\"])):\n",
    "            chunks.append(chunk)\n",
    "            metas.append({\"personaje\": personaje, \"arco\": comic[\"arco\"], \"tema\": comic[\"tema\"], \"titulo\": comic[\"titulo\"], \"doc_id\": comic[\"id\"]})\n",
    "    \n",
    "    embs = embeddings_model.embed_documents(chunks)\n",
    "    col = chroma_client.create_collection(name=f\"comics_{personaje}\", metadata={\"hnsw:space\": \"cosine\"})\n",
    "    col.add(ids=[f\"{personaje}_{i}\" for i in range(len(chunks))], embeddings=embs, documents=chunks, metadatas=metas)\n",
    "    print(f\"Coleccion comics_{personaje}: {col.count()} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7",
   "metadata": {},
   "source": [
    "## 1. Herramientas del Agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# HERRAMIENTAS DEL AGENTE\n",
    "# ============================================================\n",
    "\n",
    "@tool\n",
    "def buscar_batman(query: str) -> str:\n",
    "    \"\"\"Busca informacion sobre Batman en la base de datos de comics.\n",
    "    \n",
    "    Args:\n",
    "        query: Pregunta o tema a buscar sobre Batman.\n",
    "    \"\"\"\n",
    "    col = chroma_client.get_collection(\"comics_batman\")\n",
    "    emb = embeddings_model.embed_query(query)\n",
    "    results = col.query(query_embeddings=[emb], n_results=3, include=[\"documents\", \"metadatas\"])\n",
    "    \n",
    "    if not results[\"documents\"][0]:\n",
    "        return \"No se encontro informacion sobre Batman para esta consulta.\"\n",
    "    \n",
    "    contexto = []\n",
    "    for doc, meta in zip(results[\"documents\"][0], results[\"metadatas\"][0]):\n",
    "        contexto.append(f\"[{meta['titulo']} - {meta['arco']}]: {doc}\")\n",
    "    return \"\\n\\n\".join(contexto)\n",
    "\n",
    "\n",
    "@tool\n",
    "def buscar_spiderman(query: str) -> str:\n",
    "    \"\"\"Busca informacion sobre Spider-Man en la base de datos de comics.\n",
    "    \n",
    "    Args:\n",
    "        query: Pregunta o tema a buscar sobre Spider-Man.\n",
    "    \"\"\"\n",
    "    col = chroma_client.get_collection(\"comics_spiderman\")\n",
    "    emb = embeddings_model.embed_query(query)\n",
    "    results = col.query(query_embeddings=[emb], n_results=3, include=[\"documents\", \"metadatas\"])\n",
    "    \n",
    "    if not results[\"documents\"][0]:\n",
    "        return \"No se encontro informacion sobre Spider-Man para esta consulta.\"\n",
    "    \n",
    "    contexto = []\n",
    "    for doc, meta in zip(results[\"documents\"][0], results[\"metadatas\"][0]):\n",
    "        contexto.append(f\"[{meta['titulo']} - {meta['arco']}]: {doc}\")\n",
    "    return \"\\n\\n\".join(contexto)\n",
    "\n",
    "\n",
    "@tool\n",
    "def comparar_heroes(aspecto: str) -> str:\n",
    "    \"\"\"Compara Batman y Spider-Man buscando informacion de ambos.\n",
    "    \n",
    "    Args:\n",
    "        aspecto: Aspecto a comparar (fuerza, filosofia, equipo, relaciones, etc).\n",
    "    \"\"\"\n",
    "    batman_col = chroma_client.get_collection(\"comics_batman\")\n",
    "    spider_col = chroma_client.get_collection(\"comics_spiderman\")\n",
    "    \n",
    "    emb = embeddings_model.embed_query(aspecto)\n",
    "    \n",
    "    batman_results = batman_col.query(query_embeddings=[emb], n_results=2, include=[\"documents\", \"metadatas\"])\n",
    "    spider_results = spider_col.query(query_embeddings=[emb], n_results=2, include=[\"documents\", \"metadatas\"])\n",
    "    \n",
    "    contexto = \"BATMAN:\\n\"\n",
    "    for doc, meta in zip(batman_results[\"documents\"][0], batman_results[\"metadatas\"][0]):\n",
    "        contexto += f\"[{meta['arco']}]: {doc[:300]}\\n\"\n",
    "    \n",
    "    contexto += \"\\nSPIDER-MAN:\\n\"\n",
    "    for doc, meta in zip(spider_results[\"documents\"][0], spider_results[\"metadatas\"][0]):\n",
    "        contexto += f\"[{meta['arco']}]: {doc[:300]}\\n\"\n",
    "    \n",
    "    return contexto\n",
    "\n",
    "\n",
    "@tool\n",
    "def calcular_estadisticas(personaje: str) -> str:\n",
    "    \"\"\"Calcula estadisticas y nivel de poder de un personaje.\n",
    "    \n",
    "    Args:\n",
    "        personaje: Nombre del personaje (batman o spiderman).\n",
    "    \"\"\"\n",
    "    stats = {\n",
    "        \"batman\": {\n",
    "            \"fuerza\": 35, \"inteligencia\": 95, \"tecnologia\": 90, \"combate\": 85,\n",
    "            \"liderazgo\": 90, \"preparacion\": 98, \"recursos\": 95, \"total_promedio\": 84\n",
    "        },\n",
    "        \"spiderman\": {\n",
    "            \"fuerza\": 70, \"inteligencia\": 85, \"agilidad\": 95, \"sentido_aracnido\": 90,\n",
    "            \"creatividad\": 88, \"resistencia\": 75, \"inventiva\": 80, \"total_promedio\": 83\n",
    "        },\n",
    "    }\n",
    "    s = stats.get(personaje.lower())\n",
    "    if s:\n",
    "        return json.dumps(s, indent=2, ensure_ascii=False)\n",
    "    return f\"No hay estadisticas para {personaje}\"\n",
    "\n",
    "\n",
    "agent_tools = [buscar_batman, buscar_spiderman, comparar_heroes, calcular_estadisticas]\n",
    "\n",
    "print(\"Herramientas del agente:\")\n",
    "for t in agent_tools:\n",
    "    print(f\"  - {t.name}: {t.description.split(chr(10))[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7b8c9",
   "metadata": {},
   "source": [
    "## 2. Arquitectura del Grafo\n",
    "\n",
    "```\n",
    "                    ┌──────────┐\n",
    "                    │  START    │\n",
    "                    └────┬─────┘\n",
    "                         │\n",
    "                    ┌────▼─────┐\n",
    "              ┌─────│  Agent   │─────┐\n",
    "              │     └────┬─────┘     │\n",
    "              │          │           │\n",
    "         tool_calls    no tools   tool_calls\n",
    "              │          │           │\n",
    "         ┌────▼────┐     │     ┌────▼────┐\n",
    "         │  Tools  │     │     │  Tools  │\n",
    "         └────┬────┘     │     └────┬────┘\n",
    "              │          │          │\n",
    "              └──────────┼──────────┘\n",
    "                         │\n",
    "                    ┌────▼─────┐\n",
    "                    │ Validar  │\n",
    "                    └────┬─────┘\n",
    "                         │\n",
    "                    ┌────▼─────┐\n",
    "                    │   END    │\n",
    "                    └──────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# GRAFO DEL AGENTE COMPLETO\n",
    "# ============================================================\n",
    "\n",
    "class ExpertState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    trace: list[dict]\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"Eres un experto en comics de Batman y Spider-Man. Tu trabajo es responder \n",
    "preguntas usando las herramientas disponibles para buscar informacion precisa.\n",
    "\n",
    "REGLAS:\n",
    "1. Siempre busca informacion antes de responder\n",
    "2. Para preguntas de comparacion, busca en AMBAS bases de datos\n",
    "3. Cita las fuentes (arcos narrativos) en tu respuesta\n",
    "4. Responde en español\n",
    "5. Se preciso y evita inventar informacion\n",
    "\n",
    "HERRAMIENTAS:\n",
    "- buscar_batman: buscar en la base de datos de Batman\n",
    "- buscar_spiderman: buscar en la base de datos de Spider-Man\n",
    "- comparar_heroes: buscar en ambas bases para comparar\n",
    "- calcular_estadisticas: obtener stats numericas de un personaje\n",
    "\"\"\"\n",
    "\n",
    "llm_with_tools = llm.bind_tools(agent_tools)\n",
    "\n",
    "\n",
    "def nodo_agente(state: ExpertState) -> dict:\n",
    "    \"\"\"Nodo principal del agente.\"\"\"\n",
    "    messages = [SystemMessage(content=SYSTEM_PROMPT)] + state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    trace_entry = {\n",
    "        \"nodo\": \"agent\",\n",
    "        \"timestamp\": time.time(),\n",
    "        \"tool_calls\": len(response.tool_calls) if response.tool_calls else 0,\n",
    "        \"has_content\": bool(response.content),\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [response],\n",
    "        \"trace\": state.get(\"trace\", []) + [trace_entry],\n",
    "    }\n",
    "\n",
    "\n",
    "def should_continue(state: ExpertState) -> str:\n",
    "    last = state[\"messages\"][-1]\n",
    "    if hasattr(last, \"tool_calls\") and last.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"validar\"\n",
    "\n",
    "\n",
    "def nodo_validar(state: ExpertState) -> dict:\n",
    "    \"\"\"Validacion final de la respuesta.\"\"\"\n",
    "    last_content = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
    "    trace_entry = {\n",
    "        \"nodo\": \"validar\",\n",
    "        \"timestamp\": time.time(),\n",
    "        \"respuesta_length\": len(last_content) if last_content else 0,\n",
    "    }\n",
    "    return {\"trace\": state.get(\"trace\", []) + [trace_entry]}\n",
    "\n",
    "\n",
    "def tool_node_with_trace(state: ExpertState) -> dict:\n",
    "    \"\"\"ToolNode wrapper que agrega trazabilidad.\"\"\"\n",
    "    tool_node = ToolNode(agent_tools)\n",
    "    result = tool_node.invoke(state)\n",
    "    \n",
    "    trace_entry = {\n",
    "        \"nodo\": \"tools\",\n",
    "        \"timestamp\": time.time(),\n",
    "        \"tools_executed\": len(result.get(\"messages\", [])),\n",
    "    }\n",
    "    \n",
    "    result_trace = state.get(\"trace\", []) + [trace_entry]\n",
    "    if \"trace\" not in result:\n",
    "        result[\"trace\"] = result_trace\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Build graph\n",
    "graph = StateGraph(ExpertState)\n",
    "graph.add_node(\"agent\", nodo_agente)\n",
    "graph.add_node(\"tools\", tool_node_with_trace)\n",
    "graph.add_node(\"validar\", nodo_validar)\n",
    "\n",
    "graph.add_edge(START, \"agent\")\n",
    "graph.add_conditional_edges(\"agent\", should_continue, {\n",
    "    \"tools\": \"tools\",\n",
    "    \"validar\": \"validar\",\n",
    "})\n",
    "graph.add_edge(\"tools\", \"agent\")\n",
    "graph.add_edge(\"validar\", END)\n",
    "\n",
    "expert_app = graph.compile()\n",
    "print(\"Agente Experto en Comics compilado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c9d0e1",
   "metadata": {},
   "source": [
    "## 3. Multi-Step Reasoning Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEMO: Multi-step reasoning\n",
    "# ============================================================\n",
    "\n",
    "queries = [\n",
    "    \"Quien seria mejor lider en una crisis: Batman o Spider-Man? Justifica con evidencia de los comics.\",\n",
    "    \"Compara la filosofia de Batman con la de Spider-Man. Que los diferencia fundamentalmente?\",\n",
    "    \"Que rol juega la tecnologia en Batman vs los poderes innatos de Spider-Man?\",\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MULTI-STEP REASONING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    result = expert_app.invoke({\n",
    "        \"messages\": [HumanMessage(content=query)],\n",
    "        \"trace\": [],\n",
    "    })\n",
    "    total_time = (time.time() - t0) * 1000\n",
    "    \n",
    "    # Trace\n",
    "    print(f\"\\nTRAZABILIDAD:\")\n",
    "    for entry in result.get(\"trace\", []):\n",
    "        print(f\"  [{entry['nodo']:10s}] {json.dumps({k: v for k, v in entry.items() if k != 'nodo'})}\")\n",
    "    \n",
    "    # Count messages by type\n",
    "    msg_types = {}\n",
    "    for msg in result[\"messages\"]:\n",
    "        t = msg.__class__.__name__\n",
    "        msg_types[t] = msg_types.get(t, 0) + 1\n",
    "    print(f\"\\nMensajes: {msg_types}\")\n",
    "    print(f\"Latencia total: {total_time:.0f}ms\")\n",
    "    \n",
    "    # Final response\n",
    "    respuesta = result[\"messages\"][-1].content if result[\"messages\"][-1].content else \"(sin contenido)\"\n",
    "    print(f\"\\nRESPUESTA:\\n{respuesta[:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1f2a3",
   "metadata": {},
   "source": [
    "## 4. Analisis de Trazabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ANALISIS DE COSTOS POR QUERY\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RESUMEN DE TRAZABILIDAD\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Contar operaciones por query\n",
    "for i, query in enumerate(queries):\n",
    "    result = expert_app.invoke({\n",
    "        \"messages\": [HumanMessage(content=query)],\n",
    "        \"trace\": [],\n",
    "    })\n",
    "    \n",
    "    trace = result.get(\"trace\", [])\n",
    "    agent_calls = sum(1 for t in trace if t[\"nodo\"] == \"agent\")\n",
    "    tool_calls = sum(1 for t in trace if t[\"nodo\"] == \"tools\")\n",
    "    \n",
    "    print(f\"\\nQuery {i+1}: {query[:50]}...\")\n",
    "    print(f\"  Iteraciones del agente: {agent_calls}\")\n",
    "    print(f\"  Llamadas a herramientas: {tool_calls}\")\n",
    "    print(f\"  Total nodos ejecutados: {len(trace)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a3b4c5",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "1. Un agente completo combina **routing, herramientas, validacion y trazabilidad**\n",
    "2. Para preguntas de comparacion, el agente automaticamente busca en **ambas bases de datos**\n",
    "3. La trazabilidad permite entender **exactamente que hizo el agente** en cada paso\n",
    "4. Multi-step reasoning requiere multiples tool calls, lo que incrementa costo y latencia\n",
    "5. El pattern `agent → tools → agent → ... → validar` es el standard de LangGraph\n",
    "6. En produccion, la trazabilidad es esencial para debugging y auditoria"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat": 4,
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}