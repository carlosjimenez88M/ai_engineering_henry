{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# 04 — RAG Agentico\n",
    "\n",
    "**Objetivo**: Implementar tres niveles progresivos de RAG, desde basico hasta completamente agentico con verificacion de alucinaciones.\n",
    "\n",
    "## Contenido\n",
    "1. RAG Basico: ChromaDB + retriever + generacion\n",
    "2. RAG Agentico con Grading: evaluacion de relevancia de documentos\n",
    "3. Agentic RAG con Hallucination Check: verificacion post-generacion\n",
    "4. Evaluacion comparativa de las 3 etapas\n",
    "5. Visualizacion t-SNE del espacio vectorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pydantic import BaseModel, Field\n",
    "import chromadb\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-5-mini\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RAG AGENTICO — De basico a completo\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4e5f6",
   "metadata": {},
   "source": [
    "## Preparacion de Datos\n",
    "\n",
    "Cargamos los comics de Batman y Spider-Man, los dividimos en chunks, y los indexamos en ChromaDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CARGA Y CHUNKING DE DATOS\n",
    "# ============================================================\n",
    "\n",
    "def cargar_comics(ruta: str) -> list[dict]:\n",
    "    \"\"\"Carga comics desde un archivo JSON.\"\"\"\n",
    "    with open(ruta) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "batman_comics = cargar_comics(\"../data/batman_comics.json\")\n",
    "spider_comics = cargar_comics(\"../data/spiderman_comics.json\")\n",
    "\n",
    "print(f\"Batman comics: {len(batman_comics)}\")\n",
    "print(f\"Spider-Man comics: {len(spider_comics)}\")\n",
    "\n",
    "# Chunking\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")\n",
    "\n",
    "chunks = []\n",
    "metadatas = []\n",
    "\n",
    "for comic in batman_comics + spider_comics:\n",
    "    splits = splitter.split_text(comic[\"contenido\"])\n",
    "    for i, chunk in enumerate(splits):\n",
    "        chunks.append(chunk)\n",
    "        metadatas.append({\n",
    "            \"personaje\": comic[\"personaje\"],\n",
    "            \"arco\": comic[\"arco\"],\n",
    "            \"tema\": comic[\"tema\"],\n",
    "            \"titulo\": comic[\"titulo\"],\n",
    "            \"doc_id\": comic[\"id\"],\n",
    "            \"chunk_id\": i,\n",
    "        })\n",
    "\n",
    "print(f\"\\nTotal chunks: {len(chunks)}\")\n",
    "print(f\"Chunks Batman: {sum(1 for m in metadatas if m['personaje'] == 'batman')}\")\n",
    "print(f\"Chunks Spider-Man: {sum(1 for m in metadatas if m['personaje'] == 'spiderman')}\")\n",
    "print(f\"\\nEjemplo de chunk:\")\n",
    "print(f\"  Texto: {chunks[0][:150]}...\")\n",
    "print(f\"  Metadata: {metadatas[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# INDEXACION EN CHROMADB\n",
    "# ============================================================\n",
    "\n",
    "# Generar embeddings en batch\n",
    "print(\"Generando embeddings...\")\n",
    "t0 = time.time()\n",
    "all_embeddings = embeddings.embed_documents(chunks)\n",
    "embed_time = time.time() - t0\n",
    "print(f\"  {len(all_embeddings)} embeddings generados en {embed_time:.1f}s\")\n",
    "print(f\"  Dimension: {len(all_embeddings[0])}\")\n",
    "\n",
    "# Crear coleccion en ChromaDB\n",
    "collection = chroma_client.create_collection(\n",
    "    name=\"comics_rag\",\n",
    "    metadata={\"hnsw:space\": \"cosine\"}\n",
    ")\n",
    "\n",
    "# Insertar chunks\n",
    "collection.add(\n",
    "    ids=[f\"chunk_{i}\" for i in range(len(chunks))],\n",
    "    embeddings=all_embeddings,\n",
    "    documents=chunks,\n",
    "    metadatas=metadatas,\n",
    ")\n",
    "\n",
    "print(f\"\\nColeccion 'comics_rag' creada con {collection.count()} documentos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7b8c9",
   "metadata": {},
   "source": [
    "## Etapa 1: RAG Basico\n",
    "\n",
    "Retriever simple → Contexto → Generacion. Sin evaluacion de calidad.\n",
    "\n",
    "```\n",
    "Query → [Retriever (k=4)] → [Contexto] → [LLM] → Respuesta\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ETAPA 1: RAG BASICO\n",
    "# ============================================================\n",
    "\n",
    "def rag_basico(query: str, k: int = 4) -> dict:\n",
    "    \"\"\"\n",
    "    RAG basico: retrieve + generate.\n",
    "    \n",
    "    Args:\n",
    "        query: Pregunta del usuario.\n",
    "        k: Numero de documentos a recuperar.\n",
    "    \n",
    "    Returns:\n",
    "        Dict con respuesta, documentos, y metricas.\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Retrieve\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=k,\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "    )\n",
    "    \n",
    "    docs = results[\"documents\"][0]\n",
    "    metas = results[\"metadatas\"][0]\n",
    "    dists = results[\"distances\"][0]\n",
    "    \n",
    "    # Build context\n",
    "    contexto = \"\\n\\n\".join([\n",
    "        f\"[{m['titulo']} - {m['arco']}]: {doc}\"\n",
    "        for doc, m in zip(docs, metas)\n",
    "    ])\n",
    "    \n",
    "    # Generate\n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=f\"\"\"Eres un experto en comics. Responde SOLO con informacion del contexto.\n",
    "Si no hay informacion suficiente, di \"No tengo informacion suficiente.\"\n",
    "Responde en español.\n",
    "\n",
    "Contexto:\n",
    "{contexto}\"\"\"),\n",
    "        HumanMessage(content=query),\n",
    "    ])\n",
    "    \n",
    "    latencia = (time.time() - t0) * 1000\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"respuesta\": response.content,\n",
    "        \"docs_recuperados\": [{\"texto\": d[:100], \"meta\": m, \"distancia\": dist} for d, m, dist in zip(docs, metas, dists)],\n",
    "        \"num_docs\": len(docs),\n",
    "        \"latencia_ms\": round(latencia, 1),\n",
    "        \"etapa\": \"basico\",\n",
    "    }\n",
    "\n",
    "\n",
    "# Test\n",
    "r1 = rag_basico(\"Como se convirtio Bruce Wayne en Batman?\")\n",
    "print(\"=\" * 60)\n",
    "print(\"ETAPA 1: RAG BASICO\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nQuery: {r1['query']}\")\n",
    "print(f\"Docs recuperados: {r1['num_docs']}\")\n",
    "for i, doc in enumerate(r1[\"docs_recuperados\"]):\n",
    "    print(f\"  [{i+1}] {doc['meta']['personaje']}/{doc['meta']['arco']} (dist={doc['distancia']:.3f})\")\n",
    "print(f\"\\nRespuesta: {r1['respuesta'][:400]}...\")\n",
    "print(f\"Latencia: {r1['latencia_ms']}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c9d0e1",
   "metadata": {},
   "source": [
    "## Etapa 2: RAG Agentico con Grading\n",
    "\n",
    "Agregamos un nodo \"grader\" que evalua la relevancia de cada documento recuperado.\n",
    "Si menos de 2 documentos son relevantes, reescribimos la query y reintentamos.\n",
    "\n",
    "```\n",
    "Query → [Retrieve] → [Grade docs] → ¿>=2 relevantes?\n",
    "                                      ├── SI → [Generate]\n",
    "                                      └── NO → [Rewrite query] → [Retrieve] → ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ETAPA 2: GRADING DE RELEVANCIA\n",
    "# ============================================================\n",
    "\n",
    "from typing import Literal, TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class GradeDocument(BaseModel):\n",
    "    \"\"\"Evaluacion de relevancia de un documento.\"\"\"\n",
    "    es_relevante: Literal[\"si\", \"no\"] = Field(\n",
    "        description=\"El documento es relevante para responder la pregunta\"\n",
    "    )\n",
    "    razon: str = Field(description=\"Breve razon de la decision\")\n",
    "\n",
    "grader_llm = llm.with_structured_output(GradeDocument)\n",
    "\n",
    "\n",
    "def evaluar_relevancia(query: str, documento: str) -> GradeDocument:\n",
    "    \"\"\"Evalua si un documento es relevante para una query.\"\"\"\n",
    "    return grader_llm.invoke(\n",
    "        f\"Query del usuario: {query}\\n\\nDocumento recuperado:\\n{documento}\\n\\n\"\n",
    "        f\"¿Este documento contiene informacion relevante para responder la query?\"\n",
    "    )\n",
    "\n",
    "\n",
    "class RAGState(TypedDict):\n",
    "    query: str\n",
    "    query_original: str\n",
    "    documentos: list[dict]\n",
    "    docs_relevantes: list[dict]\n",
    "    respuesta: str\n",
    "    intentos: int\n",
    "    etapa: str\n",
    "    metricas: dict\n",
    "\n",
    "\n",
    "def nodo_retrieve(state: RAGState) -> dict:\n",
    "    \"\"\"Recupera documentos de ChromaDB.\"\"\"\n",
    "    query_emb = embeddings.embed_query(state[\"query\"])\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_emb], n_results=4,\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "    )\n",
    "    docs = [\n",
    "        {\"texto\": d, \"meta\": m, \"distancia\": dist}\n",
    "        for d, m, dist in zip(results[\"documents\"][0], results[\"metadatas\"][0], results[\"distances\"][0])\n",
    "    ]\n",
    "    return {\"documentos\": docs}\n",
    "\n",
    "\n",
    "def nodo_grade(state: RAGState) -> dict:\n",
    "    \"\"\"Evalua relevancia de cada documento.\"\"\"\n",
    "    relevantes = []\n",
    "    for doc in state[\"documentos\"]:\n",
    "        grade = evaluar_relevancia(state[\"query\"], doc[\"texto\"])\n",
    "        if grade.es_relevante == \"si\":\n",
    "            relevantes.append(doc)\n",
    "    return {\"docs_relevantes\": relevantes}\n",
    "\n",
    "\n",
    "def decidir_generacion(state: RAGState) -> str:\n",
    "    \"\"\"Decide si generar o reescribir.\"\"\"\n",
    "    if len(state.get(\"docs_relevantes\", [])) >= 2:\n",
    "        return \"generar\"\n",
    "    if state.get(\"intentos\", 0) >= 2:\n",
    "        return \"generar\"  # Generar con lo que hay\n",
    "    return \"reescribir\"\n",
    "\n",
    "\n",
    "def nodo_reescribir(state: RAGState) -> dict:\n",
    "    \"\"\"Reescribe la query para mejorar la recuperacion.\"\"\"\n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=\"Reescribe la siguiente pregunta para mejorar la busqueda en una base de datos de comics. Manten el significado pero usa diferentes palabras clave.\"),\n",
    "        HumanMessage(content=state[\"query\"]),\n",
    "    ])\n",
    "    return {\"query\": response.content, \"intentos\": state.get(\"intentos\", 0) + 1}\n",
    "\n",
    "\n",
    "def nodo_generar(state: RAGState) -> dict:\n",
    "    \"\"\"Genera respuesta con los documentos relevantes.\"\"\"\n",
    "    docs = state.get(\"docs_relevantes\", []) or state.get(\"documentos\", [])\n",
    "    contexto = \"\\n\\n\".join([d[\"texto\"] for d in docs[:4]])\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=f\"Responde basandote SOLO en el contexto. En español.\\n\\nContexto:\\n{contexto}\"),\n",
    "        HumanMessage(content=state[\"query_original\"]),\n",
    "    ])\n",
    "    return {\"respuesta\": response.content, \"etapa\": \"grading\"}\n",
    "\n",
    "\n",
    "# Build graph\n",
    "graph = StateGraph(RAGState)\n",
    "graph.add_node(\"retrieve\", nodo_retrieve)\n",
    "graph.add_node(\"grade\", nodo_grade)\n",
    "graph.add_node(\"reescribir\", nodo_reescribir)\n",
    "graph.add_node(\"generar\", nodo_generar)\n",
    "\n",
    "graph.add_edge(START, \"retrieve\")\n",
    "graph.add_edge(\"retrieve\", \"grade\")\n",
    "graph.add_conditional_edges(\"grade\", decidir_generacion, {\n",
    "    \"generar\": \"generar\",\n",
    "    \"reescribir\": \"reescribir\",\n",
    "})\n",
    "graph.add_edge(\"reescribir\", \"retrieve\")\n",
    "graph.add_edge(\"generar\", END)\n",
    "\n",
    "rag_grading_app = graph.compile()\n",
    "print(\"Grafo RAG con grading compilado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "t0 = time.time()\n",
    "r2 = rag_grading_app.invoke({\n",
    "    \"query\": \"Como se convirtio Bruce Wayne en Batman?\",\n",
    "    \"query_original\": \"Como se convirtio Bruce Wayne en Batman?\",\n",
    "    \"documentos\": [],\n",
    "    \"docs_relevantes\": [],\n",
    "    \"respuesta\": \"\",\n",
    "    \"intentos\": 0,\n",
    "    \"etapa\": \"\",\n",
    "    \"metricas\": {},\n",
    "})\n",
    "lat2 = (time.time() - t0) * 1000\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ETAPA 2: RAG CON GRADING\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Docs recuperados: {len(r2['documentos'])}\")\n",
    "print(f\"Docs relevantes: {len(r2['docs_relevantes'])}\")\n",
    "print(f\"Intentos de reescritura: {r2['intentos']}\")\n",
    "print(f\"Respuesta: {r2['respuesta'][:400]}...\")\n",
    "print(f\"Latencia: {lat2:.0f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4",
   "metadata": {},
   "source": [
    "## Etapa 3: Agentic RAG con Hallucination Check\n",
    "\n",
    "Agregamos verificacion post-generacion: el LLM evalua si la respuesta esta fundamentada en el contexto.\n",
    "\n",
    "```\n",
    "Query → [Retrieve] → [Grade] → [Decide] → [Generate] → [Hallucination Check] → [Decide Output]\n",
    "                                    │                           │\n",
    "                                    └── [Rewrite] ◄─────────────┘ (si alucina)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ETAPA 3: AGENTIC RAG CON HALLUCINATION CHECK\n",
    "# ============================================================\n",
    "\n",
    "class HallucinationCheck(BaseModel):\n",
    "    \"\"\"Evaluacion de alucinacion.\"\"\"\n",
    "    esta_fundamentada: Literal[\"si\", \"no\"] = Field(\n",
    "        description=\"La respuesta esta fundamentada en el contexto\"\n",
    "    )\n",
    "    score: int = Field(description=\"Score de grounding 1-5\", ge=1, le=5)\n",
    "    detalle: str = Field(description=\"Que partes estan o no fundamentadas\")\n",
    "\n",
    "hallucination_llm = llm.with_structured_output(HallucinationCheck)\n",
    "\n",
    "\n",
    "class FullRAGState(TypedDict):\n",
    "    query: str\n",
    "    query_original: str\n",
    "    documentos: list[dict]\n",
    "    docs_relevantes: list[dict]\n",
    "    respuesta: str\n",
    "    hallucination_check: dict | None\n",
    "    intentos: int\n",
    "    intentos_hallucination: int\n",
    "    etapa: str\n",
    "\n",
    "\n",
    "def nodo_retrieve_full(state: FullRAGState) -> dict:\n",
    "    query_emb = embeddings.embed_query(state[\"query\"])\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_emb], n_results=4,\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "    )\n",
    "    docs = [\n",
    "        {\"texto\": d, \"meta\": m, \"distancia\": dist}\n",
    "        for d, m, dist in zip(results[\"documents\"][0], results[\"metadatas\"][0], results[\"distances\"][0])\n",
    "    ]\n",
    "    return {\"documentos\": docs}\n",
    "\n",
    "\n",
    "def nodo_grade_full(state: FullRAGState) -> dict:\n",
    "    relevantes = []\n",
    "    for doc in state[\"documentos\"]:\n",
    "        grade = evaluar_relevancia(state[\"query\"], doc[\"texto\"])\n",
    "        if grade.es_relevante == \"si\":\n",
    "            relevantes.append(doc)\n",
    "    return {\"docs_relevantes\": relevantes}\n",
    "\n",
    "\n",
    "def decidir_gen_full(state: FullRAGState) -> str:\n",
    "    if len(state.get(\"docs_relevantes\", [])) >= 2:\n",
    "        return \"generar\"\n",
    "    if state.get(\"intentos\", 0) >= 2:\n",
    "        return \"generar\"\n",
    "    return \"reescribir\"\n",
    "\n",
    "\n",
    "def nodo_reescribir_full(state: FullRAGState) -> dict:\n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=\"Reescribe esta pregunta con diferentes palabras clave para buscar en una base de comics.\"),\n",
    "        HumanMessage(content=state[\"query\"]),\n",
    "    ])\n",
    "    return {\"query\": response.content, \"intentos\": state.get(\"intentos\", 0) + 1}\n",
    "\n",
    "\n",
    "def nodo_generar_full(state: FullRAGState) -> dict:\n",
    "    docs = state.get(\"docs_relevantes\", []) or state.get(\"documentos\", [])\n",
    "    contexto = \"\\n\\n\".join([d[\"texto\"] for d in docs[:4]])\n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=f\"Responde SOLO con informacion del contexto. En español.\\n\\nContexto:\\n{contexto}\"),\n",
    "        HumanMessage(content=state[\"query_original\"]),\n",
    "    ])\n",
    "    return {\"respuesta\": response.content}\n",
    "\n",
    "\n",
    "def nodo_hallucination_check(state: FullRAGState) -> dict:\n",
    "    docs = state.get(\"docs_relevantes\", []) or state.get(\"documentos\", [])\n",
    "    contexto = \"\\n\\n\".join([d[\"texto\"] for d in docs[:4]])\n",
    "    check = hallucination_llm.invoke(\n",
    "        f\"Contexto disponible:\\n{contexto}\\n\\nRespuesta generada:\\n{state['respuesta']}\\n\\n\"\n",
    "        f\"¿La respuesta esta completamente fundamentada en el contexto?\"\n",
    "    )\n",
    "    return {\"hallucination_check\": check.model_dump(), \"intentos_hallucination\": state.get(\"intentos_hallucination\", 0) + 1}\n",
    "\n",
    "\n",
    "def decidir_output(state: FullRAGState) -> str:\n",
    "    check = state.get(\"hallucination_check\", {})\n",
    "    if check.get(\"esta_fundamentada\") == \"si\":\n",
    "        return \"output\"\n",
    "    if state.get(\"intentos_hallucination\", 0) >= 2:\n",
    "        return \"output\"  # Output with warning\n",
    "    return \"regenerar\"\n",
    "\n",
    "\n",
    "# Build full graph\n",
    "full_graph = StateGraph(FullRAGState)\n",
    "full_graph.add_node(\"retrieve\", nodo_retrieve_full)\n",
    "full_graph.add_node(\"grade\", nodo_grade_full)\n",
    "full_graph.add_node(\"reescribir\", nodo_reescribir_full)\n",
    "full_graph.add_node(\"generar\", nodo_generar_full)\n",
    "full_graph.add_node(\"hallucination_check\", nodo_hallucination_check)\n",
    "\n",
    "full_graph.add_edge(START, \"retrieve\")\n",
    "full_graph.add_edge(\"retrieve\", \"grade\")\n",
    "full_graph.add_conditional_edges(\"grade\", decidir_gen_full, {\n",
    "    \"generar\": \"generar\",\n",
    "    \"reescribir\": \"reescribir\",\n",
    "})\n",
    "full_graph.add_edge(\"reescribir\", \"retrieve\")\n",
    "full_graph.add_edge(\"generar\", \"hallucination_check\")\n",
    "full_graph.add_conditional_edges(\"hallucination_check\", decidir_output, {\n",
    "    \"output\": END,\n",
    "    \"regenerar\": \"generar\",\n",
    "})\n",
    "\n",
    "rag_full_app = full_graph.compile()\n",
    "print(\"Grafo RAG completo (con hallucination check) compilado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "r3 = rag_full_app.invoke({\n",
    "    \"query\": \"Como se convirtio Bruce Wayne en Batman?\",\n",
    "    \"query_original\": \"Como se convirtio Bruce Wayne en Batman?\",\n",
    "    \"documentos\": [],\n",
    "    \"docs_relevantes\": [],\n",
    "    \"respuesta\": \"\",\n",
    "    \"hallucination_check\": None,\n",
    "    \"intentos\": 0,\n",
    "    \"intentos_hallucination\": 0,\n",
    "    \"etapa\": \"full\",\n",
    "})\n",
    "lat3 = (time.time() - t0) * 1000\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ETAPA 3: AGENTIC RAG COMPLETO\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Docs relevantes: {len(r3['docs_relevantes'])}\")\n",
    "print(f\"Hallucination check: {r3['hallucination_check']}\")\n",
    "print(f\"Respuesta: {r3['respuesta'][:400]}...\")\n",
    "print(f\"Latencia: {lat3:.0f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5d6e7",
   "metadata": {},
   "source": [
    "## 4. Evaluacion Comparativa\n",
    "\n",
    "Ejecutamos las 3 etapas con las preguntas de evaluacion y comparamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EVALUACION COMPARATIVA\n",
    "# ============================================================\n",
    "\n",
    "# Cargar preguntas de evaluacion\n",
    "eval_questions = []\n",
    "with open(\"../data/comics_eval.jsonl\") as f:\n",
    "    for line in f:\n",
    "        eval_questions.append(json.loads(line))\n",
    "\n",
    "# Evaluar solo las primeras 5 para no gastar mucho\n",
    "eval_subset = eval_questions[:5]\n",
    "\n",
    "resultados_eval = []\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"EVALUACION COMPARATIVA (5 preguntas)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for eq in eval_subset:\n",
    "    pregunta = eq[\"pregunta\"]\n",
    "    keywords = eq[\"keywords\"]\n",
    "    \n",
    "    # Etapa 1: RAG Basico\n",
    "    t0 = time.time()\n",
    "    r_basico = rag_basico(pregunta)\n",
    "    lat_basico = (time.time() - t0) * 1000\n",
    "    \n",
    "    # Keyword recall\n",
    "    resp_lower = r_basico[\"respuesta\"].lower()\n",
    "    kw_found = sum(1 for kw in keywords if kw.lower() in resp_lower)\n",
    "    recall_basico = kw_found / len(keywords)\n",
    "    \n",
    "    # Etapa 2: RAG con Grading\n",
    "    t0 = time.time()\n",
    "    r_grading = rag_grading_app.invoke({\n",
    "        \"query\": pregunta, \"query_original\": pregunta,\n",
    "        \"documentos\": [], \"docs_relevantes\": [],\n",
    "        \"respuesta\": \"\", \"intentos\": 0, \"etapa\": \"\", \"metricas\": {},\n",
    "    })\n",
    "    lat_grading = (time.time() - t0) * 1000\n",
    "    \n",
    "    resp_lower = r_grading[\"respuesta\"].lower()\n",
    "    kw_found = sum(1 for kw in keywords if kw.lower() in resp_lower)\n",
    "    recall_grading = kw_found / len(keywords)\n",
    "    \n",
    "    # Etapa 3: Full Agentic\n",
    "    t0 = time.time()\n",
    "    r_full = rag_full_app.invoke({\n",
    "        \"query\": pregunta, \"query_original\": pregunta,\n",
    "        \"documentos\": [], \"docs_relevantes\": [],\n",
    "        \"respuesta\": \"\", \"hallucination_check\": None,\n",
    "        \"intentos\": 0, \"intentos_hallucination\": 0, \"etapa\": \"full\",\n",
    "    })\n",
    "    lat_full = (time.time() - t0) * 1000\n",
    "    \n",
    "    resp_lower = r_full[\"respuesta\"].lower()\n",
    "    kw_found = sum(1 for kw in keywords if kw.lower() in resp_lower)\n",
    "    recall_full = kw_found / len(keywords)\n",
    "    \n",
    "    resultados_eval.append({\n",
    "        \"pregunta\": pregunta[:40],\n",
    "        \"recall_basico\": recall_basico,\n",
    "        \"recall_grading\": recall_grading,\n",
    "        \"recall_full\": recall_full,\n",
    "        \"lat_basico\": lat_basico,\n",
    "        \"lat_grading\": lat_grading,\n",
    "        \"lat_full\": lat_full,\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n  Q: {pregunta[:50]}...\")\n",
    "    print(f\"    Basico:  recall={recall_basico:.0%} lat={lat_basico:.0f}ms\")\n",
    "    print(f\"    Grading: recall={recall_grading:.0%} lat={lat_grading:.0f}ms\")\n",
    "    print(f\"    Full:    recall={recall_full:.0%} lat={lat_full:.0f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e7f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VISUALIZACION COMPARATIVA\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel 1: Keyword Recall por etapa\n",
    "preguntas_labels = [r[\"pregunta\"][:25] + \"...\" for r in resultados_eval]\n",
    "x = np.arange(len(preguntas_labels))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = axes[0].bar(x - width, [r[\"recall_basico\"] for r in resultados_eval], width, label=\"Basico\", color=\"#FF5722\", alpha=0.8)\n",
    "bars2 = axes[0].bar(x, [r[\"recall_grading\"] for r in resultados_eval], width, label=\"Grading\", color=\"#2196F3\", alpha=0.8)\n",
    "bars3 = axes[0].bar(x + width, [r[\"recall_full\"] for r in resultados_eval], width, label=\"Full Agentic\", color=\"#4CAF50\", alpha=0.8)\n",
    "\n",
    "axes[0].set_ylabel(\"Keyword Recall\")\n",
    "axes[0].set_title(\"Calidad: Keyword Recall por Etapa\")\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(preguntas_labels, rotation=45, ha=\"right\", fontsize=7)\n",
    "axes[0].legend()\n",
    "axes[0].set_ylim(0, 1.1)\n",
    "\n",
    "# Panel 2: Latencia por etapa\n",
    "axes[1].bar(x - width, [r[\"lat_basico\"] for r in resultados_eval], width, label=\"Basico\", color=\"#FF5722\", alpha=0.8)\n",
    "axes[1].bar(x, [r[\"lat_grading\"] for r in resultados_eval], width, label=\"Grading\", color=\"#2196F3\", alpha=0.8)\n",
    "axes[1].bar(x + width, [r[\"lat_full\"] for r in resultados_eval], width, label=\"Full Agentic\", color=\"#4CAF50\", alpha=0.8)\n",
    "\n",
    "axes[1].set_ylabel(\"Latencia (ms)\")\n",
    "axes[1].set_title(\"Costo: Latencia por Etapa\")\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(preguntas_labels, rotation=45, ha=\"right\", fontsize=7)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../data/rag_comparacion.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f8a9b0",
   "metadata": {},
   "source": [
    "## 5. Visualizacion t-SNE del Espacio Vectorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VISUALIZACION t-SNE\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Obtener todos los embeddings y metadatas de ChromaDB\n",
    "all_data = collection.get(include=[\"embeddings\", \"metadatas\"])\n",
    "embs = np.array(all_data[\"embeddings\"])\n",
    "metas = all_data[\"metadatas\"]\n",
    "\n",
    "# t-SNE reduction\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(embs) - 1))\n",
    "embs_2d = tsne.fit_transform(embs)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "colores = {\"batman\": \"#1a1a2e\", \"spiderman\": \"#e63946\"}\n",
    "marcadores = {\"batman\": \"o\", \"spiderman\": \"s\"}\n",
    "\n",
    "for i, (x, y) in enumerate(embs_2d):\n",
    "    personaje = metas[i][\"personaje\"]\n",
    "    ax.scatter(x, y, c=colores[personaje], marker=marcadores[personaje], s=50, alpha=0.7)\n",
    "\n",
    "# Query embeddings\n",
    "query_texts = [\"Batman origen\", \"Spider-Man poderes\", \"Comparar heroes\"]\n",
    "query_embs = [embeddings.embed_query(q) for q in query_texts]\n",
    "query_all = np.vstack([embs, query_embs])\n",
    "tsne_all = TSNE(n_components=2, random_state=42, perplexity=min(30, len(query_all) - 1))\n",
    "all_2d = tsne_all.fit_transform(query_all)\n",
    "\n",
    "# Re-plot with queries\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "for i in range(len(embs)):\n",
    "    personaje = metas[i][\"personaje\"]\n",
    "    ax.scatter(all_2d[i, 0], all_2d[i, 1], c=colores[personaje], \n",
    "               marker=marcadores[personaje], s=40, alpha=0.5)\n",
    "\n",
    "# Plot queries\n",
    "for i, q_text in enumerate(query_texts):\n",
    "    idx = len(embs) + i\n",
    "    ax.scatter(all_2d[idx, 0], all_2d[idx, 1], c=\"gold\", marker=\"*\", s=200, \n",
    "               edgecolors=\"black\", linewidth=1.5, zorder=5)\n",
    "    ax.annotate(q_text, (all_2d[idx, 0], all_2d[idx, 1]), \n",
    "                textcoords=\"offset points\", xytext=(10, 10), fontsize=9, fontweight=\"bold\")\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker=\"o\", color=\"w\", markerfacecolor=\"#1a1a2e\", markersize=10, label=\"Batman\"),\n",
    "    Line2D([0], [0], marker=\"s\", color=\"w\", markerfacecolor=\"#e63946\", markersize=10, label=\"Spider-Man\"),\n",
    "    Line2D([0], [0], marker=\"*\", color=\"w\", markerfacecolor=\"gold\", markersize=15, markeredgecolor=\"black\", label=\"Query\"),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc=\"upper right\")\n",
    "ax.set_title(\"Espacio Vectorial t-SNE: Comics Batman vs Spider-Man\", fontsize=14)\n",
    "ax.set_xlabel(\"t-SNE dim 1\")\n",
    "ax.set_ylabel(\"t-SNE dim 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../data/tsne_comics.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total puntos: {len(embs)} chunks + {len(query_texts)} queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b0c1d2",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "1. **RAG Basico** es rapido pero puede recuperar documentos irrelevantes\n",
    "2. **RAG con Grading** mejora la precision descartando docs irrelevantes, a costa de latencia extra\n",
    "3. **Agentic RAG completo** agrega verificacion de alucinaciones, maximizando calidad\n",
    "4. El trade-off es siempre **calidad vs costo/latencia** — elegir segun el caso de uso\n",
    "5. t-SNE muestra que los embeddings separan bien los universos Batman vs Spider-Man\n",
    "6. Las queries se ubican cerca de los clusters relevantes en el espacio vectorial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat": 4,
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}