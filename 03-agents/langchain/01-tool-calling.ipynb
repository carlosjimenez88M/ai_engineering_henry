{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# 01 \u2014 Tool Calling con LangChain\n",
    "\n",
    "**Objetivo**: Implementar herramientas con `@tool`, conectarlas a un LLM via LangGraph, y usar structured output con Pydantic.\n",
    "\n",
    "## Contenido\n",
    "1. Herramientas con `@tool` decorator\n",
    "2. Tool binding al modelo\n",
    "3. Ejecucion manual de tools\n",
    "4. LangGraph con `ToolNode`\n",
    "5. Structured output con Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-5-mini\", temperature=0)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TOOL CALLING CON LANGCHAIN\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4e5f6",
   "metadata": {},
   "source": [
    "## 1. Herramientas con `@tool`\n",
    "\n",
    "El decorator `@tool` convierte una funcion Python en una herramienta que el LLM puede invocar. LangChain genera automaticamente el schema JSON a partir del docstring y type hints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEFINICION DE HERRAMIENTAS\n",
    "# ============================================================\n",
    "\n",
    "@tool\n",
    "def buscar_comic(personaje: str, tema: str) -> str:\n",
    "    \"\"\"Busca informacion sobre un comic basado en personaje y tema.\n",
    "    \n",
    "    Args:\n",
    "        personaje: Nombre del personaje (batman o spiderman).\n",
    "        tema: Tema a buscar (origen, villanos, filosofia, etc).\n",
    "    \"\"\"\n",
    "    import json as _json\n",
    "    ruta = f\"../data/{personaje.lower()}_comics.json\"\n",
    "    try:\n",
    "        with open(ruta) as f:\n",
    "            comics = _json.load(f)\n",
    "        for comic in comics:\n",
    "            if tema.lower() in comic.get(\"tema\", \"\").lower() or tema.lower() in comic.get(\"arco\", \"\").lower():\n",
    "                return f\"[{comic['titulo']}]: {comic['contenido'][:500]}...\"\n",
    "        return f\"No se encontro informacion sobre {tema} para {personaje}.\"\n",
    "    except FileNotFoundError:\n",
    "        return f\"No se encontro el archivo de datos para {personaje}.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def calcular_poder(personaje: str) -> str:\n",
    "    \"\"\"Calcula el nivel de poder de un personaje en escala 1-100.\n",
    "    \n",
    "    Args:\n",
    "        personaje: Nombre del personaje.\n",
    "    \"\"\"\n",
    "    poderes = {\n",
    "        \"batman\": {\"fuerza\": 35, \"inteligencia\": 95, \"tecnologia\": 90, \"combate\": 85, \"total\": 76},\n",
    "        \"spiderman\": {\"fuerza\": 70, \"inteligencia\": 85, \"agilidad\": 95, \"sentido_aracnido\": 90, \"total\": 85},\n",
    "    }\n",
    "    stats = poderes.get(personaje.lower())\n",
    "    if stats:\n",
    "        return json.dumps(stats, ensure_ascii=False)\n",
    "    return f\"No hay datos de poder para {personaje}.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def comparar_personajes(aspecto: str) -> str:\n",
    "    \"\"\"Compara Batman y Spider-Man en un aspecto especifico.\n",
    "    \n",
    "    Args:\n",
    "        aspecto: Aspecto a comparar (fuerza, inteligencia, origen, filosofia, etc).\n",
    "    \"\"\"\n",
    "    comparaciones = {\n",
    "        \"fuerza\": \"Spider-Man tiene fuerza proporcional de arana (10 ton). Batman tiene fuerza humana peak (~500 kg).\",\n",
    "        \"inteligencia\": \"Ambos son genios. Batman: detective, estratega. Spider-Man: cientifico, inventor.\",\n",
    "        \"origen\": \"Batman: trauma por asesinato de padres, elige la justicia. Spider-Man: mordedura de arana + culpa por muerte de tio Ben.\",\n",
    "        \"filosofia\": \"Batman: no matar nunca, deontologia kantiana. Spider-Man: responsabilidad proporcional al poder, existencialismo.\",\n",
    "        \"equipo\": \"Batman: Liga de la Justicia (estratega). Spider-Man: Avengers (corazon moral).\",\n",
    "    }\n",
    "    resultado = comparaciones.get(aspecto.lower(), f\"No hay comparacion predefinida para: {aspecto}\")\n",
    "    return resultado\n",
    "\n",
    "\n",
    "tools = [buscar_comic, calcular_poder, comparar_personajes]\n",
    "\n",
    "print(\"Herramientas definidas:\")\n",
    "for t in tools:\n",
    "    print(f\"  - {t.name}: {t.description[:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8",
   "metadata": {},
   "source": [
    "## 2. Tool Binding\n",
    "\n",
    "Conectamos las herramientas al modelo. El LLM ahora sabe que puede invocarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BINDING DE HERRAMIENTAS AL MODELO\n",
    "# ============================================================\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# El modelo ahora puede decidir usar herramientas\n",
    "response = llm_with_tools.invoke(\"Cual es el origen de Batman?\")\n",
    "\n",
    "print(\"Respuesta del modelo con tools bound:\")\n",
    "print(f\"  Content: {response.content[:200] if response.content else '(vacio - uso tool call)'}\")\n",
    "print(f\"  Tool calls: {len(response.tool_calls) if response.tool_calls else 0}\")\n",
    "\n",
    "if response.tool_calls:\n",
    "    for tc in response.tool_calls:\n",
    "        print(f\"\\n  Tool Call:\")\n",
    "        print(f\"    Nombre: {tc['name']}\")\n",
    "        print(f\"    Args: {tc['args']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8c9d0",
   "metadata": {},
   "source": [
    "## 3. Ejecucion Manual de Tools\n",
    "\n",
    "Cuando el modelo decide usar una herramienta, debemos ejecutarla nosotros y devolver el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EJECUCION MANUAL DEL TOOL CALL\n",
    "# ============================================================\n",
    "\n",
    "if response.tool_calls:\n",
    "    # Buscar la herramienta por nombre\n",
    "    tools_map = {t.name: t for t in tools}\n",
    "    \n",
    "    tool_messages = []\n",
    "    for tc in response.tool_calls:\n",
    "        tool_fn = tools_map[tc[\"name\"]]\n",
    "        resultado = tool_fn.invoke(tc[\"args\"])\n",
    "        tool_messages.append(ToolMessage(content=resultado, tool_call_id=tc[\"id\"]))\n",
    "        print(f\"Ejecutado: {tc['name']}({tc['args']})\")\n",
    "        print(f\"Resultado: {resultado[:200]}...\\n\")\n",
    "\n",
    "    # Enviar el resultado al modelo para que genere la respuesta final\n",
    "    messages = [HumanMessage(\"Cual es el origen de Batman?\"), response] + tool_messages\n",
    "    final_response = llm_with_tools.invoke(messages)\n",
    "    print(\"Respuesta final:\")\n",
    "    print(final_response.content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e1f2",
   "metadata": {},
   "source": [
    "## 4. LangGraph con ToolNode\n",
    "\n",
    "`ToolNode` automatiza la ejecucion de herramientas dentro de un grafo LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LANGGRAPH CON TOOLNODE\n",
    "# ============================================================\n",
    "\n",
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "def call_model(state: AgentState) -> dict:\n",
    "    \"\"\"Nodo que invoca al LLM.\"\"\"\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"Decide si continuar con tools o terminar.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "# Construir el grafo\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"agent\", call_model)\n",
    "graph.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "graph.add_edge(START, \"agent\")\n",
    "graph.add_conditional_edges(\"agent\", should_continue, {\"tools\": \"tools\", END: END})\n",
    "graph.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "print(\"Grafo compilado exitosamente\")\n",
    "print(\"Nodos:\", list(app.get_graph().nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EJECUCION DEL GRAFO\n",
    "# ============================================================\n",
    "\n",
    "result = app.invoke({\"messages\": [HumanMessage(\"Compara la fuerza de Batman y Spider-Man\")]})\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"EJECUCION DEL GRAFO COMPLETO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for msg in result[\"messages\"]:\n",
    "    tipo = msg.__class__.__name__\n",
    "    if tipo == \"HumanMessage\":\n",
    "        print(f\"\\n[USER] {msg.content}\")\n",
    "    elif tipo == \"AIMessage\":\n",
    "        if msg.tool_calls:\n",
    "            for tc in msg.tool_calls:\n",
    "                print(f\"\\n[TOOL CALL] {tc['name']}({tc['args']})\")\n",
    "        if msg.content:\n",
    "            print(f\"\\n[ASSISTANT] {msg.content[:400]}\")\n",
    "    elif tipo == \"ToolMessage\":\n",
    "        print(f\"\\n[TOOL RESULT] {msg.content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a3b4c5",
   "metadata": {},
   "source": [
    "## 5. Structured Output con Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STRUCTURED OUTPUT CON PYDANTIC\n",
    "# ============================================================\n",
    "\n",
    "class ComicAnalysis(BaseModel):\n",
    "    \"\"\"Analisis estructurado de un personaje de comic.\"\"\"\n",
    "    personaje: str = Field(description=\"Nombre del personaje\")\n",
    "    fortalezas: list[str] = Field(description=\"Lista de fortalezas principales\")\n",
    "    debilidades: list[str] = Field(description=\"Lista de debilidades\")\n",
    "    nivel_poder: int = Field(description=\"Nivel de poder 1-100\", ge=1, le=100)\n",
    "    resumen: str = Field(description=\"Resumen en una oracion\")\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(ComicAnalysis)\n",
    "\n",
    "analysis = structured_llm.invoke(\"Analiza a Spider-Man como personaje de comic\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STRUCTURED OUTPUT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Personaje: {analysis.personaje}\")\n",
    "print(f\"Fortalezas: {analysis.fortalezas}\")\n",
    "print(f\"Debilidades: {analysis.debilidades}\")\n",
    "print(f\"Nivel de poder: {analysis.nivel_poder}/100\")\n",
    "print(f\"Resumen: {analysis.resumen}\")\n",
    "print(f\"\\nTipo: {type(analysis).__name__} (Pydantic validado)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5d6e7",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "1. `@tool` convierte funciones Python en herramientas invocables por el LLM\n",
    "2. `bind_tools()` conecta herramientas al modelo sin ejecutarlas\n",
    "3. La ejecucion de tools es **nuestra responsabilidad** (o de `ToolNode`)\n",
    "4. `ToolNode` + `StateGraph` automatizan el loop ReAct\n",
    "5. `with_structured_output()` garantiza respuestas tipadas con Pydantic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 5,
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}