{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 01: Bases de Datos Vectoriales - De Cero a Busqueda Semantica\n",
    "\n",
    "---\n",
    "\n",
    "**Curso:** AI Engineering | **Modulo:** RAG (Retrieval-Augmented Generation)\n",
    "\n",
    "**Autor:** Equipo de AI Engineering\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "\n",
    "Al finalizar este notebook, seras capaz de:\n",
    "\n",
    "1. **Comprender** que son los embeddings y por que son fundamentales en AI Engineering.\n",
    "2. **Generar** embeddings utilizando la API de OpenAI (`text-embedding-3-small`).\n",
    "3. **Visualizar** el espacio vectorial de embeddings mediante PCA y heatmaps de similitud.\n",
    "4. **Implementar** busqueda semantica usando ChromaDB como vector database.\n",
    "5. **Aplicar** filtrado por metadata para acotar resultados de busqueda.\n",
    "6. **Comparar** metricas de distancia (cosine, L2, inner product) y entender cuando usar cada una.\n",
    "7. **Realizar** operaciones CRUD completas sobre una coleccion de vectores.\n",
    "8. **Evaluar** distintas bases de datos vectoriales y elegir la adecuada para cada caso de uso.\n",
    "\n",
    "---\n",
    "\n",
    "> **Nota importante:** Este notebook asume que tienes configurada una API key de OpenAI en tu archivo `.env`.\n",
    "> Si no la tienes, revisa la guia de setup del curso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Que son los Embeddings?\n",
    "\n",
    "Un **embedding** es una representacion numerica (vector) de un dato — texto, imagen, audio — en un espacio de alta dimension. La clave es que **textos con significado similar producen vectores cercanos** en ese espacio.\n",
    "\n",
    "### Intuicion Visual\n",
    "\n",
    "```\n",
    "TEXTO                          VECTOR (espacio n-dimensional)\n",
    "================================  ====================================\n",
    "                                \n",
    "\"Politica de vacaciones\"   -->  [0.12, -0.45, 0.78, ..., 0.33]  ──┐\n",
    "                                                                    │ CERCANOS\n",
    "\"Dias libres del empleado\" -->  [0.14, -0.42, 0.75, ..., 0.31]  ──┘\n",
    "                                \n",
    "                                                                    \n",
    "\"Deploy a produccion\"      -->  [-0.67, 0.23, 0.11, ..., -0.89] ──┐\n",
    "                                                                    │ CERCANOS  \n",
    "\"CI/CD pipeline\"           -->  [-0.64, 0.25, 0.09, ..., -0.85] ──┘\n",
    "                                \n",
    "                                \n",
    "         ┌─────────────────────────────────────────┐\n",
    "         │     Espacio de Embeddings (2D aprox)     │\n",
    "         │                                         │\n",
    "         │   * vacaciones                          │\n",
    "         │     * dias libres      LEJOS            │\n",
    "         │                     <--------->         │\n",
    "         │                          * deploy       │\n",
    "         │                            * CI/CD      │\n",
    "         │                                         │\n",
    "         └─────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Por que importan?\n",
    "\n",
    "- **Busqueda semantica:** No buscamos por palabras exactas, sino por *significado*.\n",
    "- **RAG:** Recuperamos documentos relevantes para darle contexto a un LLM.\n",
    "- **Clustering:** Agrupamos documentos similares automaticamente.\n",
    "- **Recomendacion:** Encontramos items similares a lo que le gusto al usuario.\n",
    "\n",
    "### Dimensionalidad\n",
    "\n",
    "| Modelo                    | Dimensiones | Proveedor |\n",
    "|---------------------------|-------------|------------|\n",
    "| `text-embedding-3-small`  | 1536        | OpenAI     |\n",
    "| `text-embedding-3-large`  | 3072        | OpenAI     |\n",
    "| `text-embedding-ada-002`  | 1536        | OpenAI     |\n",
    "| `all-MiniLM-L6-v2`       | 384         | HuggingFace|\n",
    "\n",
    "En este notebook usaremos `text-embedding-3-small` por su excelente balance entre costo, velocidad y calidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup del Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SETUP: Importacion de librerias y configuracion del entorno\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Librerias principales ---\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import chromadb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# --- Carga de variables de entorno ---\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- Configuracion de matplotlib ---\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# --- Inicializar cliente de OpenAI ---\n",
    "client = OpenAI()  # Usa OPENAI_API_KEY del .env automaticamente\n",
    "\n",
    "# --- Verificacion ---\n",
    "print(\"=\" * 60)\n",
    "print(\"SETUP COMPLETADO\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"OpenAI version:    {openai.__version__}\")\n",
    "print(f\"ChromaDB version:  {chromadb.__version__}\")\n",
    "print(f\"NumPy version:     {np.__version__}\")\n",
    "print(f\"API Key cargada:   {'Si' if os.getenv('OPENAI_API_KEY') else 'No (REVISAR .env)'}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Crear Embeddings con OpenAI\n",
    "\n",
    "Vamos a construir una funcion helper que nos permita generar embeddings de forma sencilla. Esta funcion sera la base para todo lo que hagamos en el notebook.\n",
    "\n",
    "### La API de Embeddings\n",
    "\n",
    "```\n",
    "INPUT:  [\"texto 1\", \"texto 2\", ...]   (lista de strings)\n",
    "                    │\n",
    "                    ▼\n",
    "         ┌─────────────────┐\n",
    "         │  OpenAI API     │\n",
    "         │  /embeddings    │\n",
    "         └─────────────────┘\n",
    "                    │\n",
    "                    ▼\n",
    "OUTPUT: [[0.12, -0.45, ...], [0.78, 0.33, ...]]  (lista de vectores)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FUNCION HELPER: Generar embeddings con OpenAI\n",
    "# ==============================================================================\n",
    "\n",
    "def get_embeddings(texts: list[str], model: str = \"text-embedding-3-small\") -> list[list[float]]:\n",
    "    \"\"\"\n",
    "    Genera embeddings para una lista de textos usando la API de OpenAI.\n",
    "    \n",
    "    Args:\n",
    "        texts: Lista de strings a convertir en embeddings.\n",
    "        model: Modelo de embeddings a usar (default: text-embedding-3-small).\n",
    "    \n",
    "    Returns:\n",
    "        Lista de vectores (cada uno es una lista de floats).\n",
    "    \"\"\"\n",
    "    # Llamada a la API de OpenAI\n",
    "    response = client.embeddings.create(\n",
    "        input=texts,\n",
    "        model=model\n",
    "    )\n",
    "    \n",
    "    # Extraemos los vectores de la respuesta\n",
    "    embeddings = [item.embedding for item in response.data]\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# --- Verificacion rapida ---\n",
    "test_embedding = get_embeddings([\"Esto es una prueba\"])\n",
    "print(f\"Funcion get_embeddings funcionando correctamente.\")\n",
    "print(f\"Dimensiones del vector: {len(test_embedding[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CREAR EMBEDDINGS: 10 oraciones diversas (RRHH y Tech)\n",
    "# ==============================================================================\n",
    "\n",
    "# Definimos las oraciones organizadas por dominio\n",
    "oraciones_rrhh = [\n",
    "    \"La politica de vacaciones otorga 15 dias habiles al anio.\",               # 0\n",
    "    \"El proceso de onboarding para nuevos empleados dura dos semanas.\",         # 1\n",
    "    \"Las evaluaciones de desempenio se realizan cada seis meses.\",              # 2\n",
    "    \"El beneficio de home office aplica tres dias por semana.\",                 # 3\n",
    "    \"Los aumentos salariales se definen en la revision anual de compensaciones.\" # 4\n",
    "]\n",
    "\n",
    "oraciones_tech = [\n",
    "    \"El deploy a produccion se hace mediante el pipeline de CI/CD en GitHub Actions.\",  # 5\n",
    "    \"Usamos Docker y Kubernetes para orquestar los microservicios.\",                     # 6\n",
    "    \"La base de datos principal es PostgreSQL con replicas de lectura.\",                 # 7\n",
    "    \"El monitoreo de la aplicacion se realiza con Datadog y PagerDuty.\",                # 8\n",
    "    \"Las pruebas unitarias deben tener al menos 80 por ciento de coverage.\"             # 9\n",
    "]\n",
    "\n",
    "# Lista completa de oraciones\n",
    "todas_las_oraciones = oraciones_rrhh + oraciones_tech\n",
    "\n",
    "# Etiquetas para cada oracion (para visualizacion)\n",
    "etiquetas = [\n",
    "    \"Vacaciones\", \"Onboarding\", \"Evaluaciones\", \"Home office\", \"Salarios\",\n",
    "    \"Deploy/CI-CD\", \"Docker/K8s\", \"PostgreSQL\", \"Monitoreo\", \"Testing\"\n",
    "]\n",
    "\n",
    "# Dominio de cada oracion\n",
    "dominios = [\"rrhh\"] * 5 + [\"tech\"] * 5\n",
    "\n",
    "# --- Generar embeddings ---\n",
    "print(\"Generando embeddings para 10 oraciones...\")\n",
    "embeddings = get_embeddings(todas_las_oraciones)\n",
    "print(f\"Embeddings generados exitosamente.\\n\")\n",
    "\n",
    "# --- Mostrar resultados ---\n",
    "print(f\"{'#':<4} {'Etiqueta':<16} {'Dominio':<8} {'Dims':<6} {'Primeros 5 valores'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, (etiqueta, dominio, emb) in enumerate(zip(etiquetas, dominios, embeddings)):\n",
    "    primeros_5 = [f\"{v:+.4f}\" for v in emb[:5]]\n",
    "    print(f\"{i:<4} {etiqueta:<16} {dominio:<8} {len(emb):<6} {primeros_5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizar el Espacio de Embeddings\n",
    "\n",
    "Los embeddings viven en un espacio de 1536 dimensiones — imposible de visualizar directamente. Usamos **PCA (Principal Component Analysis)** para reducir a 2 dimensiones manteniendo la mayor varianza posible.\n",
    "\n",
    "### Que hace PCA?\n",
    "\n",
    "```\n",
    "Espacio original (1536D)    PCA     Espacio reducido (2D)\n",
    "┌─────────────────────┐   ------>  ┌──────────────────┐\n",
    "│ [0.12, -0.45, ...]  │           │ [1.23, -0.67]    │\n",
    "│ (1536 valores)      │           │ (2 valores)      │\n",
    "└─────────────────────┘           └──────────────────┘\n",
    "```\n",
    "\n",
    "**Advertencia:** PCA es una *aproximacion*. La estructura real del espacio es mucho mas rica. Pero es util para obtener una intuicion visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# VISUALIZACION: Reduccion con PCA y grafico 2D\n",
    "# ==============================================================================\n",
    "\n",
    "# Convertir embeddings a numpy array para PCA\n",
    "embeddings_array = np.array(embeddings)\n",
    "print(f\"Shape del array de embeddings: {embeddings_array.shape}\")\n",
    "\n",
    "# Aplicar PCA para reducir de 1536D a 2D\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(embeddings_array)\n",
    "\n",
    "print(f\"Varianza explicada por cada componente: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Varianza total explicada: {sum(pca.explained_variance_ratio_):.2%}\\n\")\n",
    "\n",
    "# --- Crear el grafico ---\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Colores por dominio\n",
    "colores = {'rrhh': '#2196F3', 'tech': '#FF5722'}  # Azul para RRHH, Naranja para Tech\n",
    "marcadores = {'rrhh': 'o', 'tech': 's'}           # Circulo para RRHH, Cuadrado para Tech\n",
    "\n",
    "# Graficar cada punto\n",
    "for i, (x, y) in enumerate(embeddings_2d):\n",
    "    dominio = dominios[i]\n",
    "    ax.scatter(\n",
    "        x, y,\n",
    "        c=colores[dominio],\n",
    "        marker=marcadores[dominio],\n",
    "        s=150,\n",
    "        edgecolors='black',\n",
    "        linewidths=0.5,\n",
    "        zorder=5\n",
    "    )\n",
    "    # Agregar etiqueta con un pequenio offset\n",
    "    ax.annotate(\n",
    "        etiquetas[i],\n",
    "        (x, y),\n",
    "        textcoords=\"offset points\",\n",
    "        xytext=(8, 8),\n",
    "        fontsize=9,\n",
    "        fontweight='bold',\n",
    "        color=colores[dominio]\n",
    "    )\n",
    "\n",
    "# Leyenda manual\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#2196F3',\n",
    "           markersize=12, label='RRHH', markeredgecolor='black'),\n",
    "    Line2D([0], [0], marker='s', color='w', markerfacecolor='#FF5722',\n",
    "           markersize=12, label='Tech', markeredgecolor='black')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper right', fontsize=12)\n",
    "\n",
    "# Configuracion del grafico\n",
    "ax.set_title('Espacio de Embeddings (PCA 2D)', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel(f'Componente Principal 1 ({pca.explained_variance_ratio_[0]:.1%} varianza)', fontsize=12)\n",
    "ax.set_ylabel(f'Componente Principal 2 ({pca.explained_variance_ratio_[1]:.1%} varianza)', fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObserva como los temas de RRHH tienden a agruparse juntos,\")\n",
    "print(\"separados de los temas de Tech. Esa es la magia de los embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Similitud Coseno Manual\n",
    "\n",
    "La **similitud coseno** mide el angulo entre dos vectores, ignorando su magnitud. Es la metrica mas usada en busqueda semantica.\n",
    "\n",
    "### Formula\n",
    "\n",
    "```\n",
    "                    A . B            Σ(ai * bi)\n",
    "cos(θ) = ──────────────────── = ─────────────────────\n",
    "             ||A|| * ||B||       √Σ(ai²) * √Σ(bi²)\n",
    "```\n",
    "\n",
    "### Interpretacion\n",
    "\n",
    "| Valor          | Significado                  |\n",
    "|----------------|------------------------------|\n",
    "| `1.0`          | Vectores identicos           |\n",
    "| `0.7 - 0.99`   | Muy similares               |\n",
    "| `0.3 - 0.7`    | Algo relacionados           |\n",
    "| `0.0`          | Sin relacion (ortogonales)  |\n",
    "| `-1.0`         | Completamente opuestos      |\n",
    "\n",
    "> **Nota:** Con embeddings de OpenAI, los valores tipicamente estan entre 0.0 y 1.0 ya que los vectores estan normalizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SIMILITUD COSENO: Implementacion manual con NumPy\n",
    "# ==============================================================================\n",
    "\n",
    "def cosine_similarity(a: list[float], b: list[float]) -> float:\n",
    "    \"\"\"\n",
    "    Calcula la similitud coseno entre dos vectores.\n",
    "    \n",
    "    Args:\n",
    "        a: Primer vector.\n",
    "        b: Segundo vector.\n",
    "    \n",
    "    Returns:\n",
    "        Similitud coseno (float entre -1 y 1).\n",
    "    \"\"\"\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    \n",
    "    # Producto punto\n",
    "    dot_product = np.dot(a, b)\n",
    "    \n",
    "    # Normas (magnitudes)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    \n",
    "    # Evitar division por cero\n",
    "    if norm_a == 0 or norm_b == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "\n",
    "# --- Definir pares de comparacion ---\n",
    "pares_comparacion = [\n",
    "    # (indice_a, indice_b, descripcion)\n",
    "    (0, 3, \"Vacaciones vs Home office (ambos RRHH)\"),\n",
    "    (5, 6, \"Deploy/CI-CD vs Docker/K8s (ambos Tech)\"),\n",
    "    (0, 1, \"Vacaciones vs Onboarding (ambos RRHH)\"),\n",
    "    (5, 8, \"Deploy/CI-CD vs Monitoreo (ambos Tech)\"),\n",
    "    (0, 5, \"Vacaciones vs Deploy (RRHH vs Tech)\"),\n",
    "    (1, 7, \"Onboarding vs PostgreSQL (RRHH vs Tech)\"),\n",
    "    (4, 9, \"Salarios vs Testing (RRHH vs Tech)\"),\n",
    "    (2, 8, \"Evaluaciones vs Monitoreo (RRHH vs Tech)\"),\n",
    "]\n",
    "\n",
    "# --- Calcular y mostrar resultados ---\n",
    "print(f\"{'Comparacion':<50} {'Similitud':>10} {'Interpretacion':>16}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for idx_a, idx_b, descripcion in pares_comparacion:\n",
    "    sim = cosine_similarity(embeddings[idx_a], embeddings[idx_b])\n",
    "    \n",
    "    # Interpretar el resultado\n",
    "    if sim >= 0.7:\n",
    "        interpretacion = \"Muy similar\"\n",
    "    elif sim >= 0.4:\n",
    "        interpretacion = \"Relacionado\"\n",
    "    else:\n",
    "        interpretacion = \"Poco similar\"\n",
    "    \n",
    "    # Barra visual proporcional\n",
    "    barra = \"█\" * int(sim * 20)\n",
    "    \n",
    "    print(f\"{descripcion:<50} {sim:>10.4f} {interpretacion:>16}  {barra}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Observa: las comparaciones dentro del mismo dominio tienen mayor similitud.\")\n",
    "print(\"Las comparaciones entre dominios distintos (RRHH vs Tech) son mas bajas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Introduccion a ChromaDB\n",
    "\n",
    "**ChromaDB** es una base de datos vectorial open-source, disenada para ser simple de usar y perfecta para prototipos y aplicaciones de mediana escala.\n",
    "\n",
    "### Conceptos Clave\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────┐\n",
    "│                   ChromaDB                       │\n",
    "│                                                  │\n",
    "│  ┌──────────────────────────────────────────┐   │\n",
    "│  │         Collection: \"novatech_docs\"       │   │\n",
    "│  │                                           │   │\n",
    "│  │  ID: \"doc_001\"                            │   │\n",
    "│  │  Document: \"La politica de vacaciones...\"  │   │\n",
    "│  │  Metadata: {domain: \"rrhh\", section: ...}  │   │\n",
    "│  │  Embedding: [0.12, -0.45, ...]             │   │\n",
    "│  │                                           │   │\n",
    "│  │  ID: \"doc_002\"                            │   │\n",
    "│  │  Document: \"El proceso de deploy...\"       │   │\n",
    "│  │  Metadata: {domain: \"tech\", section: ...}  │   │\n",
    "│  │  Embedding: [-0.67, 0.23, ...]             │   │\n",
    "│  │  ...                                      │   │\n",
    "│  └──────────────────────────────────────────┘   │\n",
    "└─────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Flujo de trabajo\n",
    "\n",
    "1. **Crear cliente** → Conexion a ChromaDB (en memoria o persistente).\n",
    "2. **Crear coleccion** → Define la metrica de distancia.\n",
    "3. **Agregar documentos** → ChromaDB genera embeddings automaticamente (o los provees tu).\n",
    "4. **Consultar** → Buscar documentos similares a un query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CHROMADB: Creacion del cliente y la coleccion\n",
    "# ==============================================================================\n",
    "\n",
    "# Crear cliente en memoria (ephemeral - para desarrollo y prototipado)\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "# Crear (o obtener si ya existe) una coleccion con distancia coseno\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=\"novatech_docs\",\n",
    "    metadata={\"hnsw:space\": \"cosine\"}  # Metrica de distancia: cosine\n",
    ")\n",
    "\n",
    "print(f\"Coleccion creada: '{collection.name}'\")\n",
    "print(f\"Metrica de distancia: cosine\")\n",
    "print(f\"Documentos actuales: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CHROMADB: Agregar documentos de la empresa ficticia NovaTech\n",
    "# ==============================================================================\n",
    "\n",
    "# Documentos de RRHH de NovaTech\n",
    "documentos_rrhh = [\n",
    "    \"NovaTech otorga 15 dias habiles de vacaciones al anio. Despues de 3 anios de antiguedad, se suman 2 dias adicionales por anio.\",\n",
    "    \"El proceso de onboarding en NovaTech dura 2 semanas e incluye sesiones con cada equipo, asignacion de buddy y configuracion de herramientas.\",\n",
    "    \"Las evaluaciones de desempenio en NovaTech se realizan semestralmente usando el framework de competencias OKR.\",\n",
    "    \"NovaTech ofrece modalidad hibrida: 3 dias de home office y 2 dias presenciales en la oficina de Buenos Aires.\",\n",
    "    \"Los ajustes salariales en NovaTech se revisan cada enero en base a desempenio, inflacion y bandas salariales del mercado.\",\n",
    "    \"NovaTech ofrece un plan de salud prepaga para el empleado y grupo familiar directo.\",\n",
    "    \"Las licencias por enfermedad en NovaTech requieren certificado medico a partir del segundo dia consecutivo.\",\n",
    "    \"NovaTech tiene un programa de referidos: si recomendas a alguien y es contratado, recibis un bono de USD 500.\"\n",
    "]\n",
    "\n",
    "# Documentos de Tech de NovaTech\n",
    "documentos_tech = [\n",
    "    \"El deploy a produccion en NovaTech se realiza mediante GitHub Actions. Todo merge a main dispara el pipeline de CI/CD automaticamente.\",\n",
    "    \"NovaTech usa Docker para containerizar servicios y Kubernetes (EKS) para la orquestacion en AWS.\",\n",
    "    \"La base de datos principal de NovaTech es PostgreSQL 15 en RDS, con replicas de lectura en us-east-1.\",\n",
    "    \"El monitoreo en NovaTech se hace con Datadog para metricas, Sentry para errores y PagerDuty para alertas on-call.\",\n",
    "    \"NovaTech exige un minimo de 80 por ciento de code coverage en tests unitarios. Usamos pytest como framework de testing.\",\n",
    "    \"El versionado de APIs en NovaTech sigue el patron /api/v1/, /api/v2/. Toda API nueva requiere documentacion en Swagger.\",\n",
    "    \"Los secrets y credenciales en NovaTech se gestionan con AWS Secrets Manager. Esta prohibido hardcodear secrets en el codigo.\",\n",
    "    \"NovaTech usa Redis como cache layer para sesiones de usuario y datos frecuentemente consultados. TTL por defecto: 1 hora.\"\n",
    "]\n",
    "\n",
    "# Combinar todos los documentos\n",
    "todos_los_documentos = documentos_rrhh + documentos_tech\n",
    "\n",
    "# Generar IDs unicos\n",
    "ids = [f\"doc_{i:03d}\" for i in range(len(todos_los_documentos))]\n",
    "\n",
    "# Crear metadata para cada documento\n",
    "secciones_rrhh = [\n",
    "    \"vacaciones\", \"onboarding\", \"evaluaciones\", \"modalidad_trabajo\",\n",
    "    \"compensaciones\", \"beneficios_salud\", \"licencias\", \"programa_referidos\"\n",
    "]\n",
    "secciones_tech = [\n",
    "    \"deploy_cicd\", \"infraestructura\", \"base_datos\", \"monitoreo\",\n",
    "    \"testing\", \"apis\", \"seguridad\", \"cache\"\n",
    "]\n",
    "\n",
    "metadatas = []\n",
    "for i, seccion in enumerate(secciones_rrhh):\n",
    "    metadatas.append({\"domain\": \"rrhh\", \"section\": seccion, \"company\": \"NovaTech\"})\n",
    "for i, seccion in enumerate(secciones_tech):\n",
    "    metadatas.append({\"domain\": \"tech\", \"section\": seccion, \"company\": \"NovaTech\"})\n",
    "\n",
    "# --- Agregar documentos a la coleccion ---\n",
    "# ChromaDB genera embeddings automaticamente usando su modelo por defecto\n",
    "collection.add(\n",
    "    documents=todos_los_documentos,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids\n",
    ")\n",
    "\n",
    "print(f\"Documentos agregados exitosamente a la coleccion '{collection.name}'.\")\n",
    "print(f\"Total de documentos: {collection.count()}\")\n",
    "print(f\"\\nDesglose:\")\n",
    "print(f\"  - RRHH: {len(documentos_rrhh)} documentos\")\n",
    "print(f\"  - Tech: {len(documentos_tech)} documentos\")\n",
    "\n",
    "# Mostrar los primeros 3 documentos como ejemplo\n",
    "print(f\"\\n--- Ejemplo de documentos cargados ---\")\n",
    "for i in range(3):\n",
    "    print(f\"\\n  ID: {ids[i]}\")\n",
    "    print(f\"  Domain: {metadatas[i]['domain']}\")\n",
    "    print(f\"  Section: {metadatas[i]['section']}\")\n",
    "    print(f\"  Documento: {todos_los_documentos[i][:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Busqueda por Similitud\n",
    "\n",
    "Ahora viene lo interesante: vamos a **buscar documentos usando lenguaje natural**. No necesitamos que la query contenga las mismas palabras que el documento — buscamos por *significado*.\n",
    "\n",
    "### Como funciona?\n",
    "\n",
    "```\n",
    "Query: \"cuantos dias de vacaciones tengo?\"\n",
    "           │\n",
    "           ▼\n",
    "    [embedding del query]\n",
    "           │\n",
    "           ▼\n",
    "    Comparar con TODOS los embeddings de la coleccion\n",
    "           │\n",
    "           ▼\n",
    "    Retornar los N documentos mas cercanos (menor distancia)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# BUSQUEDA SEMANTICA: Query sobre vacaciones (deberia devolver docs de RRHH)\n",
    "# ==============================================================================\n",
    "\n",
    "def mostrar_resultados(resultados: dict, query: str) -> None:\n",
    "    \"\"\"Muestra los resultados de una query de ChromaDB de forma formateada.\"\"\"\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"QUERY: \\\"{query}\\\"\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    \n",
    "    documentos = resultados['documents'][0]\n",
    "    distancias = resultados['distances'][0]\n",
    "    metadatas = resultados['metadatas'][0]\n",
    "    ids = resultados['ids'][0]\n",
    "    \n",
    "    for i, (doc, dist, meta, doc_id) in enumerate(zip(documentos, distancias, metadatas, ids)):\n",
    "        similitud = 1 - dist  # Para metrica cosine, distancia = 1 - similitud\n",
    "        barra = \"█\" * int(similitud * 30)\n",
    "        \n",
    "        print(f\"\\n  [{i+1}] ID: {doc_id} | Domain: {meta['domain']} | Section: {meta['section']}\")\n",
    "        print(f\"      Distancia: {dist:.4f} | Similitud: {similitud:.4f}  {barra}\")\n",
    "        print(f\"      Documento: {doc[:100]}{'...' if len(doc) > 100 else ''}\")\n",
    "\n",
    "\n",
    "# --- Query 1: Vacaciones (tema de RRHH) ---\n",
    "query_vacaciones = \"cuantos dias de vacaciones tengo?\"\n",
    "\n",
    "resultados_vacaciones = collection.query(\n",
    "    query_texts=[query_vacaciones],\n",
    "    n_results=5\n",
    ")\n",
    "\n",
    "mostrar_resultados(resultados_vacaciones, query_vacaciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# BUSQUEDA SEMANTICA: Query sobre deploy (deberia devolver docs de Tech)\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Query 2: Deploy a produccion (tema de Tech) ---\n",
    "query_deploy = \"como hago deploy a produccion?\"\n",
    "\n",
    "resultados_deploy = collection.query(\n",
    "    query_texts=[query_deploy],\n",
    "    n_results=5\n",
    ")\n",
    "\n",
    "mostrar_resultados(resultados_deploy, query_deploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# ANALISIS: Por que estos resultados tienen sentido?\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"ANALISIS DE RESULTADOS\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"Query 1: 'cuantos dias de vacaciones tengo?'\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Los resultados principales son documentos de RRHH, con\")\n",
    "print(\"el documento de vacaciones en primer lugar. Esto es correcto\")\n",
    "print(\"porque la busqueda semantica entiende el SIGNIFICADO, no\")\n",
    "print(\"solo las palabras.\")\n",
    "print()\n",
    "print(\"Query 2: 'como hago deploy a produccion?'\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Los resultados principales son documentos de Tech, con\")\n",
    "print(\"el documento de CI/CD en primer lugar. Observa que incluso\")\n",
    "print(\"documentos de infraestructura (Docker/K8s) aparecen como\")\n",
    "print(\"relevantes, ya que estan semanticamente relacionados con deploy.\")\n",
    "print()\n",
    "print(\"CONCLUSION: La busqueda semantica agrupa resultados por\")\n",
    "print(\"significado, no por coincidencia de palabras clave.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Filtrado por Metadata\n",
    "\n",
    "Ademas de la busqueda semantica, ChromaDB permite **filtrar por metadata**. Esto es crucial en aplicaciones reales donde necesitas acotar la busqueda a un subconjunto de documentos.\n",
    "\n",
    "### Casos de uso tipicos\n",
    "\n",
    "- Filtrar por **departamento** (solo documentos de RRHH)\n",
    "- Filtrar por **fecha** (solo documentos actualizados este anio)\n",
    "- Filtrar por **nivel de acceso** (solo documentos publicos)\n",
    "- Filtrar por **idioma** (solo documentos en espaniol)\n",
    "\n",
    "### Sintaxis de filtro en ChromaDB\n",
    "\n",
    "```python\n",
    "# Igualdad\n",
    "where={\"domain\": \"rrhh\"}\n",
    "\n",
    "# Operadores logicos\n",
    "where={\"$and\": [{\"domain\": \"tech\"}, {\"section\": \"deploy_cicd\"}]}\n",
    "where={\"$or\": [{\"domain\": \"rrhh\"}, {\"section\": \"seguridad\"}]}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FILTRADO POR METADATA: Comparar resultados con y sin filtro\n",
    "# ==============================================================================\n",
    "\n",
    "# Query ambigua que podria traer resultados de ambos dominios\n",
    "query_ambigua = \"cual es la politica de la empresa?\"\n",
    "\n",
    "# --- Sin filtro ---\n",
    "print(\"\\n\" + \"#\" * 80)\n",
    "print(\"# SIN FILTRO DE METADATA\")\n",
    "print(\"#\" * 80)\n",
    "\n",
    "resultados_sin_filtro = collection.query(\n",
    "    query_texts=[query_ambigua],\n",
    "    n_results=5\n",
    ")\n",
    "mostrar_resultados(resultados_sin_filtro, query_ambigua)\n",
    "\n",
    "# --- Con filtro: solo RRHH ---\n",
    "print(\"\\n\" + \"#\" * 80)\n",
    "print(\"# CON FILTRO: domain = 'rrhh'\")\n",
    "print(\"#\" * 80)\n",
    "\n",
    "resultados_rrhh = collection.query(\n",
    "    query_texts=[query_ambigua],\n",
    "    n_results=5,\n",
    "    where={\"domain\": \"rrhh\"}\n",
    ")\n",
    "mostrar_resultados(resultados_rrhh, query_ambigua + \" [FILTRO: RRHH]\")\n",
    "\n",
    "# --- Con filtro: solo Tech ---\n",
    "print(\"\\n\" + \"#\" * 80)\n",
    "print(\"# CON FILTRO: domain = 'tech'\")\n",
    "print(\"#\" * 80)\n",
    "\n",
    "resultados_tech = collection.query(\n",
    "    query_texts=[query_ambigua],\n",
    "    n_results=5,\n",
    "    where={\"domain\": \"tech\"}\n",
    ")\n",
    "mostrar_resultados(resultados_tech, query_ambigua + \" [FILTRO: Tech]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FILTRADO POR METADATA: Discusion sobre cuando es critico\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"CUANDO EL FILTRADO POR METADATA ES CRITICO\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"1. MULTI-TENANCY (multiples clientes):\")\n",
    "print(\"   Si tu base de datos tiene documentos de diferentes\")\n",
    "print(\"   clientes, DEBES filtrar por tenant_id para evitar\")\n",
    "print(\"   que un cliente vea informacion de otro.\")\n",
    "print()\n",
    "print(\"2. PERMISOS DE ACCESO:\")\n",
    "print(\"   Un empleado junior no deberia ver documentos\")\n",
    "print(\"   clasificados como 'confidencial' o 'directivos'.\")\n",
    "print()\n",
    "print(\"3. CONTEXTO DEL CHAT:\")\n",
    "print(\"   Si el usuario esta en la seccion de RRHH del chatbot,\")\n",
    "print(\"   filtrar solo documentos de RRHH mejora la relevancia\")\n",
    "print(\"   y evita respuestas fuera de contexto.\")\n",
    "print()\n",
    "print(\"4. VERSIONADO DE DOCUMENTOS:\")\n",
    "print(\"   Filtrar por 'version: latest' para no devolver\")\n",
    "print(\"   documentos desactualizados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Comparacion de Metricas de Distancia\n",
    "\n",
    "ChromaDB soporta tres metricas de distancia. Entender las diferencias es importante para elegir la correcta.\n",
    "\n",
    "### Las tres metricas\n",
    "\n",
    "| Metrica           | Formula                          | Rango           | Mejor para                        |\n",
    "|-------------------|----------------------------------|-----------------|------------------------------------|\n",
    "| **Cosine**        | `1 - cos(A, B)`                  | `[0, 2]`        | Textos, cuando la magnitud no importa |\n",
    "| **L2 (Euclidean)**| `√Σ(ai - bi)²`                  | `[0, ∞)`        | Datos donde la magnitud importa    |\n",
    "| **IP (Inner Product)** | `-Σ(ai * bi)`               | `(-∞, ∞)`       | Vectores normalizados, ranking     |\n",
    "\n",
    "> **Regla general:** Si usas embeddings de OpenAI (que estan normalizados), **cosine** e **IP** dan resultados equivalentes. **L2** puede dar un ordenamiento ligeramente diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# COMPARACION DE METRICAS: Crear 3 colecciones con diferentes distancias\n",
    "# ==============================================================================\n",
    "\n",
    "# Definir las metricas a comparar\n",
    "metricas = {\n",
    "    \"cosine\": \"cosine\",\n",
    "    \"l2\": \"l2\",\n",
    "    \"ip\": \"ip\"\n",
    "}\n",
    "\n",
    "colecciones_metricas = {}\n",
    "\n",
    "for nombre, metrica in metricas.items():\n",
    "    # Crear coleccion con la metrica especificada\n",
    "    col = chroma_client.get_or_create_collection(\n",
    "        name=f\"novatech_{nombre}\",\n",
    "        metadata={\"hnsw:space\": metrica}\n",
    "    )\n",
    "    \n",
    "    # Agregar los mismos documentos a cada coleccion\n",
    "    col.add(\n",
    "        documents=todos_los_documentos,\n",
    "        metadatas=metadatas,\n",
    "        ids=ids\n",
    "    )\n",
    "    \n",
    "    colecciones_metricas[nombre] = col\n",
    "    print(f\"Coleccion '{col.name}' creada con metrica '{metrica}' - {col.count()} docs\")\n",
    "\n",
    "print(f\"\\n3 colecciones creadas con los mismos {len(todos_los_documentos)} documentos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# COMPARACION DE METRICAS: Misma query, diferentes metricas\n",
    "# ==============================================================================\n",
    "\n",
    "query_comparacion = \"como funciona el sistema de monitoreo?\"\n",
    "n_resultados = 5\n",
    "\n",
    "print(f\"QUERY: \\\"{query_comparacion}\\\"\")\n",
    "print(f\"Comparando top {n_resultados} resultados con cada metrica:\\n\")\n",
    "\n",
    "# Encabezado de la tabla\n",
    "print(f\"{'Rank':<6} {'COSINE':<30} {'L2':<30} {'IP':<30}\")\n",
    "print(f\"{'':6} {'ID':10} {'Dist':>8} {'Sec':>10} {'ID':10} {'Dist':>8} {'Sec':>10} {'ID':10} {'Dist':>8} {'Sec':>10}\")\n",
    "print(\"-\" * 96)\n",
    "\n",
    "# Ejecutar la misma query en las 3 colecciones\n",
    "resultados_por_metrica = {}\n",
    "for nombre, col in colecciones_metricas.items():\n",
    "    resultados_por_metrica[nombre] = col.query(\n",
    "        query_texts=[query_comparacion],\n",
    "        n_results=n_resultados\n",
    "    )\n",
    "\n",
    "# Mostrar resultados lado a lado\n",
    "for rank in range(n_resultados):\n",
    "    fila = f\"{rank+1:<6} \"\n",
    "    for nombre in [\"cosine\", \"l2\", \"ip\"]:\n",
    "        res = resultados_por_metrica[nombre]\n",
    "        doc_id = res['ids'][0][rank]\n",
    "        dist = res['distances'][0][rank]\n",
    "        sec = res['metadatas'][0][rank]['section']\n",
    "        fila += f\"{doc_id:10} {dist:>8.4f} {sec:>10} \"\n",
    "    print(fila)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 96)\n",
    "print(\"Observa: el ORDEN de los resultados puede variar entre metricas,\")\n",
    "print(\"pero los documentos mas relevantes tienden a aparecer en las 3.\")\n",
    "print(\"Con embeddings normalizados (OpenAI), cosine e IP son casi equivalentes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Operaciones CRUD\n",
    "\n",
    "Una base de datos vectorial no solo sirve para buscar. Necesitamos poder **crear**, **leer**, **actualizar** y **eliminar** documentos.\n",
    "\n",
    "```\n",
    "C - Create  →  collection.add()\n",
    "R - Read    →  collection.get()\n",
    "U - Update  →  collection.update()\n",
    "D - Delete  →  collection.delete()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CRUD: Operaciones completas sobre la coleccion\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"OPERACIONES CRUD EN CHROMADB\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# --- READ: Obtener documento por ID ---\n",
    "print(\"\\n1. READ - Obtener documento por ID\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "doc_obtenido = collection.get(\n",
    "    ids=[\"doc_000\"],\n",
    "    include=[\"documents\", \"metadatas\"]\n",
    ")\n",
    "\n",
    "print(f\"   ID: {doc_obtenido['ids'][0]}\")\n",
    "print(f\"   Metadata: {doc_obtenido['metadatas'][0]}\")\n",
    "print(f\"   Documento: {doc_obtenido['documents'][0][:80]}...\")\n",
    "\n",
    "# --- COUNT: Contar documentos ---\n",
    "print(f\"\\n   Total documentos en coleccion: {collection.count()}\")\n",
    "\n",
    "# --- UPDATE: Actualizar un documento ---\n",
    "print(\"\\n2. UPDATE - Actualizar documento doc_000\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "nuevo_texto = \"NovaTech ahora otorga 20 dias habiles de vacaciones al anio (actualizado 2026). Despues de 2 anios de antiguedad, se suman 3 dias adicionales por anio.\"\n",
    "\n",
    "collection.update(\n",
    "    ids=[\"doc_000\"],\n",
    "    documents=[nuevo_texto],\n",
    "    metadatas=[{\"domain\": \"rrhh\", \"section\": \"vacaciones\", \"company\": \"NovaTech\", \"updated\": \"2026-01\"}]\n",
    ")\n",
    "\n",
    "# Verificar el update\n",
    "doc_actualizado = collection.get(\n",
    "    ids=[\"doc_000\"],\n",
    "    include=[\"documents\", \"metadatas\"]\n",
    ")\n",
    "print(f\"   Documento actualizado: {doc_actualizado['documents'][0][:80]}...\")\n",
    "print(f\"   Metadata actualizada: {doc_actualizado['metadatas'][0]}\")\n",
    "\n",
    "# --- DELETE: Eliminar un documento ---\n",
    "print(\"\\n3. DELETE - Eliminar documento doc_007\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(f\"   Documentos antes de eliminar: {collection.count()}\")\n",
    "\n",
    "collection.delete(ids=[\"doc_007\"])\n",
    "\n",
    "print(f\"   Documentos despues de eliminar: {collection.count()}\")\n",
    "\n",
    "# Verificar que ya no existe\n",
    "doc_eliminado = collection.get(ids=[\"doc_007\"])\n",
    "print(f\"   Documento doc_007 existe: {len(doc_eliminado['ids']) > 0}\")\n",
    "\n",
    "# --- GET: Obtener multiples documentos ---\n",
    "print(\"\\n4. GET - Obtener multiples documentos por ID\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "docs_multiples = collection.get(\n",
    "    ids=[\"doc_000\", \"doc_005\", \"doc_010\"],\n",
    "    include=[\"documents\", \"metadatas\"]\n",
    ")\n",
    "\n",
    "for doc_id, doc, meta in zip(docs_multiples['ids'], docs_multiples['documents'], docs_multiples['metadatas']):\n",
    "    print(f\"   {doc_id} [{meta['domain']}] -> {doc[:60]}...\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"Estado final de la coleccion: {collection.count()} documentos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualizacion Avanzada: Heatmap de Similitud\n",
    "\n",
    "Para entender la estructura de nuestro corpus de documentos, vamos a crear un **heatmap de similitud** que muestra que tan similar es cada par de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# HEATMAP DE SIMILITUD: Matriz de similitud entre todos los documentos\n",
    "# ==============================================================================\n",
    "\n",
    "# Obtener todos los documentos de la coleccion\n",
    "todos_docs = collection.get(\n",
    "    include=[\"documents\", \"metadatas\", \"embeddings\"]\n",
    ")\n",
    "\n",
    "n_docs = len(todos_docs['ids'])\n",
    "print(f\"Calculando matriz de similitud para {n_docs} documentos...\")\n",
    "\n",
    "# Obtener embeddings (ChromaDB los genera internamente)\n",
    "# Usamos los embeddings almacenados en ChromaDB\n",
    "doc_embeddings = np.array(todos_docs['embeddings'])\n",
    "\n",
    "# Calcular la matriz de similitud coseno\n",
    "# Para vectores normalizados: similitud = producto punto\n",
    "# Forma general: sim(a, b) = (a . b) / (||a|| * ||b||)\n",
    "normas = np.linalg.norm(doc_embeddings, axis=1, keepdims=True)\n",
    "embeddings_normalizados = doc_embeddings / normas\n",
    "matriz_similitud = np.dot(embeddings_normalizados, embeddings_normalizados.T)\n",
    "\n",
    "print(f\"Shape de la matriz de similitud: {matriz_similitud.shape}\")\n",
    "\n",
    "# Crear etiquetas abreviadas para el heatmap\n",
    "etiquetas_abreviadas = []\n",
    "for doc_id, meta in zip(todos_docs['ids'], todos_docs['metadatas']):\n",
    "    prefijo = \"RH\" if meta['domain'] == 'rrhh' else \"TK\"\n",
    "    seccion = meta['section'][:8]\n",
    "    etiquetas_abreviadas.append(f\"{prefijo}:{seccion}\")\n",
    "\n",
    "# --- Crear el heatmap ---\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Graficar la matriz con imshow\n",
    "im = ax.imshow(matriz_similitud, cmap='RdYlBu_r', vmin=0.5, vmax=1.0, aspect='auto')\n",
    "\n",
    "# Configurar ejes\n",
    "ax.set_xticks(range(n_docs))\n",
    "ax.set_yticks(range(n_docs))\n",
    "ax.set_xticklabels(etiquetas_abreviadas, rotation=45, ha='right', fontsize=8)\n",
    "ax.set_yticklabels(etiquetas_abreviadas, fontsize=8)\n",
    "\n",
    "# Agregar valores numericos en cada celda\n",
    "for i in range(n_docs):\n",
    "    for j in range(n_docs):\n",
    "        valor = matriz_similitud[i, j]\n",
    "        color_texto = 'white' if valor > 0.85 else 'black'\n",
    "        ax.text(j, i, f'{valor:.2f}', ha='center', va='center',\n",
    "                fontsize=6, color=color_texto)\n",
    "\n",
    "# Barra de color\n",
    "cbar = plt.colorbar(im, ax=ax, shrink=0.8)\n",
    "cbar.set_label('Similitud Coseno', fontsize=12)\n",
    "\n",
    "# Titulo y formato\n",
    "ax.set_title('Heatmap de Similitud entre Documentos de NovaTech', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Agregar lineas separadoras entre dominios RRHH y Tech\n",
    "# Encontrar el indice donde cambia de RRHH a Tech\n",
    "dominios_docs = [m['domain'] for m in todos_docs['metadatas']]\n",
    "n_rrhh = sum(1 for d in dominios_docs if d == 'rrhh')\n",
    "\n",
    "ax.axhline(y=n_rrhh - 0.5, color='black', linewidth=2, linestyle='--')\n",
    "ax.axvline(x=n_rrhh - 0.5, color='black', linewidth=2, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nLa linea punteada separa documentos de RRHH (arriba/izquierda)\")\n",
    "print(\"de documentos Tech (abajo/derecha).\")\n",
    "print(\"Observa que los bloques diagonales (mismo dominio) son mas claros\")\n",
    "print(\"(mayor similitud) que los bloques cruzados (dominios diferentes).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Comparativa de Bases de Datos Vectoriales\n",
    "\n",
    "ChromaDB es excelente para prototipos y proyectos pequenios a medianos, pero existen muchas otras opciones. Aqui una comparativa para ayudarte a elegir.\n",
    "\n",
    "### Tabla Comparativa\n",
    "\n",
    "| Caracteristica       | ChromaDB       | FAISS           | Pinecone        | Weaviate        | Qdrant          | pgvector        |\n",
    "|----------------------|----------------|-----------------|-----------------|-----------------|-----------------|------------------|\n",
    "| **Tipo**             | Embedded DB    | Libreria        | Managed Cloud   | Self-hosted/Cloud| Self-hosted/Cloud| Extension PG    |\n",
    "| **Open Source**      | Si             | Si              | No              | Si              | Si              | Si              |\n",
    "| **Lenguaje**         | Python         | C++ (Python API)| API REST        | Go              | Rust            | C (PostgreSQL)  |\n",
    "| **Persistencia**     | In-memory/Disco| In-memory       | Cloud           | Disco           | Disco           | PostgreSQL      |\n",
    "| **Escalabilidad**    | Baja-Media     | Alta (single node)| Muy alta      | Alta            | Alta            | Media-Alta      |\n",
    "| **Filtrado Metadata**| Si             | Limitado        | Si              | Si (GraphQL)    | Si (rico)       | Si (SQL!)       |\n",
    "| **Setup**            | 1 linea        | Moderado        | API key         | Docker          | Docker/Cloud    | Extension PG    |\n",
    "| **Mejor para**       | Prototipo, POC | Alta velocidad  | Produccion SaaS | Apps complejas  | Produccion alto rendimiento | Ya usas PostgreSQL |\n",
    "| **Pricing**          | Gratis         | Gratis          | Freemium        | Gratis/Paid     | Gratis/Paid     | Gratis          |\n",
    "\n",
    "### Cuando usar cada una?\n",
    "\n",
    "- **ChromaDB:** Queres arrancar rapido, prototipar, o tu dataset es < 100K documentos. Ideal para este curso.\n",
    "- **FAISS (Facebook AI):** Necesitas velocidad extrema en un solo nodo. Ideal para busqueda offline o batch.\n",
    "- **Pinecone:** Queres un servicio managed sin preocuparte por infraestructura. Ideal para startups en produccion.\n",
    "- **Weaviate:** Necesitas queries complejas con GraphQL y funcionalidades de ML integradas.\n",
    "- **Qdrant:** Necesitas alto rendimiento con filtrado avanzado. Excelente para produccion on-premise.\n",
    "- **pgvector:** Ya tenes PostgreSQL en tu stack y no queres agregar otra base de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Errores Comunes\n",
    "\n",
    "Despues de trabajar con cientos de estudiantes, estos son los errores mas frecuentes que vemos:\n",
    "\n",
    "### Error 1: No normalizar los textos antes de generar embeddings\n",
    "\n",
    "```python\n",
    "# MAL: textos con whitespace inconsistente\n",
    "textos = [\"  Hola mundo  \", \"Hola\\n\\nmundo\", \"HOLA MUNDO\"]\n",
    "\n",
    "# BIEN: limpiar antes de embeddear\n",
    "textos = [t.strip().lower() for t in textos]\n",
    "```\n",
    "\n",
    "**Por que importa:** El modelo de embeddings es sensible a diferencias en formato. Un mismo texto con diferente whitespace puede producir embeddings ligeramente distintos.\n",
    "\n",
    "---\n",
    "\n",
    "### Error 2: No incluir metadata relevante desde el inicio\n",
    "\n",
    "```python\n",
    "# MAL: agregar documentos sin metadata\n",
    "collection.add(documents=[...], ids=[...])\n",
    "\n",
    "# BIEN: agregar metadata desde el inicio\n",
    "collection.add(\n",
    "    documents=[...],\n",
    "    ids=[...],\n",
    "    metadatas=[{\"source\": \"...\", \"domain\": \"...\", \"date\": \"...\"}]\n",
    ")\n",
    "```\n",
    "\n",
    "**Por que importa:** Agregar metadata despues es costoso y propenso a errores. Pensalo como parte del schema desde el dia 1.\n",
    "\n",
    "---\n",
    "\n",
    "### Error 3: Chunks demasiado grandes o demasiado pequenios\n",
    "\n",
    "```python\n",
    "# MAL: embeddear un documento entero de 50 paginas\n",
    "embedding = get_embeddings([documento_completo])  # Pierde precision semantica\n",
    "\n",
    "# MAL: chunks de una sola oracion\n",
    "chunks = documento.split(\".\")  # Pierde contexto\n",
    "\n",
    "# BIEN: chunks de 200-500 tokens con overlap\n",
    "chunks = chunk_text(documento, chunk_size=400, overlap=50)\n",
    "```\n",
    "\n",
    "**Por que importa:** Chunks muy grandes diluyen el significado. Chunks muy chicos pierden contexto. El chunking strategy es uno de los factores mas importantes en la calidad de un sistema RAG.\n",
    "\n",
    "---\n",
    "\n",
    "### Error 4: Confundir distancia con similitud\n",
    "\n",
    "```python\n",
    "# MAL: pensar que mayor distancia = mas similar\n",
    "# En ChromaDB con cosine, menor distancia = mas similar\n",
    "\n",
    "# Distancia coseno = 1 - similitud coseno\n",
    "# distancia 0.1 → similitud 0.9 (MUY similar)\n",
    "# distancia 0.8 → similitud 0.2 (poco similar)\n",
    "```\n",
    "\n",
    "**Por que importa:** Interpretar los resultados al reves lleva a seleccionar los documentos *menos* relevantes.\n",
    "\n",
    "---\n",
    "\n",
    "### Error 5: No considerar el costo de las llamadas a la API de embeddings\n",
    "\n",
    "```python\n",
    "# MAL: generar embeddings en cada request\n",
    "for query in user_queries:\n",
    "    emb = get_embeddings([query])  # $$ por cada query\n",
    "    # ... buscar\n",
    "\n",
    "# BIEN: cachear embeddings de documentos, solo generar embedding del query\n",
    "# Los documentos se embeddean UNA VEZ y se almacenan en la vector DB\n",
    "# Solo el query necesita embedding en runtime\n",
    "```\n",
    "\n",
    "**Por que importa:** `text-embedding-3-small` cuesta ~$0.02 por millon de tokens. Parece poco, pero a escala suma rapido si re-generas embeddings innecesariamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Checklist de Consolidacion\n",
    "\n",
    "Antes de pasar al siguiente notebook, asegurate de poder responder estas preguntas:\n",
    "\n",
    "- [ ] **1.** Que es un embedding y por que textos semanticamente similares producen vectores cercanos?\n",
    "\n",
    "- [ ] **2.** Cual es la diferencia entre similitud coseno y distancia coseno? Si ChromaDB me devuelve una distancia de 0.15, la similitud es alta o baja?\n",
    "\n",
    "- [ ] **3.** Por que el filtrado por metadata es critico en aplicaciones multi-tenant? Que podria pasar si no lo implementamos?\n",
    "\n",
    "- [ ] **4.** Si tengo 1 millon de documentos y necesito busqueda semantica en produccion con alta disponibilidad, que base de datos vectorial elegirias y por que?\n",
    "\n",
    "- [ ] **5.** Explica con tus palabras por que el tamanio del chunk afecta la calidad de la busqueda semantica. Que pasaria con chunks de 1 palabra? Y con chunks de 10,000 palabras?\n",
    "\n",
    "---\n",
    "\n",
    "### Siguiente Notebook\n",
    "\n",
    "En el **Notebook 02** vamos a construir un sistema RAG completo, combinando lo que aprendimos aqui de vector databases con un LLM para generar respuestas contextualizadas.\n",
    "\n",
    "---\n",
    "\n",
    "*Fin del Notebook 01: Bases de Datos Vectoriales*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
