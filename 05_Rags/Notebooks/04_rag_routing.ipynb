{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 04: RAG con Routing - Agente Multi-Dominio que Clasifica y Delega\n",
    "\n",
    "**Modulo 05 - RAG (Retrieval-Augmented Generation) | AI Engineering - Henry**\n",
    "\n",
    "---\n",
    "\n",
    "## Contexto\n",
    "\n",
    "En los notebooks anteriores construimos los fundamentos:\n",
    "- **Notebook 01**: RAG basico con embeddings y retrieval sobre una sola base de conocimiento.\n",
    "- **Notebook 02**: Chunking strategies y optimizacion de la calidad de retrieval.\n",
    "- **Notebook 03**: RAG con Prompt Chaining - encadenando pasos de razonamiento.\n",
    "\n",
    "Ahora damos el siguiente salto: **Routing**. Un sistema RAG que primero **clasifica la intencion** del usuario y luego **delega a un agente especializado** segun el dominio detectado.\n",
    "\n",
    "## Objetivos de aprendizaje\n",
    "\n",
    "1. Entender **por que** un sistema multi-dominio necesita routing en lugar de un solo retriever.\n",
    "2. Implementar un **clasificador de intencion** usando LLM con structured output.\n",
    "3. Construir **agentes RAG especializados** por dominio (Productos y Tecnica).\n",
    "4. Orquestar todo con **LangGraph**: nodos, edges condicionales y estado compartido.\n",
    "5. Evaluar el impacto del **umbral de confianza** en las decisiones de routing.\n",
    "6. Comparar routing vs single retriever para entender las ventajas.\n",
    "\n",
    "## Empresa: NovaTech Solutions\n",
    "\n",
    "Trabajamos con dos dominios de conocimiento:\n",
    "- **PRODUCTOS**: Informacion de productos, precios, features, planes (Analytics Pro, DataSync, AI Assistant).\n",
    "- **TECNICA**: Operaciones tecnicas, deploys, troubleshooting, monitoreo, seguridad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Por que Routing para RAG?\n",
    "\n",
    "### El problema del retriever unico\n",
    "\n",
    "Imagina que tienes una empresa con documentacion de **productos** (precios, features, planes) y documentacion **tecnica** (deploys, Kubernetes, troubleshooting). Si indexas todo junto en una sola coleccion:\n",
    "\n",
    "- La query \"cuanto cuesta el plan Enterprise?\" podria traer chunks de troubleshooting que mencionan \"Enterprise\" por contexto.\n",
    "- La query \"como hago rollback?\" podria traer chunks de producto que mencionan \"rollback automatico\" en features.\n",
    "- El retriever no tiene **contexto semantico del dominio** -- solo busca similitud vectorial.\n",
    "\n",
    "### La solucion: clasificar y delegar\n",
    "\n",
    "```\n",
    "                        +---------------------+\n",
    "                        |    User Query        |\n",
    "                        +----------+----------+\n",
    "                                   |\n",
    "                                   v\n",
    "                        +---------------------+\n",
    "                        | Intent Classifier   |\n",
    "                        | (LLM + Structured   |\n",
    "                        |  Output)            |\n",
    "                        +----+------+----+----+\n",
    "                             |      |    |\n",
    "                   PRODUCTOS |      |    | UNKNOWN\n",
    "                             |      |    |\n",
    "                             v      |    v\n",
    "                  +----------+--+   |  +-+----------+\n",
    "                  | Product RAG |   |  |  Fallback  |\n",
    "                  | Agent       |   |  |  Agent     |\n",
    "                  +----------+--+   |  +-+----------+\n",
    "                             |      |    |\n",
    "                             |  TECNICA  |\n",
    "                             |      |    |\n",
    "                             |      v    |\n",
    "                             | +----+------+\n",
    "                             | | Tech RAG  |\n",
    "                             | | Agent     |\n",
    "                             | +----+------+\n",
    "                             |      |    |\n",
    "                             v      v    v\n",
    "                        +---------------------+\n",
    "                        |   Respuesta Final   |\n",
    "                        +---------------------+\n",
    "```\n",
    "\n",
    "### Ventajas del routing\n",
    "\n",
    "| Aspecto | Single Retriever | Routing |\n",
    "|---------|-----------------|----------|\n",
    "| Precision de retrieval | Contaminacion entre dominios | Busqueda aislada por dominio |\n",
    "| Prompt del LLM | Generico, sin contexto de dominio | Especializado por dominio |\n",
    "| Escalabilidad | Agregar docs degrada todo | Agregar un dominio nuevo es independiente |\n",
    "| Trazabilidad | No sabes por que eligio ciertos docs | Sabes que dominio y por que |\n",
    "| Costo | Siempre busca en todo | Solo busca en el dominio relevante |\n",
    "\n",
    "### Cuando usar routing vs single retriever\n",
    "\n",
    "- **Single retriever**: Documentacion homogenea, un solo tema, base pequena (<100 docs).\n",
    "- **Routing**: Multiples dominios, tipos de pregunta distintos, necesidad de respuestas especializadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Arquitectura del Sistema\n",
    "\n",
    "### Grafo completo con LangGraph\n",
    "\n",
    "```\n",
    "+-------------------------------------------------------------------+\n",
    "|                         RouterState                               |\n",
    "|  query | intent | retrieved_docs | response | route | steps_trace |\n",
    "+-------------------------------------------------------------------+\n",
    "                              |\n",
    "                              v\n",
    "                    [classify_intent]\n",
    "                    Nodo de entrada\n",
    "                    - Recibe query\n",
    "                    - LLM clasifica intent\n",
    "                    - Retorna: intent, confidence, reasoning\n",
    "                              |\n",
    "                    (conditional edge)\n",
    "                    route_by_intent()\n",
    "                              |\n",
    "            +-----------------+-----------------+\n",
    "            |                 |                 |\n",
    "            v                 v                 v\n",
    "   [product_agent]    [tech_agent]       [fallback]\n",
    "   confidence >= 0.6  confidence >= 0.6  confidence < 0.6\n",
    "   intent=PRODUCTOS   intent=TECNICA     o intent=UNKNOWN\n",
    "   - Retrieve from    - Retrieve from    - Mensaje de\n",
    "     col. productos     col. tecnica       clarificacion\n",
    "   - Prompt especial  - Prompt especial  - Sin retrieval\n",
    "            |                 |                 |\n",
    "            v                 v                 v\n",
    "          [END]             [END]             [END]\n",
    "```\n",
    "\n",
    "### Flujo del estado\n",
    "\n",
    "1. El estado se inicializa con la `query` del usuario.\n",
    "2. `classify_intent` llena `intent` (con confidence y reasoning).\n",
    "3. `route_by_intent` evalua confidence + intent para decidir la ruta.\n",
    "4. El agente elegido llena `retrieved_docs`, `response` y `route_taken`.\n",
    "5. Cada nodo agrega su nombre a `steps_trace` para trazabilidad.\n",
    "\n",
    "### Routing basado en confianza\n",
    "\n",
    "El clasificador no solo dice \"PRODUCTOS\" o \"TECNICA\": tambien da un **score de confianza** (0.0 a 1.0). Si la confianza es baja (<0.6), incluso si clasifico como PRODUCTOS, preferimos ir al fallback. Esto evita respuestas incorrectas cuando la query es ambigua."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Instalacion de dependencias (ejecutar una vez)\n",
    "# =============================================================================\n",
    "# %pip install openai chromadb langchain langchain-openai langchain-core langgraph pydantic python-dotenv matplotlib pandas --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Imports principales\n",
    "# =============================================================================\n",
    "import os\n",
    "import json\n",
    "from typing import Optional, Literal, TypedDict\n",
    "from pathlib import Path\n",
    "\n",
    "# LLM y embeddings\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# Vector store\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Text splitting\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# LangGraph\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Pydantic para structured output\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Visualizacion y datos\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Variables de entorno\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "print(\"Imports completados exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cargar variables de entorno e inicializar LLM\n",
    "# =============================================================================\n",
    "load_dotenv()\n",
    "\n",
    "# Verificar que la API key esta configurada\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY no encontrada. Verifica tu archivo .env\"\n",
    "\n",
    "# Inicializar el modelo de lenguaje\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,  # Deterministico para clasificacion\n",
    ")\n",
    "\n",
    "# Inicializar embeddings\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Inicializar cliente OpenAI directo (para structured output)\n",
    "client = OpenAI()\n",
    "\n",
    "print(\"LLM inicializado: gpt-4o-mini\")\n",
    "print(\"Embeddings: text-embedding-3-small\")\n",
    "print(\"Setup completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Preparar Bases de Conocimiento por Dominio\n",
    "\n",
    "La clave del routing es que cada dominio tiene su **propia coleccion** en ChromaDB. Esto significa:\n",
    "- Los embeddings de productos solo compiten con otros embeddings de productos.\n",
    "- Los embeddings tecnicos solo compiten con otros embeddings tecnicos.\n",
    "- No hay contaminacion cruzada en el retrieval.\n",
    "\n",
    "Vamos a:\n",
    "1. Cargar cada archivo `.md` de la carpeta `data/`.\n",
    "2. Dividirlo en chunks con `RecursiveCharacterTextSplitter`.\n",
    "3. Indexar cada conjunto de chunks en su propia coleccion ChromaDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cargar documentos fuente\n",
    "# =============================================================================\n",
    "\n",
    "# Rutas a las bases de conocimiento\n",
    "DATA_DIR = Path(\"../data\")\n",
    "\n",
    "ruta_productos = DATA_DIR / \"base_conocimiento_productos.md\"\n",
    "ruta_tecnica = DATA_DIR / \"base_conocimiento_tecnica.md\"\n",
    "\n",
    "# Leer contenido de cada archivo\n",
    "with open(ruta_productos, \"r\", encoding=\"utf-8\") as f:\n",
    "    contenido_productos = f.read()\n",
    "\n",
    "with open(ruta_tecnica, \"r\", encoding=\"utf-8\") as f:\n",
    "    contenido_tecnica = f.read()\n",
    "\n",
    "print(f\"Documento PRODUCTOS cargado: {len(contenido_productos):,} caracteres\")\n",
    "print(f\"Documento TECNICA cargado:   {len(contenido_tecnica):,} caracteres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Chunking: dividir documentos en fragmentos manejables\n",
    "# =============================================================================\n",
    "\n",
    "# Configuracion del splitter\n",
    "# - chunk_size=500: fragmentos de ~500 caracteres (balanceado para precision)\n",
    "# - chunk_overlap=100: solapamiento para no perder contexto en bordes\n",
    "# - Separadores: priorizamos cortar por secciones markdown, luego parrafos, luego oraciones\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n## \", \"\\n### \", \"\\n\\n\", \"\\n\", \". \", \" \"],\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "# Dividir cada documento\n",
    "chunks_productos = text_splitter.split_text(contenido_productos)\n",
    "chunks_tecnica = text_splitter.split_text(contenido_tecnica)\n",
    "\n",
    "print(f\"Chunks PRODUCTOS: {len(chunks_productos)}\")\n",
    "print(f\"Chunks TECNICA:   {len(chunks_tecnica)}\")\n",
    "print(f\"\\n--- Ejemplo chunk PRODUCTOS (chunk 0) ---\")\n",
    "print(chunks_productos[0][:300] + \"...\")\n",
    "print(f\"\\n--- Ejemplo chunk TECNICA (chunk 0) ---\")\n",
    "print(chunks_tecnica[0][:300] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Indexar en ChromaDB: una coleccion por dominio\n",
    "# =============================================================================\n",
    "\n",
    "# Inicializar cliente ChromaDB (en memoria para este notebook)\n",
    "chroma_client = chromadb.Client(Settings(anonymized_telemetry=False))\n",
    "\n",
    "def crear_coleccion(nombre: str, chunks: list[str]) -> chromadb.Collection:\n",
    "    \"\"\"Crea una coleccion en ChromaDB e indexa los chunks con embeddings de OpenAI.\"\"\"\n",
    "    \n",
    "    # Eliminar coleccion si ya existe (para re-ejecucion limpia)\n",
    "    try:\n",
    "        chroma_client.delete_collection(nombre)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Crear coleccion nueva\n",
    "    coleccion = chroma_client.create_collection(\n",
    "        name=nombre,\n",
    "        metadata={\"hnsw:space\": \"cosine\"}  # Distancia coseno para similitud\n",
    "    )\n",
    "    \n",
    "    # Generar embeddings para cada chunk\n",
    "    embeddings = embeddings_model.embed_documents(chunks)\n",
    "    \n",
    "    # Agregar documentos a la coleccion\n",
    "    coleccion.add(\n",
    "        documents=chunks,\n",
    "        embeddings=embeddings,\n",
    "        ids=[f\"{nombre}_chunk_{i}\" for i in range(len(chunks))],\n",
    "        metadatas=[{\"dominio\": nombre, \"chunk_index\": i} for i in range(len(chunks))],\n",
    "    )\n",
    "    \n",
    "    return coleccion\n",
    "\n",
    "# Crear colecciones por dominio\n",
    "col_productos = crear_coleccion(\"productos\", chunks_productos)\n",
    "col_tecnica = crear_coleccion(\"tecnica\", chunks_tecnica)\n",
    "\n",
    "print(f\"Coleccion 'productos' creada: {col_productos.count()} documentos indexados\")\n",
    "print(f\"Coleccion 'tecnica' creada:   {col_tecnica.count()} documentos indexados\")\n",
    "print(\"\\nBases de conocimiento listas para retrieval.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Definir Esquemas\n",
    "\n",
    "Usamos **Pydantic** para definir estructuras de datos rigidas. Esto nos da:\n",
    "- Validacion automatica de tipos y rangos.\n",
    "- Structured output del LLM (el modelo responde directamente en este formato).\n",
    "- Documentacion implicita del contrato de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Esquema: Clasificacion de intencion\n",
    "# =============================================================================\n",
    "\n",
    "class IntentClassification(BaseModel):\n",
    "    \"\"\"Resultado de la clasificacion de intencion del usuario.\"\"\"\n",
    "    intent: Literal[\"PRODUCTOS\", \"TECNICA\", \"UNKNOWN\"] = Field(\n",
    "        description=\"Dominio clasificado de la consulta del usuario\"\n",
    "    )\n",
    "    confidence: float = Field(\n",
    "        ge=0.0, le=1.0,\n",
    "        description=\"Nivel de confianza de la clasificacion (0.0 a 1.0)\"\n",
    "    )\n",
    "    reasoning: str = Field(\n",
    "        description=\"Explicacion breve de por que se clasifico en este dominio\"\n",
    "    )\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Esquema: Respuesta del sistema RAG\n",
    "# =============================================================================\n",
    "\n",
    "class RAGResponse(BaseModel):\n",
    "    \"\"\"Respuesta generada por un agente RAG especializado.\"\"\"\n",
    "    answer: str = Field(\n",
    "        description=\"Respuesta completa a la consulta del usuario\"\n",
    "    )\n",
    "    sources: list[str] = Field(\n",
    "        description=\"Fragmentos de documentacion usados como fuente\"\n",
    "    )\n",
    "    confidence: float = Field(\n",
    "        ge=0.0, le=1.0,\n",
    "        description=\"Confianza del agente en la calidad de su respuesta\"\n",
    "    )\n",
    "    domain: str = Field(\n",
    "        description=\"Dominio que genero la respuesta\"\n",
    "    )\n",
    "    follow_up: str = Field(\n",
    "        description=\"Pregunta de seguimiento sugerida para el usuario\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Esquema IntentClassification:\")\n",
    "print(json.dumps(IntentClassification.model_json_schema(), indent=2, ensure_ascii=False)[:500])\n",
    "print(\"\\nEsquema RAGResponse:\")\n",
    "print(json.dumps(RAGResponse.model_json_schema(), indent=2, ensure_ascii=False)[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Definir Estado del Grafo\n",
    "\n",
    "El estado es el **objeto compartido** que fluye entre todos los nodos del grafo. Cada nodo lee y escribe en este estado. Es el equivalente a la \"memoria de trabajo\" del sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Estado del grafo: lo que todos los nodos comparten\n",
    "# =============================================================================\n",
    "\n",
    "class RouterState(TypedDict):\n",
    "    \"\"\"Estado compartido entre todos los nodos del grafo de routing.\"\"\"\n",
    "    query: str                                    # Consulta original del usuario\n",
    "    intent: Optional[IntentClassification]        # Resultado de la clasificacion\n",
    "    retrieved_docs: list[str]                     # Documentos recuperados por el agente\n",
    "    response: Optional[RAGResponse]               # Respuesta final generada\n",
    "    route_taken: str                              # Nombre de la ruta elegida\n",
    "    steps_trace: list[str]                        # Traza de nodos visitados\n",
    "\n",
    "\n",
    "print(\"RouterState definido con campos:\")\n",
    "for campo, tipo in RouterState.__annotations__.items():\n",
    "    print(f\"  - {campo}: {tipo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Nodo 1: Clasificador de Intencion\n",
    "\n",
    "Este es el **cerebro del routing**. Recibe la query del usuario y decide a que dominio pertenece.\n",
    "\n",
    "### Como funciona\n",
    "1. Toma la query del estado.\n",
    "2. Envia un prompt al LLM con **ejemplos** de cada categoria (few-shot).\n",
    "3. Usa **structured output** para forzar que el LLM responda en formato `IntentClassification`.\n",
    "4. Retorna el estado actualizado con la clasificacion.\n",
    "\n",
    "### Nota sobre el system prompt\n",
    "El prompt incluye ejemplos concretos de cada dominio para guiar al modelo. Esto es critico: sin ejemplos, el modelo tiende a clasificar demasiadas queries como UNKNOWN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Nodo 1: Clasificador de intencion (intent classifier)\n",
    "# =============================================================================\n",
    "\n",
    "CLASIFICADOR_SYSTEM_PROMPT = \"\"\"Eres un clasificador de intenciones para NovaTech Solutions.\n",
    "Tu trabajo es determinar si la consulta del usuario pertenece a uno de estos dominios:\n",
    "\n",
    "PRODUCTOS:\n",
    "- Preguntas sobre precios, planes, features de productos (Analytics Pro, DataSync, AI Assistant)\n",
    "- Comparaciones entre planes (Starter, Professional, Enterprise, Growth, Scale, Business)\n",
    "- Limites, requisitos tecnicos de productos\n",
    "- Politicas de soporte, SLAs, reembolsos\n",
    "- Preguntas frecuentes sobre uso de productos\n",
    "Ejemplos: \"cuanto cuesta el plan Enterprise?\", \"que incluye DataSync Growth?\",\n",
    "\"cual es el SLA de Analytics Pro?\", \"como migro entre planes?\"\n",
    "\n",
    "TECNICA:\n",
    "- Procedimientos de deploy, rollback, CI/CD\n",
    "- Troubleshooting de errores y problemas operativos\n",
    "- Arquitectura de infraestructura, microservicios, Kubernetes\n",
    "- Monitoreo, alertas, metricas (Datadog, PagerDuty, Sentry)\n",
    "- Seguridad, autenticacion, gestion de secretos\n",
    "- On-call, respuesta a incidentes\n",
    "Ejemplos: \"como hago rollback en produccion?\", \"que hago si analytics-engine no responde?\",\n",
    "\"como roto secretos en AWS?\", \"cual es el proceso de deploy de emergencia?\"\n",
    "\n",
    "UNKNOWN:\n",
    "- Preguntas que no tienen relacion con NovaTech Solutions\n",
    "- Temas personales, recetas, deportes, etc.\n",
    "- Si no estas seguro, clasifica como UNKNOWN con confidence baja\n",
    "\n",
    "IMPORTANTE:\n",
    "- Asigna un score de confidence entre 0.0 y 1.0\n",
    "- Si la query es ambigua (podria ser de cualquier dominio), baja la confidence\n",
    "- Siempre explica tu razonamiento brevemente\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def classify_intent(state: RouterState) -> RouterState:\n",
    "    \"\"\"Clasifica la intencion de la query del usuario usando LLM con structured output.\"\"\"\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    \n",
    "    # Llamada al LLM con structured output (response_format de OpenAI)\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": CLASIFICADOR_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": f\"Clasifica esta consulta: {query}\"},\n",
    "        ],\n",
    "        response_format=IntentClassification,\n",
    "    )\n",
    "    \n",
    "    # Extraer la clasificacion parseada\n",
    "    clasificacion = response.choices[0].message.parsed\n",
    "    \n",
    "    # Imprimir resultado para visibilidad\n",
    "    print(f\"[CLASIFICADOR] Query: '{query}'\")\n",
    "    print(f\"  Intent:     {clasificacion.intent}\")\n",
    "    print(f\"  Confidence: {clasificacion.confidence}\")\n",
    "    print(f\"  Reasoning:  {clasificacion.reasoning}\")\n",
    "    \n",
    "    # Actualizar estado\n",
    "    return {\n",
    "        **state,\n",
    "        \"intent\": clasificacion,\n",
    "        \"steps_trace\": state.get(\"steps_trace\", []) + [\"classify_intent\"],\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Nodo classify_intent definido.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Nodo 2: Agente RAG de Productos\n",
    "\n",
    "Este agente se activa cuando el clasificador detecta intent=PRODUCTOS con alta confianza.\n",
    "\n",
    "Su especialidad:\n",
    "- Busca **solo** en la coleccion `productos`.\n",
    "- Tiene un system prompt optimizado para responder sobre precios, planes, features.\n",
    "- Conoce la estructura de productos de NovaTech (Analytics Pro, DataSync, AI Assistant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Funcion auxiliar: buscar documentos en una coleccion ChromaDB\n",
    "# =============================================================================\n",
    "\n",
    "def buscar_documentos(\n",
    "    coleccion: chromadb.Collection,\n",
    "    query: str,\n",
    "    n_results: int = 3\n",
    ") -> list[str]:\n",
    "    \"\"\"Busca los documentos mas relevantes en una coleccion ChromaDB.\"\"\"\n",
    "    \n",
    "    # Generar embedding de la query\n",
    "    query_embedding = embeddings_model.embed_query(query)\n",
    "    \n",
    "    # Buscar en la coleccion\n",
    "    resultados = coleccion.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=n_results,\n",
    "    )\n",
    "    \n",
    "    # Extraer documentos (ChromaDB retorna listas anidadas)\n",
    "    documentos = resultados[\"documents\"][0] if resultados[\"documents\"] else []\n",
    "    return documentos\n",
    "\n",
    "\n",
    "print(\"Funcion buscar_documentos definida.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Nodo 2: Agente RAG de Productos\n",
    "# =============================================================================\n",
    "\n",
    "PRODUCTO_SYSTEM_PROMPT = \"\"\"Eres un agente experto en productos de NovaTech Solutions.\n",
    "Tu especialidad es responder preguntas sobre:\n",
    "- NovaTech Analytics Pro: plataforma de business intelligence\n",
    "- NovaTech DataSync: herramienta de ETL\n",
    "- NovaTech AI Assistant: chatbot empresarial con IA\n",
    "\n",
    "Usa UNICAMENTE la informacion proporcionada en el contexto para responder.\n",
    "Si el contexto no contiene la informacion, dilo honestamente.\n",
    "Responde en espanol de forma profesional y concisa.\n",
    "Cuando menciones precios, se preciso con los valores y condiciones.\n",
    "Sugiere una pregunta de seguimiento relevante para el usuario.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def product_rag_agent(state: RouterState) -> RouterState:\n",
    "    \"\"\"Agente RAG especializado en informacion de productos NovaTech.\"\"\"\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    \n",
    "    # Paso 1: Recuperar documentos relevantes de la coleccion de productos\n",
    "    docs = buscar_documentos(col_productos, query, n_results=3)\n",
    "    \n",
    "    print(f\"[AGENTE PRODUCTOS] Documentos recuperados: {len(docs)}\")\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"  Doc {i}: {doc[:100]}...\")\n",
    "    \n",
    "    # Paso 2: Construir contexto para el LLM\n",
    "    contexto = \"\\n\\n---\\n\\n\".join(docs)\n",
    "    \n",
    "    # Paso 3: Generar respuesta con structured output\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.2,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": PRODUCTO_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": (\n",
    "                f\"CONTEXTO:\\n{contexto}\\n\\n\"\n",
    "                f\"PREGUNTA DEL USUARIO:\\n{query}\"\n",
    "            )},\n",
    "        ],\n",
    "        response_format=RAGResponse,\n",
    "    )\n",
    "    \n",
    "    rag_response = response.choices[0].message.parsed\n",
    "    # Asegurar que el dominio este correcto\n",
    "    rag_response.domain = \"PRODUCTOS\"\n",
    "    \n",
    "    print(f\"  Respuesta generada (confidence: {rag_response.confidence})\")\n",
    "    \n",
    "    # Actualizar estado\n",
    "    return {\n",
    "        **state,\n",
    "        \"retrieved_docs\": docs,\n",
    "        \"response\": rag_response,\n",
    "        \"route_taken\": \"product_agent\",\n",
    "        \"steps_trace\": state.get(\"steps_trace\", []) + [\"product_rag_agent\"],\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Nodo product_rag_agent definido.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Nodo 3: Agente RAG Tecnico\n",
    "\n",
    "Este agente maneja todas las consultas de operaciones, infraestructura y troubleshooting.\n",
    "\n",
    "Su especialidad:\n",
    "- Busca **solo** en la coleccion `tecnica`.\n",
    "- Tiene un system prompt optimizado para procedimientos operativos.\n",
    "- Conoce la arquitectura de microservicios, Kubernetes, CI/CD de NovaTech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Nodo 3: Agente RAG Tecnico\n",
    "# =============================================================================\n",
    "\n",
    "TECNICA_SYSTEM_PROMPT = \"\"\"Eres un agente experto en operaciones tecnicas de NovaTech Solutions.\n",
    "Tu especialidad es responder preguntas sobre:\n",
    "- Arquitectura de microservicios (12 servicios en Kubernetes/EKS)\n",
    "- Procedimientos de deploy y rollback\n",
    "- Troubleshooting de errores comunes\n",
    "- Monitoreo con Datadog, alertas con PagerDuty\n",
    "- Gestion de secretos con AWS Secrets Manager\n",
    "- Seguridad, autenticacion, compliance\n",
    "- Procedimientos de on-call y respuesta a incidentes\n",
    "\n",
    "Usa UNICAMENTE la informacion proporcionada en el contexto para responder.\n",
    "Si el contexto no contiene la informacion, dilo honestamente.\n",
    "Responde en espanol de forma tecnica pero clara.\n",
    "Cuando menciones comandos, incluyelos con formato de codigo.\n",
    "Sugiere una pregunta de seguimiento relevante para el usuario.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def tech_rag_agent(state: RouterState) -> RouterState:\n",
    "    \"\"\"Agente RAG especializado en operaciones tecnicas de NovaTech.\"\"\"\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    \n",
    "    # Paso 1: Recuperar documentos relevantes de la coleccion tecnica\n",
    "    docs = buscar_documentos(col_tecnica, query, n_results=3)\n",
    "    \n",
    "    print(f\"[AGENTE TECNICO] Documentos recuperados: {len(docs)}\")\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"  Doc {i}: {doc[:100]}...\")\n",
    "    \n",
    "    # Paso 2: Construir contexto para el LLM\n",
    "    contexto = \"\\n\\n---\\n\\n\".join(docs)\n",
    "    \n",
    "    # Paso 3: Generar respuesta con structured output\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.2,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": TECNICA_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": (\n",
    "                f\"CONTEXTO:\\n{contexto}\\n\\n\"\n",
    "                f\"PREGUNTA DEL USUARIO:\\n{query}\"\n",
    "            )},\n",
    "        ],\n",
    "        response_format=RAGResponse,\n",
    "    )\n",
    "    \n",
    "    rag_response = response.choices[0].message.parsed\n",
    "    # Asegurar que el dominio este correcto\n",
    "    rag_response.domain = \"TECNICA\"\n",
    "    \n",
    "    print(f\"  Respuesta generada (confidence: {rag_response.confidence})\")\n",
    "    \n",
    "    # Actualizar estado\n",
    "    return {\n",
    "        **state,\n",
    "        \"retrieved_docs\": docs,\n",
    "        \"response\": rag_response,\n",
    "        \"route_taken\": \"tech_agent\",\n",
    "        \"steps_trace\": state.get(\"steps_trace\", []) + [\"tech_rag_agent\"],\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Nodo tech_rag_agent definido.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Nodo 4: Agente Fallback\n",
    "\n",
    "Se activa cuando:\n",
    "- La clasificacion es UNKNOWN (query fuera de dominio).\n",
    "- La confianza es menor al umbral (query ambigua).\n",
    "\n",
    "**No hace retrieval** -- simplemente genera un mensaje educado pidiendo clarificacion y sugiriendo los dominios disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Nodo 4: Agente Fallback\n",
    "# =============================================================================\n",
    "\n",
    "def fallback_agent(state: RouterState) -> RouterState:\n",
    "    \"\"\"Agente fallback: responde cuando no se puede clasificar la consulta con confianza.\"\"\"\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    intent = state.get(\"intent\")\n",
    "    \n",
    "    # Construir mensaje de fallback\n",
    "    if intent and intent.intent == \"UNKNOWN\":\n",
    "        mensaje = (\n",
    "            f\"Lo siento, tu consulta '{query}' no parece estar relacionada con los \"\n",
    "            f\"servicios de NovaTech Solutions. \"\n",
    "            f\"Puedo ayudarte con:\\n\"\n",
    "            f\"- **Productos**: Precios, planes, features de Analytics Pro, DataSync y AI Assistant.\\n\"\n",
    "            f\"- **Tecnica**: Deploy, rollback, troubleshooting, monitoreo, seguridad.\\n\\n\"\n",
    "            f\"Por favor, reformula tu pregunta dentro de estos dominios.\"\n",
    "        )\n",
    "    else:\n",
    "        # Baja confianza en la clasificacion\n",
    "        mensaje = (\n",
    "            f\"Tu consulta '{query}' es un poco ambigua y no estoy seguro de como \"\n",
    "            f\"dirigirla correctamente. \"\n",
    "            f\"Podrias especificar si tu pregunta es sobre:\\n\"\n",
    "            f\"- **Productos**: Precios, planes, features, SLAs.\\n\"\n",
    "            f\"- **Tecnica**: Deploy, errores, infraestructura, seguridad.\\n\\n\"\n",
    "            f\"Asi podre darte una respuesta mas precisa.\"\n",
    "        )\n",
    "    \n",
    "    # Crear respuesta de fallback\n",
    "    rag_response = RAGResponse(\n",
    "        answer=mensaje,\n",
    "        sources=[],\n",
    "        confidence=0.0,\n",
    "        domain=\"FALLBACK\",\n",
    "        follow_up=\"Podrias reformular tu pregunta especificando si es sobre productos o temas tecnicos?\",\n",
    "    )\n",
    "    \n",
    "    print(f\"[FALLBACK] Query: '{query}'\")\n",
    "    print(f\"  Razon: {'fuera de dominio' if intent and intent.intent == 'UNKNOWN' else 'baja confianza'}\")\n",
    "    \n",
    "    # Actualizar estado\n",
    "    return {\n",
    "        **state,\n",
    "        \"retrieved_docs\": [],\n",
    "        \"response\": rag_response,\n",
    "        \"route_taken\": \"fallback\",\n",
    "        \"steps_trace\": state.get(\"steps_trace\", []) + [\"fallback_agent\"],\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Nodo fallback_agent definido.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Funcion de Routing (Conditional Edges)\n",
    "\n",
    "Esta funcion es el **decision maker** del grafo. No es un nodo -- es la funcion que LangGraph usa para decidir que edge seguir despues del clasificador.\n",
    "\n",
    "### Logica de decision\n",
    "```\n",
    "if confidence >= 0.6 AND intent == \"PRODUCTOS\"  --> product_agent\n",
    "if confidence >= 0.6 AND intent == \"TECNICA\"     --> tech_agent\n",
    "else (baja confianza o UNKNOWN)                  --> fallback\n",
    "```\n",
    "\n",
    "### Por que 0.6 como umbral?\n",
    "\n",
    "- **0.3 (muy bajo)**: Demasiadas queries dudosas se enrutan a agentes especializados. Riesgo de respuestas incorrectas.\n",
    "- **0.6 (balanceado)**: Acepta clasificaciones razonablemente seguras. Queries ambiguas van a fallback.\n",
    "- **0.8 (muy alto)**: Demasiadas queries validas caen en fallback. Frustracion del usuario.\n",
    "\n",
    "En la seccion de ajuste de umbral experimentaremos con estos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Funcion de routing: decide que edge seguir\n",
    "# =============================================================================\n",
    "\n",
    "# Umbral de confianza configurable (lo ajustaremos despues)\n",
    "CONFIDENCE_THRESHOLD = 0.6\n",
    "\n",
    "\n",
    "def route_by_intent(state: RouterState) -> str:\n",
    "    \"\"\"Decide la ruta basandose en el intent clasificado y su confianza.\n",
    "    \n",
    "    Returns:\n",
    "        str: Nombre del nodo destino (\"product_agent\", \"tech_agent\", o \"fallback\")\n",
    "    \"\"\"\n",
    "    \n",
    "    intent = state.get(\"intent\")\n",
    "    \n",
    "    # Si no hay clasificacion, ir a fallback\n",
    "    if intent is None:\n",
    "        print(f\"[ROUTER] Sin clasificacion -> fallback\")\n",
    "        return \"fallback\"\n",
    "    \n",
    "    # Evaluar confianza y dominio\n",
    "    if intent.confidence >= CONFIDENCE_THRESHOLD and intent.intent == \"PRODUCTOS\":\n",
    "        print(f\"[ROUTER] PRODUCTOS (confidence={intent.confidence:.2f}) -> product_agent\")\n",
    "        return \"product_agent\"\n",
    "    \n",
    "    elif intent.confidence >= CONFIDENCE_THRESHOLD and intent.intent == \"TECNICA\":\n",
    "        print(f\"[ROUTER] TECNICA (confidence={intent.confidence:.2f}) -> tech_agent\")\n",
    "        return \"tech_agent\"\n",
    "    \n",
    "    else:\n",
    "        razon = (\n",
    "            f\"intent={intent.intent}, confidence={intent.confidence:.2f} \"\n",
    "            f\"(umbral={CONFIDENCE_THRESHOLD})\"\n",
    "        )\n",
    "        print(f\"[ROUTER] {razon} -> fallback\")\n",
    "        return \"fallback\"\n",
    "\n",
    "\n",
    "print(f\"Funcion route_by_intent definida (umbral de confianza: {CONFIDENCE_THRESHOLD}).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. Construir el Grafo con LangGraph\n",
    "\n",
    "Ahora ensamblamos todo. LangGraph nos permite definir:\n",
    "- **Nodos**: Las funciones que procesan el estado.\n",
    "- **Edges**: Las conexiones entre nodos.\n",
    "- **Conditional edges**: Bifurcaciones dinamicas basadas en el estado.\n",
    "- **Entry point**: Por donde entra el flujo.\n",
    "- **END**: Nodo terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Construir el grafo de routing\n",
    "# =============================================================================\n",
    "\n",
    "# 1. Crear el grafo con el tipo de estado\n",
    "workflow = StateGraph(RouterState)\n",
    "\n",
    "# 2. Agregar nodos\n",
    "workflow.add_node(\"classify\", classify_intent)        # Clasificador de intencion\n",
    "workflow.add_node(\"product_agent\", product_rag_agent)  # Agente de productos\n",
    "workflow.add_node(\"tech_agent\", tech_rag_agent)        # Agente tecnico\n",
    "workflow.add_node(\"fallback\", fallback_agent)          # Agente fallback\n",
    "\n",
    "# 3. Definir punto de entrada\n",
    "workflow.set_entry_point(\"classify\")\n",
    "\n",
    "# 4. Agregar edges condicionales desde el clasificador\n",
    "workflow.add_conditional_edges(\n",
    "    \"classify\",          # Nodo origen\n",
    "    route_by_intent,     # Funcion que decide la ruta\n",
    "    {                    # Mapeo: valor retornado -> nodo destino\n",
    "        \"product_agent\": \"product_agent\",\n",
    "        \"tech_agent\": \"tech_agent\",\n",
    "        \"fallback\": \"fallback\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# 5. Los agentes terminan el flujo despues de responder\n",
    "workflow.add_edge(\"product_agent\", END)\n",
    "workflow.add_edge(\"tech_agent\", END)\n",
    "workflow.add_edge(\"fallback\", END)\n",
    "\n",
    "# 6. Compilar el grafo\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"Grafo compilado exitosamente.\")\n",
    "print(\"Nodos: classify -> [product_agent | tech_agent | fallback] -> END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 13. Visualizar el Grafo\n",
    "\n",
    "LangGraph puede generar una representacion visual del grafo. Esto es fundamental para entender y depurar el flujo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Visualizar el grafo con Mermaid\n",
    "# =============================================================================\n",
    "\n",
    "try:\n",
    "    # Intentar generar imagen PNG del grafo\n",
    "    from IPython.display import Image, display\n",
    "    \n",
    "    graph_image = app.get_graph().draw_mermaid_png()\n",
    "    display(Image(graph_image))\n",
    "    print(\"Grafo renderizado como imagen.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"No se pudo renderizar imagen ({e}).\")\n",
    "    print(\"Representacion textual del grafo (Mermaid):\")\n",
    "    print()\n",
    "    print(app.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 14. Funcion auxiliar para ejecutar y mostrar resultados\n",
    "\n",
    "Creamos una funcion helper que ejecuta una query por el grafo y muestra todos los detalles de forma legible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Funcion auxiliar: ejecutar query y mostrar resultados detallados\n",
    "# =============================================================================\n",
    "\n",
    "def ejecutar_query(query: str, verbose: bool = True) -> dict:\n",
    "    \"\"\"Ejecuta una query por el grafo de routing y muestra resultados.\n",
    "    \n",
    "    Args:\n",
    "        query: Consulta del usuario\n",
    "        verbose: Si True, imprime detalles completos\n",
    "    \n",
    "    Returns:\n",
    "        dict: Estado final del grafo\n",
    "    \"\"\"\n",
    "    \n",
    "    # Estado inicial\n",
    "    estado_inicial = {\n",
    "        \"query\": query,\n",
    "        \"intent\": None,\n",
    "        \"retrieved_docs\": [],\n",
    "        \"response\": None,\n",
    "        \"route_taken\": \"\",\n",
    "        \"steps_trace\": [],\n",
    "    }\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Ejecutar el grafo\n",
    "    resultado = app.invoke(estado_inicial)\n",
    "    \n",
    "    if verbose and resultado.get(\"response\"):\n",
    "        resp = resultado[\"response\"]\n",
    "        print(f\"\\n{'─' * 60}\")\n",
    "        print(f\"RESULTADO FINAL\")\n",
    "        print(f\"{'─' * 60}\")\n",
    "        print(f\"Ruta tomada:       {resultado['route_taken']}\")\n",
    "        print(f\"Traza de pasos:    {' -> '.join(resultado['steps_trace'])}\")\n",
    "        print(f\"Dominio respuesta: {resp.domain}\")\n",
    "        print(f\"Confidence resp:   {resp.confidence}\")\n",
    "        print(f\"Docs recuperados:  {len(resultado['retrieved_docs'])}\")\n",
    "        print(f\"\\nRESPUESTA:\")\n",
    "        print(resp.answer)\n",
    "        if resp.sources:\n",
    "            print(f\"\\nFUENTES ({len(resp.sources)}):\")\n",
    "            for i, src in enumerate(resp.sources):\n",
    "                print(f\"  [{i+1}] {src[:120]}...\" if len(src) > 120 else f\"  [{i+1}] {src}\")\n",
    "        print(f\"\\nSUGERENCIA: {resp.follow_up}\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    return resultado\n",
    "\n",
    "\n",
    "print(\"Funcion ejecutar_query definida.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 15. Ejemplo 1: Query de Productos\n",
    "\n",
    "Empezamos con una consulta clara de productos. Deberia clasificarse como **PRODUCTOS** con alta confianza y enrutarse al agente de productos.\n",
    "\n",
    "Observa:\n",
    "- Como el clasificador identifica la intencion.\n",
    "- Que documentos recupera el agente de productos.\n",
    "- La calidad de la respuesta con contexto especializado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Ejemplo 1: Pregunta sobre precios de producto\n",
    "# =============================================================================\n",
    "\n",
    "resultado_1 = ejecutar_query(\n",
    "    \"Cuanto cuesta el plan Enterprise de DataSync y que incluye?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 16. Ejemplo 2: Query Tecnico\n",
    "\n",
    "Ahora una consulta claramente tecnica. El clasificador deberia enrutarla al agente tecnico, que buscara en la coleccion `tecnica`.\n",
    "\n",
    "Observa como los documentos recuperados son **completamente diferentes** a los del ejemplo anterior -- eso es el poder de tener colecciones separadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Ejemplo 2: Pregunta sobre procedimiento tecnico\n",
    "# =============================================================================\n",
    "\n",
    "resultado_2 = ejecutar_query(\n",
    "    \"Como hago rollback de un deploy en produccion?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 17. Ejemplo 3: Query Ambiguo\n",
    "\n",
    "Este es el caso interesante. La query menciona \"AI Assistant\" (un producto) pero el problema es de \"confianza baja\" (que podria ser un tema de troubleshooting tecnico).\n",
    "\n",
    "El clasificador tiene que decidir:\n",
    "- Es una pregunta sobre el **producto** AI Assistant (como mejorarlo, que plan tiene)?\n",
    "- Es una pregunta **tecnica** (como debugear el modelo, revisar embeddings)?\n",
    "\n",
    "Presta atencion al score de confidence y al reasoning del clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Ejemplo 3: Query ambiguo que cruza dominios\n",
    "# =============================================================================\n",
    "\n",
    "resultado_3 = ejecutar_query(\n",
    "    \"Necesito ayuda con el AI Assistant, da respuestas con confianza baja\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 18. Ejemplo 4: Query Fuera de Dominio\n",
    "\n",
    "Cuando el usuario pregunta algo que no tiene nada que ver con NovaTech, el clasificador deberia retornar UNKNOWN y el sistema activar el fallback.\n",
    "\n",
    "Esto es importante en produccion: un buen sistema RAG debe saber decir \"no se\" en lugar de inventar respuestas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Ejemplo 4: Query completamente fuera de dominio\n",
    "# =============================================================================\n",
    "\n",
    "resultado_4 = ejecutar_query(\n",
    "    \"Cual es la receta del guacamole?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 19. Batch de Queries: Evaluacion Sistematica\n",
    "\n",
    "Para evaluar el sistema de forma robusta, ejecutamos un **batch diverso** de queries y analizamos los patrones de clasificacion y routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Batch de queries diversas\n",
    "# =============================================================================\n",
    "\n",
    "queries_test = [\n",
    "    # Productos (esperamos: PRODUCTOS con alta confianza)\n",
    "    \"Que diferencias hay entre el plan Starter y Professional de Analytics Pro?\",\n",
    "    \"Cuantas consultas por mes incluye el plan Business de AI Assistant?\",\n",
    "    \"Ofrecen descuentos por volumen para mas de 50 usuarios?\",\n",
    "    \n",
    "    # Tecnica (esperamos: TECNICA con alta confianza)\n",
    "    \"Que hago si veo un error 429 rate limit exceeded?\",\n",
    "    \"Como roto los secretos de JWT signing keys?\",\n",
    "    \"Cual es el proceso de deploy de emergencia (hotfix)?\",\n",
    "    \n",
    "    # Ambiguos (esperamos: clasificacion con confianza media)\n",
    "    \"El pipeline de DataSync esta fallando con timeout\",\n",
    "    \"Necesito mejorar el rendimiento del sistema\",\n",
    "    \n",
    "    # Fuera de dominio (esperamos: UNKNOWN)\n",
    "    \"Quien gano el mundial de futbol en 2022?\",\n",
    "    \"Explicame la teoria de la relatividad\",\n",
    "]\n",
    "\n",
    "# Ejecutar todas las queries y recolectar resultados\n",
    "resultados_batch = []\n",
    "\n",
    "for query in queries_test:\n",
    "    resultado = ejecutar_query(query, verbose=False)  # verbose=False para no saturar el output\n",
    "    \n",
    "    # Extraer datos clave\n",
    "    intent = resultado.get(\"intent\")\n",
    "    response = resultado.get(\"response\")\n",
    "    \n",
    "    resultados_batch.append({\n",
    "        \"query\": query[:60] + \"...\" if len(query) > 60 else query,\n",
    "        \"intent\": intent.intent if intent else \"N/A\",\n",
    "        \"confidence\": f\"{intent.confidence:.2f}\" if intent else \"N/A\",\n",
    "        \"route\": resultado.get(\"route_taken\", \"N/A\"),\n",
    "        \"answer_preview\": response.answer[:80] + \"...\" if response else \"N/A\",\n",
    "    })\n",
    "\n",
    "print(f\"\\nBatch completado: {len(resultados_batch)} queries procesadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Mostrar resultados del batch como tabla\n",
    "# =============================================================================\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados_batch)\n",
    "\n",
    "# Configurar pandas para mostrar texto completo\n",
    "pd.set_option(\"display.max_colwidth\", 80)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"TABLA DE RESULTADOS DEL BATCH\")\n",
    "print(\"=\" * 100)\n",
    "print(df_resultados.to_string(index=True))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Resumen estadistico\n",
    "print(\"RESUMEN DE ROUTING:\")\n",
    "print(df_resultados[\"route\"].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 20. Visualizacion: Distribucion de Rutas\n",
    "\n",
    "Un grafico nos permite ver rapidamente como se distribuyen las queries entre los dominios. En un sistema de produccion, monitorearias esta distribucion para detectar anomalias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Grafico: distribucion de rutas tomadas\n",
    "# =============================================================================\n",
    "\n",
    "# Contar queries por ruta\n",
    "distribucion = df_resultados[\"route\"].value_counts()\n",
    "\n",
    "# Colores por dominio\n",
    "colores = {\n",
    "    \"product_agent\": \"#4CAF50\",   # Verde para productos\n",
    "    \"tech_agent\": \"#2196F3\",      # Azul para tecnica\n",
    "    \"fallback\": \"#FF9800\",        # Naranja para fallback\n",
    "}\n",
    "colores_plot = [colores.get(ruta, \"#9E9E9E\") for ruta in distribucion.index]\n",
    "\n",
    "# Crear figura con dos subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Subplot 1: Pie chart\n",
    "ax1.pie(\n",
    "    distribucion.values,\n",
    "    labels=distribucion.index,\n",
    "    autopct=\"%1.0f%%\",\n",
    "    colors=colores_plot,\n",
    "    startangle=90,\n",
    "    textprops={\"fontsize\": 11},\n",
    ")\n",
    "ax1.set_title(\"Distribucion de Rutas (Pie Chart)\", fontsize=13, fontweight=\"bold\")\n",
    "\n",
    "# Subplot 2: Bar chart\n",
    "bars = ax2.bar(distribucion.index, distribucion.values, color=colores_plot, edgecolor=\"black\")\n",
    "ax2.set_ylabel(\"Cantidad de queries\", fontsize=11)\n",
    "ax2.set_title(\"Distribucion de Rutas (Bar Chart)\", fontsize=13, fontweight=\"bold\")\n",
    "ax2.set_ylim(0, max(distribucion.values) + 1)\n",
    "\n",
    "# Agregar valor sobre cada barra\n",
    "for bar, val in zip(bars, distribucion.values):\n",
    "    ax2.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + 0.1,\n",
    "        str(val),\n",
    "        ha=\"center\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Grafico generado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 21. Ajuste de Umbral de Confianza\n",
    "\n",
    "El umbral de confianza es un **hiperparametro** del sistema. Vamos a experimentar con tres valores:\n",
    "\n",
    "| Umbral | Comportamiento esperado |\n",
    "|--------|------------------------|\n",
    "| 0.3    | Muy permisivo. Casi todo se enruta a un agente. Riesgo de respuestas incorrectas. |\n",
    "| 0.6    | Balanceado. Acepta clasificaciones razonables. |\n",
    "| 0.8    | Muy estricto. Muchas queries validas caen en fallback. |\n",
    "\n",
    "Ejecutamos el **mismo batch de queries** con cada umbral y comparamos como cambian las decisiones de routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Experimento: impacto del umbral de confianza en routing\n",
    "# =============================================================================\n",
    "\n",
    "# Primero, recolectamos las clasificaciones (sin routing) para todas las queries\n",
    "# Esto evita repetir las llamadas al clasificador\n",
    "clasificaciones = []\n",
    "\n",
    "for query in queries_test:\n",
    "    estado_test = {\n",
    "        \"query\": query,\n",
    "        \"intent\": None,\n",
    "        \"retrieved_docs\": [],\n",
    "        \"response\": None,\n",
    "        \"route_taken\": \"\",\n",
    "        \"steps_trace\": [],\n",
    "    }\n",
    "    estado_clasificado = classify_intent(estado_test)\n",
    "    clasificaciones.append({\n",
    "        \"query\": query[:50] + \"...\" if len(query) > 50 else query,\n",
    "        \"intent\": estado_clasificado[\"intent\"].intent,\n",
    "        \"confidence\": estado_clasificado[\"intent\"].confidence,\n",
    "    })\n",
    "\n",
    "print(f\"Clasificaciones recolectadas para {len(clasificaciones)} queries.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Simular routing con diferentes umbrales\n",
    "# =============================================================================\n",
    "\n",
    "umbrales = [0.3, 0.6, 0.8]\n",
    "resultados_por_umbral = {}\n",
    "\n",
    "for umbral in umbrales:\n",
    "    rutas = []\n",
    "    for c in clasificaciones:\n",
    "        if c[\"confidence\"] >= umbral and c[\"intent\"] == \"PRODUCTOS\":\n",
    "            rutas.append(\"product_agent\")\n",
    "        elif c[\"confidence\"] >= umbral and c[\"intent\"] == \"TECNICA\":\n",
    "            rutas.append(\"tech_agent\")\n",
    "        else:\n",
    "            rutas.append(\"fallback\")\n",
    "    resultados_por_umbral[umbral] = rutas\n",
    "\n",
    "# Construir tabla comparativa\n",
    "df_umbrales = pd.DataFrame({\n",
    "    \"query\": [c[\"query\"] for c in clasificaciones],\n",
    "    \"intent\": [c[\"intent\"] for c in clasificaciones],\n",
    "    \"confidence\": [f\"{c['confidence']:.2f}\" for c in clasificaciones],\n",
    "})\n",
    "\n",
    "for umbral in umbrales:\n",
    "    df_umbrales[f\"ruta_{umbral}\"] = resultados_por_umbral[umbral]\n",
    "\n",
    "print(\"COMPARACION DE ROUTING CON DIFERENTES UMBRALES\")\n",
    "print(\"=\" * 120)\n",
    "print(df_umbrales.to_string(index=True))\n",
    "print()\n",
    "\n",
    "# Resumen: cuantas queries van a fallback con cada umbral\n",
    "print(\"\\nQUERIES EN FALLBACK POR UMBRAL:\")\n",
    "for umbral in umbrales:\n",
    "    n_fallback = resultados_por_umbral[umbral].count(\"fallback\")\n",
    "    n_total = len(resultados_por_umbral[umbral])\n",
    "    print(f\"  Umbral {umbral}: {n_fallback}/{n_total} queries ({n_fallback/n_total*100:.0f}%) van a fallback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Visualizacion: routing por umbral\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for i, umbral in enumerate(umbrales):\n",
    "    rutas = resultados_por_umbral[umbral]\n",
    "    conteo = pd.Series(rutas).value_counts()\n",
    "    \n",
    "    colores_barras = [colores.get(r, \"#9E9E9E\") for r in conteo.index]\n",
    "    \n",
    "    axes[i].bar(conteo.index, conteo.values, color=colores_barras, edgecolor=\"black\")\n",
    "    axes[i].set_title(f\"Umbral = {umbral}\", fontsize=13, fontweight=\"bold\")\n",
    "    axes[i].set_ylabel(\"Cantidad\")\n",
    "    axes[i].set_ylim(0, len(queries_test) + 1)\n",
    "    \n",
    "    # Valor sobre cada barra\n",
    "    for bar_idx, (ruta_name, val) in enumerate(conteo.items()):\n",
    "        axes[i].text(\n",
    "            bar_idx, val + 0.15, str(val),\n",
    "            ha=\"center\", fontsize=12, fontweight=\"bold\"\n",
    "        )\n",
    "\n",
    "plt.suptitle(\"Impacto del Umbral de Confianza en el Routing\", fontsize=14, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Observa como el umbral mas alto (0.8) envia mas queries al fallback.\")\n",
    "print(\"El balance entre precision y cobertura es un trade-off de ingenieria.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 22. Comparacion: Routing vs Single RAG\n",
    "\n",
    "Para demostrar el valor del routing, implementamos un **RAG simple** que indexa TODOS los documentos en una sola coleccion y ejecutamos las mismas queries. Comparamos la calidad de las respuestas.\n",
    "\n",
    "**Hipotesis**: El routing produce mejores respuestas porque:\n",
    "1. Los documentos recuperados son mas relevantes (no hay contaminacion).\n",
    "2. El prompt del agente esta especializado para el dominio.\n",
    "3. Queries fuera de dominio se manejan explicitamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Crear RAG con coleccion unica (todos los docs mezclados)\n",
    "# =============================================================================\n",
    "\n",
    "# Combinar todos los chunks en una sola coleccion\n",
    "todos_los_chunks = chunks_productos + chunks_tecnica\n",
    "col_unica = crear_coleccion(\"todos_juntos\", todos_los_chunks)\n",
    "\n",
    "print(f\"Coleccion unica creada: {col_unica.count()} documentos\")\n",
    "print(f\"  (productos: {len(chunks_productos)} + tecnica: {len(chunks_tecnica)})\")\n",
    "\n",
    "\n",
    "# Prompt generico (no especializado)\n",
    "SINGLE_RAG_PROMPT = \"\"\"Eres un asistente de NovaTech Solutions.\n",
    "Responde la pregunta del usuario basandote UNICAMENTE en el contexto proporcionado.\n",
    "Si el contexto no contiene la informacion, dilo honestamente.\n",
    "Responde en espanol de forma profesional.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def single_rag_query(query: str) -> dict:\n",
    "    \"\"\"Ejecuta una query contra el RAG de coleccion unica (sin routing).\"\"\"\n",
    "    \n",
    "    # Recuperar documentos de la coleccion unica\n",
    "    docs = buscar_documentos(col_unica, query, n_results=3)\n",
    "    contexto = \"\\n\\n---\\n\\n\".join(docs)\n",
    "    \n",
    "    # Generar respuesta\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.2,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SINGLE_RAG_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": f\"CONTEXTO:\\n{contexto}\\n\\nPREGUNTA:\\n{query}\"},\n",
    "        ],\n",
    "        response_format=RAGResponse,\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"answer\": response.choices[0].message.parsed.answer,\n",
    "        \"confidence\": response.choices[0].message.parsed.confidence,\n",
    "        \"docs\": docs,\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Single RAG configurado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Comparacion lado a lado: Routing RAG vs Single RAG\n",
    "# =============================================================================\n",
    "\n",
    "# Seleccionar queries representativas para comparar\n",
    "queries_comparacion = [\n",
    "    \"Cuanto cuesta el plan Enterprise de DataSync?\",            # Productos clara\n",
    "    \"Como hago rollback de emergencia en produccion?\",          # Tecnica clara\n",
    "    \"El pipeline de DataSync esta fallando con timeout\",        # Ambigua\n",
    "    \"Quien gano el mundial de futbol en 2022?\",                # Fuera de dominio\n",
    "]\n",
    "\n",
    "print(\"COMPARACION: ROUTING RAG vs SINGLE RAG\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for query in queries_comparacion:\n",
    "    print(f\"\\nQUERY: {query}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Routing RAG\n",
    "    resultado_routing = ejecutar_query(query, verbose=False)\n",
    "    resp_routing = resultado_routing.get(\"response\")\n",
    "    \n",
    "    # Single RAG\n",
    "    resultado_single = single_rag_query(query)\n",
    "    \n",
    "    print(f\"\\n  [ROUTING RAG]\")\n",
    "    print(f\"  Ruta:       {resultado_routing.get('route_taken', 'N/A')}\")\n",
    "    print(f\"  Confidence: {resp_routing.confidence if resp_routing else 'N/A'}\")\n",
    "    print(f\"  Respuesta:  {resp_routing.answer[:200]}...\" if resp_routing and len(resp_routing.answer) > 200 else f\"  Respuesta:  {resp_routing.answer if resp_routing else 'N/A'}\")\n",
    "    \n",
    "    print(f\"\\n  [SINGLE RAG]\")\n",
    "    print(f\"  Confidence: {resultado_single['confidence']}\")\n",
    "    print(f\"  Respuesta:  {resultado_single['answer'][:200]}...\" if len(resultado_single['answer']) > 200 else f\"  Respuesta:  {resultado_single['answer']}\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de la comparacion\n",
    "\n",
    "Puntos clave a observar:\n",
    "\n",
    "1. **Queries claras de productos**: El routing deberia dar respuestas mas precisas porque recupera solo documentos de productos. El single RAG puede traer documentos tecnicos que mencionan el mismo producto pero no responden la pregunta.\n",
    "\n",
    "2. **Queries claras tecnicas**: Similar al caso anterior pero con documentos tecnicos.\n",
    "\n",
    "3. **Queries ambiguas**: Aqui el routing puede elegir un dominio (o ir a fallback), mientras que el single RAG mezcla documentos de ambos dominios sin criterio.\n",
    "\n",
    "4. **Queries fuera de dominio**: El routing tiene un fallback explicito. El single RAG intenta responder con documentos irrelevantes, dando respuestas potencialmente enganosas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 23. Combinando Routing + Prompt Chaining\n",
    "\n",
    "En un sistema de produccion real, no usas routing **o** prompt chaining -- usas **ambos**.\n",
    "\n",
    "### Arquitectura combinada\n",
    "\n",
    "```\n",
    "User Query\n",
    "    |\n",
    "    v\n",
    "[Intent Classifier] -----> Routing Layer\n",
    "    |\n",
    "    +-----> PRODUCTOS -----> [Agente Especializado con Chaining Interno]\n",
    "    |                           |\n",
    "    |                           +---> Paso 1: Reformular query para el dominio\n",
    "    |                           +---> Paso 2: Retrieve documentos\n",
    "    |                           +---> Paso 3: Generar respuesta borrador\n",
    "    |                           +---> Paso 4: Validar contra fuentes\n",
    "    |                           +---> Paso 5: Formatear respuesta final\n",
    "    |\n",
    "    +-----> TECNICA -----> [Agente Especializado con Chaining Interno]\n",
    "    |                           |\n",
    "    |                           +---> (mismo pipeline, diferente prompt/contexto)\n",
    "    |\n",
    "    +-----> FALLBACK -----> Mensaje de clarificacion\n",
    "```\n",
    "\n",
    "### Lo que esto significa para el proyecto\n",
    "\n",
    "El **Notebook 05 (proyecto integrador)** combina todos estos patrones:\n",
    "- Routing para clasificar y delegar.\n",
    "- Prompt chaining dentro de cada agente especializado.\n",
    "- Evaluacion y optimizacion del pipeline completo.\n",
    "\n",
    "Este notebook (04) te da las herramientas de routing. El siguiente paso es integrarlas en un sistema completo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 24. Errores Comunes\n",
    "\n",
    "### 1. No incluir ejemplos en el prompt del clasificador\n",
    "Sin ejemplos concretos de cada dominio, el LLM tiende a clasificar demasiadas queries como UNKNOWN. Los few-shot examples son criticos para la calidad de la clasificacion.\n",
    "\n",
    "### 2. Umbral de confianza estatico en produccion\n",
    "Un umbral fijo (como 0.6) funciona para un demo, pero en produccion necesitas monitorear la distribucion de confidence scores y ajustar dinamicamente. Si el 80% de tus queries llegan con confidence > 0.95, tu umbral de 0.6 no esta discriminando nada util.\n",
    "\n",
    "### 3. No tener fallback (o un fallback que miente)\n",
    "Algunos sistemas omiten el fallback y fuerzan siempre una respuesta. Esto genera alucinaciones. Un buen fallback dice \"no se\" y guia al usuario. Peor que no responder es responder mal.\n",
    "\n",
    "### 4. Colecciones no balanceadas\n",
    "Si la coleccion de productos tiene 500 chunks y la tecnica tiene 20, el agente tecnico tendra retrieval pobre. Asegurate de que cada dominio tenga documentacion suficiente. Si un dominio es \"pobre\", mejor fusionarlo con otro.\n",
    "\n",
    "### 5. Ignorar queries ambiguas en las metricas\n",
    "Las queries que el clasificador envia a fallback por baja confianza son **senales valiosas**. Analizalas periodicamente: muchas queries ambiguas en un mismo tema pueden indicar que necesitas un nuevo dominio o mejorar la documentacion existente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 25. Checklist de Comprension\n",
    "\n",
    "Antes de pasar al siguiente notebook, deberias poder responder estas preguntas:\n",
    "\n",
    "- [ ] **Por que separamos las colecciones por dominio** en lugar de indexar todo junto? Que problema resuelve?\n",
    "\n",
    "- [ ] **Que pasa si el umbral de confianza es demasiado alto** (ej. 0.95)? Y si es demasiado bajo (ej. 0.1)?\n",
    "\n",
    "- [ ] **Como agregarias un tercer dominio** (ej. BILLING) al grafo? Que nodos, edges y prompts necesitas?\n",
    "\n",
    "- [ ] **Que ventaja tiene el structured output** (Pydantic) sobre parsear texto libre del LLM para la clasificacion?\n",
    "\n",
    "- [ ] **En que escenario real de AI Engineering** aplicarias este patron de routing manana mismo?\n",
    "\n",
    "---\n",
    "\n",
    "**Siguiente paso**: Notebook 05 - Proyecto integrador que combina routing + prompt chaining + evaluacion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 2,
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}