{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 01: Pydantic para Pipelines de AI/ML\n",
    "\n",
    "**Clase extra de Python** | Notebook 6 de la serie\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivos de aprendizaje\n",
    "\n",
    "Al finalizar este notebook seras capaz de:\n",
    "\n",
    "1. **Validar requests de inferencia** usando modelos Pydantic con restricciones de campo.\n",
    "2. **Crear modelos con `field_validator`** para reglas de negocio personalizadas.\n",
    "3. **Manejar errores de validacion** de forma estructurada y accionable.\n",
    "4. **Comparar dict vs Pydantic** y entender por que los dicts producen bugs silenciosos.\n",
    "5. **Disenar contratos de datos** para pipelines de AI/ML completos.\n",
    "\n",
    "---\n",
    "\n",
    "| Aspecto | Detalle |\n",
    "|---|---|\n",
    "| **Tiempo estimado** | 60-90 minutos |\n",
    "| **Dependencias** | `pydantic` (ya instalado en el proyecto) |\n",
    "| **API keys** | No requiere. Todo se ejecuta localmente. |\n",
    "| **Base** | Expande `ejemplo_07_pydantic_ai.py` |\n",
    "\n",
    "> **Nota:** Este notebook no requiere API keys ni conexion a internet. Todo el codigo se ejecuta localmente."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === SETUP ===\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Literal, Optional\n",
    "from importlib import import_module\n",
    "\n",
    "from pydantic import (\n",
    "    BaseModel,\n",
    "    Field,\n",
    "    ValidationError,\n",
    "    field_validator,\n",
    "    model_validator,\n",
    ")\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Setup completo\")\n",
    "print(f\"Pydantic version: {import_module('pydantic').VERSION}\")\n",
    "print(f\"Fecha de ejecucion: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Por que validar datos en AI/ML?\n",
    "\n",
    "En un pipeline de AI/ML, los datos pasan por multiples etapas. **Sin validacion**, los errores\n",
    "se propagan silenciosamente y explotan en los lugares mas dificiles de depurar.\n",
    "\n",
    "### Flujo tipico de un pipeline\n",
    "\n",
    "```\n",
    "  Datos crudos       Validacion       Preprocesamiento       Modelo        Validacion       Output\n",
    "  (JSON/API)         de entrada       (features)             (inferencia)  de salida        (respuesta)\n",
    "       |                 |                  |                    |               |               |\n",
    "       v                 v                  v                    v               v               v\n",
    "  +----------+     +-----------+     +--------------+     +-----------+   +-----------+   +-----------+\n",
    "  | raw_data | --> | Pydantic  | --> | transform()  | --> | predict() | ->| Pydantic  | ->|  cliente  |\n",
    "  | (dict)   |     | Model     |     | normalize()  |     |           |   | Model     |   |  recibe   |\n",
    "  +----------+     +-----------+     +--------------+     +-----------+   +-----------+   +-----------+\n",
    "       ^                 ^                  ^                    ^               ^               ^\n",
    "     Puede            CAPTURA            Puede               Puede           CAPTURA          Datos\n",
    "     tener            errores            fallar si            dar             errores          limpios\n",
    "     basura           AQUI               datos malos          basura          AQUI             y seguros\n",
    "```\n",
    "\n",
    "### Que puede salir mal SIN validacion?\n",
    "\n",
    "| Etapa | Sin validacion | Con Pydantic |\n",
    "|---|---|---|\n",
    "| **Input** | Tipos incorrectos pasan silenciosamente (`\"123\"` como string en lugar de int) | `ValidationError` inmediato con ubicacion exacta del error |\n",
    "| **Features** | Valores fuera de rango (`age = -5`) corrompen el modelo | Restricciones `ge=0, le=120` rechazan el dato |\n",
    "| **Output del modelo** | Score de 1.5 (fuera de [0,1]) se envia al cliente | Constraint `le=1.0` lo detecta antes de responder |\n",
    "| **Campos faltantes** | `KeyError` en produccion a las 3 AM | Campo requerido reportado con nombre y tipo esperado |\n",
    "\n",
    "> **Principio clave:** Valida en los bordes del sistema (entrada y salida). El interior puede confiar en datos limpios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Seccion 1: Validacion de Request de Inferencia\n",
    "\n",
    "Cuando un cliente envia un request a tu API de inferencia, necesitas garantizar que:\n",
    "\n",
    "- El **prompt** tenga una longitud razonable (ni vacio ni excesivamente largo).\n",
    "- Los **hiperparametros** (`max_tokens`, `temperature`) esten dentro de rangos validos.\n",
    "- Los **tipos** sean correctos (no aceptar strings donde esperamos numeros).\n",
    "\n",
    "Pydantic hace todo esto de forma declarativa con `Field()`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Modelo: InferenceRequest ---\n",
    "\n",
    "class InferenceRequest(BaseModel):\n",
    "    \"\"\"Valida un request de inferencia a un LLM.\"\"\"\n",
    "    prompt: str = Field(min_length=5, max_length=2000, description=\"Texto de entrada para el modelo\")\n",
    "    max_tokens: int = Field(default=256, ge=1, le=4096, description=\"Maximo de tokens a generar\")\n",
    "    temperature: float = Field(default=0.2, ge=0.0, le=2.0, description=\"Temperatura de muestreo\")\n",
    "\n",
    "\n",
    "# --- Demo: request VALIDO ---\n",
    "print(\"=\" * 60)\n",
    "print(\"REQUEST VALIDO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "valid_payload = {\n",
    "    \"prompt\": \"Explica en 3 puntos por que MLOps necesita validacion de datos.\",\n",
    "    \"max_tokens\": 300,\n",
    "    \"temperature\": 0.3,\n",
    "}\n",
    "\n",
    "request = InferenceRequest(**valid_payload)\n",
    "print(f\"Tipo: {type(request).__name__}\")\n",
    "print(f\"Datos validados: {request.model_dump()}\")\n",
    "print()\n",
    "\n",
    "# --- Demo: request INVALIDO ---\n",
    "print(\"=\" * 60)\n",
    "print(\"REQUEST INVALIDO (3 errores simultaneos)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "invalid_payload = {\n",
    "    \"prompt\": \"hola\",           # Muy corto (min_length=5)\n",
    "    \"max_tokens\": \"muchos\",      # Tipo incorrecto (esperamos int)\n",
    "    \"temperature\": 4.2,          # Fuera de rango (max 2.0)\n",
    "}\n",
    "\n",
    "try:\n",
    "    InferenceRequest(**invalid_payload)\n",
    "except ValidationError as exc:\n",
    "    print(f\"Se encontraron {exc.error_count()} errores:\\n\")\n",
    "    for i, err in enumerate(exc.errors(), 1):\n",
    "        print(f\"  Error {i}:\")\n",
    "        print(f\"    Campo: {err['loc']}\")\n",
    "        print(f\"    Mensaje: {err['msg']}\")\n",
    "        print(f\"    Tipo: {err['type']}\")\n",
    "        print()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Seccion 2: Validacion de Features con Custom Validators\n",
    "\n",
    "Las restricciones basicas de `Field()` cubren muchos casos, pero a veces necesitamos\n",
    "**reglas de negocio** mas complejas. Para eso usamos `@field_validator`.\n",
    "\n",
    "### Cuando usar cada mecanismo\n",
    "\n",
    "```\n",
    "  Restriccion simple          Regla de negocio          Validacion entre campos\n",
    "  (rango, tipo, longitud)     (logica custom)           (campo A depende de B)\n",
    "         |                          |                           |\n",
    "         v                          v                           v\n",
    "    Field(ge=0, le=120)     @field_validator(\"campo\")    @model_validator(mode=\"after\")\n",
    "```\n",
    "\n",
    "`@field_validator` recibe el valor **de un campo individual** y puede:\n",
    "- Transformarlo (limpiar, normalizar).\n",
    "- Rechazarlo (lanzar `ValueError`).\n",
    "- Retornarlo validado."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Modelo: FeatureRow con custom validator ---\n",
    "\n",
    "class FeatureRow(BaseModel):\n",
    "    \"\"\"Una fila de features para un modelo de deteccion de fraude.\"\"\"\n",
    "    age: int = Field(ge=0, le=120, description=\"Edad del usuario\")\n",
    "    monthly_income_usd: float = Field(ge=0, description=\"Ingreso mensual en USD\")\n",
    "    tenure_months: int = Field(ge=0, description=\"Meses como cliente\")\n",
    "\n",
    "    @field_validator(\"monthly_income_usd\")\n",
    "    @classmethod\n",
    "    def reject_unrealistic_income(cls, value: float) -> float:\n",
    "        \"\"\"Rechaza ingresos mensuales irrealisticamente altos.\"\"\"\n",
    "        if value > 1_000_000:\n",
    "            raise ValueError(\n",
    "                f\"monthly_income_usd={value:,.0f} parece fuera de rango realista \"\n",
    "                f\"(maximo aceptado: 1,000,000)\"\n",
    "            )\n",
    "        return value\n",
    "\n",
    "\n",
    "# --- Demo: features VALIDAS ---\n",
    "print(\"=\" * 60)\n",
    "print(\"FEATURES VALIDAS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "valid_features = FeatureRow(age=29, monthly_income_usd=820.5, tenure_months=1)\n",
    "print(f\"Features: {valid_features.model_dump()}\")\n",
    "print()\n",
    "\n",
    "# --- Demo: features INVALIDAS (custom validator) ---\n",
    "print(\"=\" * 60)\n",
    "print(\"FEATURES INVALIDAS (ingreso irreal)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    FeatureRow(age=31, monthly_income_usd=2_500_000, tenure_months=4)\n",
    "except ValidationError as exc:\n",
    "    for err in exc.errors():\n",
    "        print(f\"  Campo: {err['loc']}\")\n",
    "        print(f\"  Mensaje: {err['msg']}\")\n",
    "        print(f\"  Input rechazado: {err.get('input', 'N/A')}\")\n",
    "        print()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Seccion 3: Validacion de Output del Modelo\n",
    "\n",
    "No solo necesitamos validar lo que **entra** al pipeline, tambien lo que **sale**.\n",
    "\n",
    "Un modelo de ML puede producir:\n",
    "- Un **label** que deberia ser uno de un conjunto fijo de valores (`Literal`).\n",
    "- Un **score** que deberia estar entre 0 y 1.\n",
    "- Una **explicacion** que deberia tener cierta longitud minima.\n",
    "\n",
    "Si alguno de estos contratos se rompe, queremos saberlo **antes** de enviar la respuesta al cliente."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Modelo: FraudPrediction ---\n",
    "\n",
    "class FraudPrediction(BaseModel):\n",
    "    \"\"\"Resultado validado de un modelo de deteccion de fraude.\"\"\"\n",
    "    label: Literal[\"fraud\", \"not_fraud\"]\n",
    "    score: float = Field(ge=0.0, le=1.0, description=\"Probabilidad de fraude\")\n",
    "    rationale: str = Field(min_length=10, description=\"Explicacion de la prediccion\")\n",
    "\n",
    "\n",
    "def fake_model_predict(features: FeatureRow) -> FraudPrediction:\n",
    "    \"\"\"Modelo simplificado solo para demo educativa.\"\"\"\n",
    "    if features.monthly_income_usd < 1000 and features.tenure_months < 3:\n",
    "        return FraudPrediction(\n",
    "            label=\"fraud\",\n",
    "            score=0.81,\n",
    "            rationale=\"Patron de riesgo: bajo ingreso y poca antiguedad.\",\n",
    "        )\n",
    "    return FraudPrediction(\n",
    "        label=\"not_fraud\",\n",
    "        score=0.22,\n",
    "        rationale=\"No se observan senales fuertes de fraude en las features.\",\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Pipeline: validar features -> predecir -> validar output ---\n",
    "print(\"=\" * 60)\n",
    "print(\"PIPELINE COMPLETO: Features -> Modelo -> Prediccion\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Paso 1: Validar features\n",
    "features = FeatureRow(age=29, monthly_income_usd=820.5, tenure_months=1)\n",
    "print(f\"\\n[Paso 1] Features validadas:\")\n",
    "print(f\"  {features.model_dump()}\")\n",
    "\n",
    "# Paso 2: Ejecutar modelo\n",
    "prediction = fake_model_predict(features)\n",
    "print(f\"\\n[Paso 2] Prediccion generada y validada:\")\n",
    "print(f\"  Label:     {prediction.label}\")\n",
    "print(f\"  Score:     {prediction.score}\")\n",
    "print(f\"  Rationale: {prediction.rationale}\")\n",
    "\n",
    "# Paso 3: Serializar para respuesta\n",
    "print(f\"\\n[Paso 3] JSON listo para enviar al cliente:\")\n",
    "print(f\"  {prediction.model_dump_json(indent=2)}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Seccion 4: Pipeline Completo con Manejo de Errores\n",
    "\n",
    "Ahora unimos todo en una funcion que toma un `dict` crudo y ejecuta el pipeline completo\n",
    "con manejo robusto de errores.\n",
    "\n",
    "```\n",
    "    dict crudo                                               dict / error\n",
    "        |                                                        ^\n",
    "        v                                                        |\n",
    "  +------------------------------------------------------------------+\n",
    "  |                    run_fraud_pipeline()                           |\n",
    "  |                                                                  |\n",
    "  |   raw_dict  -->  FeatureRow(**raw_dict)  -->  fake_model_predict  |\n",
    "  |                       |                            |             |\n",
    "  |                  ValidationError?             FraudPrediction    |\n",
    "  |                       |                            |             |\n",
    "  |                  return error              return .model_dump()  |\n",
    "  +------------------------------------------------------------------+\n",
    "```\n",
    "\n",
    "**Objetivo:** una sola funcion que nunca lanza excepciones no manejadas."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Pipeline completo con manejo de errores ---\n",
    "\n",
    "def run_fraud_pipeline(raw_data: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Ejecuta el pipeline de deteccion de fraude.\n",
    "    \n",
    "    Retorna:\n",
    "        dict con \"status\": \"ok\" y la prediccion, o\n",
    "        dict con \"status\": \"error\" y los detalles del error.\n",
    "    \"\"\"\n",
    "    # Paso 1: Validar features de entrada\n",
    "    try:\n",
    "        features = FeatureRow(**raw_data)\n",
    "    except ValidationError as exc:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"stage\": \"input_validation\",\n",
    "            \"error_count\": exc.error_count(),\n",
    "            \"errors\": [\n",
    "                {\"campo\": str(e[\"loc\"]), \"mensaje\": e[\"msg\"]}\n",
    "                for e in exc.errors()\n",
    "            ],\n",
    "        }\n",
    "\n",
    "    # Paso 2: Ejecutar modelo y validar output\n",
    "    try:\n",
    "        prediction = fake_model_predict(features)\n",
    "    except ValidationError as exc:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"stage\": \"output_validation\",\n",
    "            \"error_count\": exc.error_count(),\n",
    "            \"errors\": [\n",
    "                {\"campo\": str(e[\"loc\"]), \"mensaje\": e[\"msg\"]}\n",
    "                for e in exc.errors()\n",
    "            ],\n",
    "        }\n",
    "\n",
    "    # Paso 3: Exito\n",
    "    return {\n",
    "        \"status\": \"ok\",\n",
    "        \"input\": features.model_dump(),\n",
    "        \"prediction\": prediction.model_dump(),\n",
    "    }\n",
    "\n",
    "\n",
    "# --- Probar con 3 casos ---\n",
    "test_cases = [\n",
    "    {\n",
    "        \"nombre\": \"Caso 1: Valido (cliente joven, bajo ingreso)\",\n",
    "        \"data\": {\"age\": 22, \"monthly_income_usd\": 500.0, \"tenure_months\": 2},\n",
    "    },\n",
    "    {\n",
    "        \"nombre\": \"Caso 2: Edge case (valores en el limite)\",\n",
    "        \"data\": {\"age\": 120, \"monthly_income_usd\": 1_000_000, \"tenure_months\": 0},\n",
    "    },\n",
    "    {\n",
    "        \"nombre\": \"Caso 3: Invalido (multiples errores)\",\n",
    "        \"data\": {\"age\": -5, \"monthly_income_usd\": 2_500_000, \"tenure_months\": \"tres\"},\n",
    "    },\n",
    "]\n",
    "\n",
    "for case in test_cases:\n",
    "    print(\"=\" * 60)\n",
    "    print(case[\"nombre\"])\n",
    "    print(\"-\" * 60)\n",
    "    result = run_fraud_pipeline(case[\"data\"])\n",
    "    print(json.dumps(result, indent=2, ensure_ascii=False))\n",
    "    print()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Seccion 5: Dict vs Pydantic - Detectando Bugs Silenciosos\n",
    "\n",
    "Esta es la seccion mas importante del notebook. Vamos a ver **exactamente** por que\n",
    "usar dicts crudos en pipelines de AI/ML es peligroso.\n",
    "\n",
    "El problema fundamental:\n",
    "\n",
    "```\n",
    "  Dict crudo                              Pydantic\n",
    "  --------                                --------\n",
    "  - Acepta CUALQUIER dato                 - Solo acepta datos validos\n",
    "  - Errores aparecen DESPUES              - Errores aparecen EN EL MOMENTO\n",
    "    (durante el entrenamiento,              (antes de que el dato entre\n",
    "     la inferencia, o en produccion)         al pipeline)\n",
    "  - Mensajes de error crÃ­pticos           - Mensajes claros con ubicacion\n",
    "    (KeyError, TypeError, NaN)              y tipo de error\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Comparacion: Dict vs Pydantic ---\n",
    "\n",
    "# ============================================\n",
    "# ENFOQUE 1: Solo dicts (SIN validacion)\n",
    "# ============================================\n",
    "\n",
    "def process_with_dict(raw_data: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Procesa features directamente desde un dict.\n",
    "    NO valida nada. Los errores se propagan silenciosamente.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Simulamos calculo de un 'risk_score' basado en features\n",
    "        risk = (\n",
    "            (100 - raw_data[\"age\"]) * 0.3\n",
    "            + (5000 - raw_data[\"monthly_income_usd\"]) * 0.0005\n",
    "            + (12 - raw_data[\"tenure_months\"]) * 0.1\n",
    "        )\n",
    "        return {\"status\": \"ok\", \"risk_score\": round(risk, 4)}\n",
    "    except Exception as exc:\n",
    "        return {\"status\": \"error_tardio\", \"tipo\": type(exc).__name__, \"msg\": str(exc)}\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# ENFOQUE 2: Con Pydantic (CON validacion)\n",
    "# ============================================\n",
    "\n",
    "def process_with_pydantic(raw_data: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Valida con Pydantic ANTES de procesar.\n",
    "    Los errores se detectan temprano.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        features = FeatureRow(**raw_data)\n",
    "    except ValidationError as exc:\n",
    "        return {\n",
    "            \"status\": \"error_temprano\",\n",
    "            \"errores\": [f\"{e['loc']}: {e['msg']}\" for e in exc.errors()],\n",
    "        }\n",
    "\n",
    "    risk = (\n",
    "        (100 - features.age) * 0.3\n",
    "        + (5000 - features.monthly_income_usd) * 0.0005\n",
    "        + (12 - features.tenure_months) * 0.1\n",
    "    )\n",
    "    return {\"status\": \"ok\", \"risk_score\": round(risk, 4)}\n",
    "\n",
    "\n",
    "# --- Datos de prueba: mezcla de buenos y malos ---\n",
    "test_payloads = [\n",
    "    {\"desc\": \"Valido normal\",          \"data\": {\"age\": 35, \"monthly_income_usd\": 3000, \"tenure_months\": 24}},\n",
    "    {\"desc\": \"Edad negativa\",          \"data\": {\"age\": -5, \"monthly_income_usd\": 3000, \"tenure_months\": 12}},\n",
    "    {\"desc\": \"Ingreso como string\",    \"data\": {\"age\": 40, \"monthly_income_usd\": \"mucho\", \"tenure_months\": 6}},\n",
    "    {\"desc\": \"Campo faltante\",         \"data\": {\"age\": 30, \"tenure_months\": 10}},\n",
    "]\n",
    "\n",
    "print(f\"{'Caso':<25} {'Dict (sin validar)':<45} {'Pydantic (validado)':<45}\")\n",
    "print(\"=\" * 115)\n",
    "\n",
    "for payload in test_payloads:\n",
    "    dict_result = process_with_dict(payload[\"data\"])\n",
    "    pydantic_result = process_with_pydantic(payload[\"data\"])\n",
    "\n",
    "    # Resumir resultados para la tabla\n",
    "    if dict_result[\"status\"] == \"ok\":\n",
    "        dict_summary = f\"ok (risk={dict_result['risk_score']})  <-- puede ser BASURA\"\n",
    "    else:\n",
    "        dict_summary = f\"{dict_result['tipo']}: {dict_result['msg'][:35]}\"\n",
    "\n",
    "    if pydantic_result[\"status\"] == \"ok\":\n",
    "        pydantic_summary = f\"ok (risk={pydantic_result['risk_score']})\"\n",
    "    else:\n",
    "        pydantic_summary = f\"RECHAZADO: {'; '.join(pydantic_result['errores'])[:35]}\"\n",
    "\n",
    "    print(f\"{payload['desc']:<25} {dict_summary:<45} {pydantic_summary:<45}\")\n",
    "\n",
    "print()\n",
    "print(\"Observa: con dicts, la 'edad negativa' produce un risk_score INCORRECTO pero NO da error.\")\n",
    "print(\"Pydantic lo detecta INMEDIATAMENTE.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Stress test: 10 payloads, dict vs Pydantic ---\n",
    "\n",
    "stress_payloads = [\n",
    "    {\"age\": 25, \"monthly_income_usd\": 3500, \"tenure_months\": 14},     # Valido\n",
    "    {\"age\": 0,  \"monthly_income_usd\": 0,    \"tenure_months\": 0},      # Valido (edge)\n",
    "    {\"age\": -3, \"monthly_income_usd\": 2000,  \"tenure_months\": 5},     # Invalido: age < 0\n",
    "    {\"age\": 45, \"monthly_income_usd\": -100,  \"tenure_months\": 20},    # Invalido: income < 0\n",
    "    {\"age\": 130, \"monthly_income_usd\": 5000, \"tenure_months\": 36},    # Invalido: age > 120\n",
    "    {\"age\": 55, \"monthly_income_usd\": 2_500_000, \"tenure_months\": 8}, # Invalido: income irreal\n",
    "    {\"age\": \"joven\", \"monthly_income_usd\": 1000, \"tenure_months\": 3}, # Invalido: tipo incorrecto\n",
    "    {\"age\": 38, \"monthly_income_usd\": 4200, \"tenure_months\": 48},     # Valido\n",
    "    {\"monthly_income_usd\": 3000, \"tenure_months\": 12},                # Invalido: falta age\n",
    "    {\"age\": 60, \"monthly_income_usd\": 8000, \"tenure_months\": -2},     # Invalido: tenure < 0\n",
    "]\n",
    "\n",
    "dict_ok = 0\n",
    "dict_error_tardio = 0\n",
    "dict_bug_silencioso = 0\n",
    "pydantic_ok = 0\n",
    "pydantic_rechazado = 0\n",
    "\n",
    "for i, payload in enumerate(stress_payloads):\n",
    "    # Dict approach\n",
    "    dict_res = process_with_dict(payload)\n",
    "    if dict_res[\"status\"] == \"ok\":\n",
    "        # Verificamos si el dato REALMENTE era valido\n",
    "        pydantic_check = process_with_pydantic(payload)\n",
    "        if pydantic_check[\"status\"] == \"ok\":\n",
    "            dict_ok += 1\n",
    "        else:\n",
    "            dict_bug_silencioso += 1  # Dict dijo 'ok' pero dato era invalido!\n",
    "    else:\n",
    "        dict_error_tardio += 1\n",
    "\n",
    "    # Pydantic approach\n",
    "    pydantic_res = process_with_pydantic(payload)\n",
    "    if pydantic_res[\"status\"] == \"ok\":\n",
    "        pydantic_ok += 1\n",
    "    else:\n",
    "        pydantic_rechazado += 1\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STRESS TEST: 10 payloads (mezcla de validos e invalidos)\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(f\"{'Metrica':<40} {'Dict':>8} {'Pydantic':>10}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Procesados correctamente':<40} {dict_ok:>8} {pydantic_ok:>10}\")\n",
    "print(f\"{'Errores detectados temprano':<40} {'N/A':>8} {pydantic_rechazado:>10}\")\n",
    "print(f\"{'Errores detectados tarde (excepcion)':<40} {dict_error_tardio:>8} {'0':>10}\")\n",
    "print(f\"{'BUGS SILENCIOSOS (dato malo, sin error)':<40} {dict_bug_silencioso:>8} {'0':>10}\")\n",
    "print()\n",
    "print(f\"Los {dict_bug_silencioso} bugs silenciosos del dict son datos invalidos que\")\n",
    "print(f\"se procesaron sin error y produjeron resultados INCORRECTOS.\")\n",
    "print(f\"Pydantic los hubiera rechazado inmediatamente.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Seccion 6: Patrones Avanzados\n",
    "\n",
    "Tres patrones que aparecen frecuentemente en pipelines de produccion:\n",
    "\n",
    "1. **Modelos anidados:** Un `BatchRequest` que contiene una lista de `InferenceRequest`.\n",
    "2. **`model_validator`:** Validacion que involucra multiples campos (ej: si `temperature > 1.5`, `max_tokens` no puede ser mayor a 500).\n",
    "3. **Export de JSON Schema:** Generar el esquema JSON del modelo para documentacion o integracion con OpenAPI."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Patron 1: Modelos anidados ---\n",
    "\n",
    "class BatchInferenceRequest(BaseModel):\n",
    "    \"\"\"Batch de multiples requests de inferencia.\"\"\"\n",
    "    requests: list[InferenceRequest] = Field(\n",
    "        min_length=1, max_length=50, description=\"Lista de requests individuales\"\n",
    "    )\n",
    "    priority: Literal[\"low\", \"medium\", \"high\"] = Field(default=\"medium\")\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PATRON 1: Modelos anidados (BatchInferenceRequest)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "batch = BatchInferenceRequest(\n",
    "    requests=[\n",
    "        InferenceRequest(prompt=\"Analiza este texto sobre redes neuronales.\"),\n",
    "        InferenceRequest(prompt=\"Resume los resultados del experimento.\", max_tokens=100),\n",
    "    ],\n",
    "    priority=\"high\",\n",
    ")\n",
    "print(f\"Batch con {len(batch.requests)} requests, prioridad: {batch.priority}\")\n",
    "for i, req in enumerate(batch.requests):\n",
    "    print(f\"  Request {i+1}: prompt='{req.prompt[:40]}...' max_tokens={req.max_tokens}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# --- Patron 2: model_validator (validacion cruzada entre campos) ---\n",
    "\n",
    "class SafeInferenceRequest(BaseModel):\n",
    "    \"\"\"Request con validacion cruzada: alta temperatura + muchos tokens = peligro.\"\"\"\n",
    "    prompt: str = Field(min_length=5, max_length=2000)\n",
    "    max_tokens: int = Field(default=256, ge=1, le=4096)\n",
    "    temperature: float = Field(default=0.2, ge=0.0, le=2.0)\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def check_high_temp_low_tokens(self) -> SafeInferenceRequest:\n",
    "        \"\"\"Si temperature > 1.5, limitar max_tokens para evitar outputs muy largos y ruidosos.\"\"\"\n",
    "        if self.temperature > 1.5 and self.max_tokens > 500:\n",
    "            raise ValueError(\n",
    "                f\"Combinacion peligrosa: temperature={self.temperature} con \"\n",
    "                f\"max_tokens={self.max_tokens}. Con temperature > 1.5, \"\n",
    "                f\"max_tokens debe ser <= 500 para evitar outputs ruidosos.\"\n",
    "            )\n",
    "        return self\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PATRON 2: model_validator (validacion cruzada)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Valido: alta temperatura pero pocos tokens\n",
    "safe_req = SafeInferenceRequest(\n",
    "    prompt=\"Genera ideas creativas para nombres de producto.\",\n",
    "    temperature=1.8,\n",
    "    max_tokens=200,\n",
    ")\n",
    "print(f\"Valido: temp={safe_req.temperature}, tokens={safe_req.max_tokens}\")\n",
    "\n",
    "# Invalido: alta temperatura Y muchos tokens\n",
    "try:\n",
    "    SafeInferenceRequest(\n",
    "        prompt=\"Genera un ensayo largo sobre inteligencia artificial.\",\n",
    "        temperature=1.8,\n",
    "        max_tokens=2000,\n",
    "    )\n",
    "except ValidationError as exc:\n",
    "    for err in exc.errors():\n",
    "        print(f\"Rechazado: {err['msg']}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# --- Patron 3: Export de JSON Schema ---\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PATRON 3: JSON Schema (para documentacion y OpenAPI)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "schema = InferenceRequest.model_json_schema()\n",
    "print(json.dumps(schema, indent=2, ensure_ascii=False))\n",
    "print()\n",
    "print(\"Este schema se puede usar directamente en:\")\n",
    "print(\"  - Documentacion de API (OpenAPI/Swagger)\")\n",
    "print(\"  - Validacion en el frontend\")\n",
    "print(\"  - Generacion automatica de formularios\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Seccion 7: Serializacion y Deserializacion\n",
    "\n",
    "En pipelines reales, los datos llegan como **JSON** (desde APIs, archivos, colas de mensajes).\n",
    "Pydantic facilita la conversion entre JSON y objetos validados."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Serializacion y deserializacion ---\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SERIALIZACION: Objeto -> JSON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "features = FeatureRow(age=35, monthly_income_usd=4500.0, tenure_months=24)\n",
    "\n",
    "# model_dump() -> dict\n",
    "as_dict = features.model_dump()\n",
    "print(f\"model_dump() -> {type(as_dict).__name__}: {as_dict}\")\n",
    "\n",
    "# model_dump_json() -> str JSON\n",
    "as_json = features.model_dump_json(indent=2)\n",
    "print(f\"\\nmodel_dump_json():\\n{as_json}\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"DESERIALIZACION: JSON -> Objeto validado\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# model_validate_json() -> FeatureRow (desde JSON string)\n",
    "json_string = '{\"age\": 42, \"monthly_income_usd\": 6200.0, \"tenure_months\": 36}'\n",
    "from_json = FeatureRow.model_validate_json(json_string)\n",
    "print(f\"Desde JSON string: {from_json}\")\n",
    "\n",
    "# model_validate() -> FeatureRow (desde dict)\n",
    "from_dict = FeatureRow.model_validate({\"age\": 50, \"monthly_income_usd\": 7000, \"tenure_months\": 48})\n",
    "print(f\"Desde dict:        {from_dict}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# JSON invalido tambien se detecta\n",
    "print(\"JSON invalido:\")\n",
    "try:\n",
    "    FeatureRow.model_validate_json('{\"age\": -10, \"monthly_income_usd\": \"no_se\", \"tenure_months\": 5}')\n",
    "except ValidationError as exc:\n",
    "    for err in exc.errors():\n",
    "        print(f\"  {err['loc']}: {err['msg']}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Seccion 8: Resumen de la API de Pydantic\n",
    "\n",
    "Referencia rapida de los metodos y decoradores que usamos:\n",
    "\n",
    "| Metodo / Decorador | Que hace | Ejemplo |\n",
    "|---|---|---|\n",
    "| `Field(ge=0, le=100)` | Restriccion numerica en campo | `age: int = Field(ge=0, le=120)` |\n",
    "| `Field(min_length=5)` | Restriccion de longitud de string | `prompt: str = Field(min_length=5)` |\n",
    "| `Field(default=X)` | Valor por defecto | `temperature: float = Field(default=0.2)` |\n",
    "| `@field_validator` | Validacion custom de un campo | Rechazar ingresos > 1M |\n",
    "| `@model_validator` | Validacion cruzada entre campos | temp alta + muchos tokens |\n",
    "| `Literal[\"a\", \"b\"]` | Solo acepta valores del conjunto | `label: Literal[\"fraud\", \"not_fraud\"]` |\n",
    "| `.model_dump()` | Convierte a dict | `features.model_dump()` |\n",
    "| `.model_dump_json()` | Convierte a JSON string | `features.model_dump_json()` |\n",
    "| `.model_validate()` | Crea desde dict con validacion | `FeatureRow.model_validate(d)` |\n",
    "| `.model_validate_json()` | Crea desde JSON string con validacion | `FeatureRow.model_validate_json(s)` |\n",
    "| `.model_json_schema()` | Exporta JSON Schema | Para OpenAPI/Swagger |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejercicios\n",
    "\n",
    "Completa los siguientes ejercicios para afianzar lo aprendido. Cada uno incluye instrucciones\n",
    "detalladas y un esqueleto de codigo para que completes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ==========================================================\n",
    "# EJERCICIO 1: Modelos para un Pipeline de Entrenamiento\n",
    "# ==========================================================\n",
    "#\n",
    "# Crea dos modelos Pydantic:\n",
    "#\n",
    "# 1. TrainingConfig:\n",
    "#    - learning_rate: float entre 1e-6 y 1.0\n",
    "#    - epochs: int entre 1 y 1000\n",
    "#    - batch_size: int que DEBE ser potencia de 2 (usa @field_validator)\n",
    "#      Hint: un numero es potencia de 2 si (n & (n - 1)) == 0 y n > 0\n",
    "#    - optimizer: Literal[\"adam\", \"sgd\", \"adamw\"]\n",
    "#\n",
    "# 2. TrainingResult:\n",
    "#    - final_loss: float >= 0\n",
    "#    - accuracy: float entre 0.0 y 1.0\n",
    "#    - duration_seconds: float > 0\n",
    "#    - config: TrainingConfig  (modelo anidado!)\n",
    "#\n",
    "# Prueba:\n",
    "#   a) Crea un TrainingConfig valido y uno invalido (batch_size=100).\n",
    "#   b) Crea un TrainingResult completo.\n",
    "#   c) Exporta el JSON Schema de TrainingResult.\n",
    "# ==========================================================\n",
    "\n",
    "class TrainingConfig(BaseModel):\n",
    "    # Tu codigo aqui\n",
    "    pass\n",
    "\n",
    "\n",
    "class TrainingResult(BaseModel):\n",
    "    # Tu codigo aqui\n",
    "    pass\n",
    "\n",
    "\n",
    "# Pruebas (descomenta cuando completes los modelos):\n",
    "# config = TrainingConfig(learning_rate=0.001, epochs=50, batch_size=32, optimizer=\"adam\")\n",
    "# print(\"Config valido:\", config.model_dump())\n",
    "#\n",
    "# try:\n",
    "#     TrainingConfig(learning_rate=0.001, epochs=50, batch_size=100, optimizer=\"adam\")\n",
    "# except ValidationError as exc:\n",
    "#     print(\"Batch size invalido:\", exc.errors()[0][\"msg\"])\n",
    "#\n",
    "# result = TrainingResult(\n",
    "#     final_loss=0.023, accuracy=0.97, duration_seconds=342.5, config=config\n",
    "# )\n",
    "# print(\"\\nResultado completo:\")\n",
    "# print(result.model_dump_json(indent=2))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ==========================================================\n",
    "# EJERCICIO 2: Pipeline de Analisis de Sentimiento\n",
    "# ==========================================================\n",
    "#\n",
    "# Crea:\n",
    "#\n",
    "# 1. SentimentAnalysisRequest:\n",
    "#    - text: str (min_length=10, max_length=5000)\n",
    "#    - language: Literal[\"es\", \"en\", \"pt\"] con default \"es\"\n",
    "#    - include_confidence: bool con default True\n",
    "#\n",
    "# 2. SentimentAnalysisResponse:\n",
    "#    - sentiment: Literal[\"positive\", \"negative\", \"neutral\"]\n",
    "#    - confidence: float entre 0.0 y 1.0\n",
    "#    - original_text: str\n",
    "#    - @model_validator: si confidence < 0.5, sentiment debe ser \"neutral\"\n",
    "#      (un modelo con poca confianza no deberia dar una opinion fuerte)\n",
    "#\n",
    "# 3. Funcion fake_sentiment_analysis(request) -> SentimentAnalysisResponse\n",
    "#    que analice el texto de forma simplificada.\n",
    "#\n",
    "# 4. Procesa un batch de 5 textos (algunos validos, algunos invalidos).\n",
    "#    Imprime resultados y errores.\n",
    "# ==========================================================\n",
    "\n",
    "class SentimentAnalysisRequest(BaseModel):\n",
    "    # Tu codigo aqui\n",
    "    pass\n",
    "\n",
    "\n",
    "class SentimentAnalysisResponse(BaseModel):\n",
    "    # Tu codigo aqui\n",
    "    pass\n",
    "\n",
    "\n",
    "def fake_sentiment_analysis(request: SentimentAnalysisRequest) -> SentimentAnalysisResponse:\n",
    "    # Tu codigo aqui\n",
    "    pass\n",
    "\n",
    "\n",
    "# batch_texts = [\n",
    "#     {\"text\": \"Este producto es increible, me encanta!\", \"language\": \"es\"},\n",
    "#     {\"text\": \"Pesimo servicio, nunca mas vuelvo.\", \"language\": \"es\"},\n",
    "#     {\"text\": \"corto\"},  # invalido: muy corto\n",
    "#     {\"text\": \"El producto esta bien, nada especial.\", \"language\": \"es\"},\n",
    "#     {\"text\": \"Great product, highly recommended!\", \"language\": \"en\"},\n",
    "# ]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ==========================================================\n",
    "# EJERCICIO 3: Pipeline Validado para un Dominio de tu Eleccion\n",
    "# ==========================================================\n",
    "#\n",
    "# Construye un pipeline completo para UNO de estos dominios\n",
    "# (o inventa el tuyo propio):\n",
    "#\n",
    "# Opcion A: Clasificacion de imagenes\n",
    "#   - ImageClassificationRequest: image_url, model_name, top_k\n",
    "#   - ImageClassificationResponse: predictions (lista de {label, score})\n",
    "#\n",
    "# Opcion B: Recomendacion de productos\n",
    "#   - UserProfile: user_id, age, interests (lista), purchase_history_count\n",
    "#   - RecommendationResponse: products (lista), confidence, strategy\n",
    "#\n",
    "# Opcion C: Tu propio dominio\n",
    "#   - Define al menos 2 modelos (input y output)\n",
    "#   - Incluye al menos 1 field_validator y 1 model_validator\n",
    "#\n",
    "# Requisitos minimos:\n",
    "#   1. Modelo de input con al menos 4 campos y validaciones\n",
    "#   2. Modelo de output con Literal types y restricciones\n",
    "#   3. Funcion de pipeline que valida input -> procesa -> valida output\n",
    "#   4. Manejo de errores con mensajes claros\n",
    "#   5. Prueba con al menos 3 casos (valido, edge case, invalido)\n",
    "#   6. Exporta el JSON Schema de tu modelo principal\n",
    "# ==========================================================\n",
    "\n",
    "# Tu pipeline aqui\n",
    "pass"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Checklist de Consolidacion\n",
    "\n",
    "Antes de cerrar este notebook, verifica que puedes responder \"si\" a cada punto:\n",
    "\n",
    "- [ ] **Se crear un modelo Pydantic** con `Field()` para definir restricciones de tipo, rango y longitud.\n",
    "- [ ] **Se usar `@field_validator`** para agregar reglas de validacion personalizadas a un campo.\n",
    "- [ ] **Se usar `@model_validator`** para validaciones que involucran multiples campos.\n",
    "- [ ] **Entiendo la diferencia entre dict y Pydantic** y puedo explicar por que los dicts producen bugs silenciosos.\n",
    "- [ ] **Se atrapar `ValidationError`** e iterar sobre `.errors()` para generar mensajes de error utiles.\n",
    "- [ ] **Se serializar/deserializar** modelos con `model_dump()`, `model_dump_json()`, `model_validate()` y `model_validate_json()`.\n",
    "- [ ] **Se disenar contratos de datos** para un pipeline input -> procesamiento -> output.\n",
    "- [ ] **Se exportar JSON Schema** con `model_json_schema()` para documentacion o integracion.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "> **Pydantic convierte errores silenciosos en errores explicitos y accionables.**\n",
    "\n",
    "En pipelines de AI/ML, donde los datos fluyen a traves de multiples etapas y los errores\n",
    "pueden propagarse silenciosamente durante horas o dias, la validacion estructurada no es\n",
    "un lujo: es una necesidad.\n",
    "\n",
    "Lo que aprendimos hoy:\n",
    "- Pydantic declara **que forma deben tener los datos** (contrato).\n",
    "- Los errores se reportan **en el momento exacto** en que ocurren, no minutos u horas despues.\n",
    "- La combinacion de `Field()`, `@field_validator` y `@model_validator` cubre desde restricciones simples hasta reglas de negocio complejas.\n",
    "- El JSON Schema exportado permite integrar la validacion con el resto del ecosistema (APIs, frontend, documentacion).\n",
    "\n",
    "---\n",
    "\n",
    "### Proximos pasos\n",
    "\n",
    "**Notebook 02: Patrones de Produccion** - Veremos como aplicar estos conceptos en:\n",
    "- APIs con FastAPI + Pydantic\n",
    "- Configuracion de experimentos de ML\n",
    "- Logging estructurado con modelos validados\n",
    "- Testing automatizado de contratos de datos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}