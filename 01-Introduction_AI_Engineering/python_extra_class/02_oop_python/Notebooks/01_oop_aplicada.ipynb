{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 01: OOP Aplicada a AI/ML Engineering\n",
    "\n",
    "**Clase extra de Python - Notebook 4 de la serie**\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivos de aprendizaje\n",
    "\n",
    "Al finalizar este notebook seras capaz de:\n",
    "\n",
    "1. **Definir clases** con estado (atributos) y comportamiento (metodos) en contextos de AI/ML.\n",
    "2. **Proteger invariantes** con encapsulamiento (`@property`, convenciones `_private`).\n",
    "3. **Elegir entre herencia y composicion** segun el problema, aplicando polimorfismo.\n",
    "4. **Usar `dataclasses`** para datos estructurados sin boilerplate.\n",
    "5. **Aplicar logging** dentro de clases para trazabilidad de pipelines.\n",
    "6. **Disenar APIs limpias** usando criterios de responsabilidad unica y superficie minima.\n",
    "\n",
    "## Informacion del curso\n",
    "\n",
    "| Item | Detalle |\n",
    "|---|---|\n",
    "| **Tiempo estimado** | 90 - 120 minutos |\n",
    "| **Prerequisitos** | Notebooks 01-03 (variables, control de flujo, funciones) |\n",
    "| **Dependencias** | Solo biblioteca estandar de Python (no se necesita `pip install`) |\n",
    "| **Contexto** | AI Engineering - wrappers de modelos, servicios de inferencia, orquestadores |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# SETUP - Imports y configuracion\n",
    "# =============================================================================\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "import logging\n",
    "from typing import Protocol, Optional, List, Dict, Any\n",
    "from abc import ABC, abstractmethod\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Configuracion basica de logging para todo el notebook\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s | %(name)-25s | %(levelname)-8s | %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\",\n",
    "    force=True  # force=True para que funcione bien en Jupyter\n",
    ")\n",
    "\n",
    "# Verificacion rapida\n",
    "print(\"=\"*60)\n",
    "print(\"  Setup completo - Todos los imports cargados\")\n",
    "print(\"  Modulos: dataclasses, logging, typing, abc, time, json\")\n",
    "print(\"=\"*60)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Seccion 1: Clases, Estado y Comportamiento\n",
    "\n",
    "Una **clase** es la unidad fundamental de OOP. Combina **estado** (datos) y **comportamiento** (operaciones sobre esos datos) en una sola entidad.\n",
    "\n",
    "```\n",
    "+-----------------------------------------+\n",
    "|          CLASE: ModelConfig              |\n",
    "+-----------------------------------------+\n",
    "|  ESTADO (atributos)                     |\n",
    "|    - model_name: str                    |\n",
    "|    - temperature: float                 |\n",
    "|    - max_tokens: int                    |\n",
    "+-----------------------------------------+\n",
    "|  COMPORTAMIENTO (metodos)               |\n",
    "|    + __init__(...)     -> constructor    |\n",
    "|    + __repr__(...)     -> representacion |\n",
    "|    + validate()        -> validar config |\n",
    "|    + to_dict()         -> exportar       |\n",
    "+-----------------------------------------+\n",
    "              |\n",
    "              |  instanciar\n",
    "              v\n",
    "    config_gpt = ModelConfig(\"gpt-4\", 0.7, 1024)\n",
    "    config_claude = ModelConfig(\"claude\", 0.3, 2048)\n",
    "    (cada una es un OBJETO con su propio estado)\n",
    "```\n",
    "\n",
    "### Conceptos clave\n",
    "\n",
    "| Concepto | Definicion | Analogia en AI/ML |\n",
    "|---|---|---|\n",
    "| **Clase** | Blueprint / plantilla | Arquitectura de un modelo (ej: Transformer) |\n",
    "| **Instancia (objeto)** | Un ejemplar concreto | Un modelo entrenado con pesos especificos |\n",
    "| **Atributo** | Variable ligada al objeto | Pesos, hiperparametros, configuracion |\n",
    "| **Metodo** | Funcion ligada al objeto | `predict()`, `fit()`, `evaluate()` |\n",
    "| **`__init__`** | Constructor, inicializa estado | Cargar pesos y configuracion al crear el modelo |\n",
    "| **`self`** | Referencia a la instancia actual | \"Este modelo en particular\" |\n",
    "\n",
    "> **Regla fundamental**: `self` es siempre el primer parametro de los metodos de instancia. Python lo pasa automaticamente cuando llamas `objeto.metodo()`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# Seccion 1: Clases basicas en contexto AI/ML\n",
    "# =============================================================================\n",
    "\n",
    "class ModelConfig:\n",
    "    \"\"\"Configuracion para un modelo de lenguaje.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str, temperature: float, max_tokens: int):\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.created_at = time.time()  # estado interno automatico\n",
    "    \n",
    "    def validate(self) -> bool:\n",
    "        \"\"\"Valida que la configuracion sea coherente.\"\"\"\n",
    "        if not (0.0 <= self.temperature <= 2.0):\n",
    "            print(f\"  ERROR: temperature={self.temperature} fuera de rango [0.0, 2.0]\")\n",
    "            return False\n",
    "        if self.max_tokens <= 0:\n",
    "            print(f\"  ERROR: max_tokens={self.max_tokens} debe ser positivo\")\n",
    "            return False\n",
    "        print(f\"  OK: Configuracion valida para '{self.model_name}'\")\n",
    "        return True\n",
    "    \n",
    "    def to_dict(self) -> dict:\n",
    "        \"\"\"Exporta la configuracion como diccionario.\"\"\"\n",
    "        return {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"max_tokens\": self.max_tokens,\n",
    "        }\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return (f\"ModelConfig(model='{self.model_name}', \"\n",
    "                f\"temp={self.temperature}, tokens={self.max_tokens})\")\n",
    "\n",
    "\n",
    "class Prediction:\n",
    "    \"\"\"Resultado de una prediccion de modelo.\"\"\"\n",
    "    \n",
    "    def __init__(self, label: str, score: float):\n",
    "        self.label = label\n",
    "        self.score = score\n",
    "        self.timestamp = time.time()\n",
    "    \n",
    "    def is_confident(self, threshold: float = 0.8) -> bool:\n",
    "        \"\"\"Determina si la prediccion supera el umbral de confianza.\"\"\"\n",
    "        return self.score >= threshold\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Prediction(label='{self.label}', score={self.score:.3f})\"\n",
    "\n",
    "\n",
    "# --- Uso ---\n",
    "print(\"=== Creando configuraciones ===\")\n",
    "config_gpt = ModelConfig(\"gpt-4o\", 0.7, 1024)\n",
    "config_claude = ModelConfig(\"claude-opus\", 0.3, 4096)\n",
    "\n",
    "print(config_gpt)\n",
    "print(config_claude)\n",
    "print()\n",
    "\n",
    "print(\"=== Validando ===\")\n",
    "config_gpt.validate()\n",
    "config_malo = ModelConfig(\"test\", 5.0, -1)  # config invalida\n",
    "config_malo.validate()\n",
    "print()\n",
    "\n",
    "print(\"=== Predicciones ===\")\n",
    "pred1 = Prediction(\"positivo\", 0.95)\n",
    "pred2 = Prediction(\"negativo\", 0.42)\n",
    "\n",
    "print(f\"{pred1} -> confiable: {pred1.is_confident()}\")\n",
    "print(f\"{pred2} -> confiable: {pred2.is_confident()}\")\n",
    "print()\n",
    "\n",
    "print(\"=== Exportar a dict ===\")\n",
    "print(json.dumps(config_gpt.to_dict(), indent=2))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Seccion 2: Encapsulamiento - Proteger Invariantes\n",
    "\n",
    "El **encapsulamiento** es el principio de ocultar los detalles internos y exponer solo lo necesario. En Python usamos convenciones:\n",
    "\n",
    "```\n",
    "Nivel de acceso en Python:\n",
    "\n",
    "  self.publico        -> acceso libre desde cualquier lugar\n",
    "  self._protegido     -> convencion: \"no toques esto desde afuera\"\n",
    "  self.__privado      -> name mangling (Python renombra a _Clase__privado)\n",
    "\n",
    "  Patron recomendado:\n",
    "  +--------------------------------------------------+\n",
    "  |  Atributo interno: self._valor                   |\n",
    "  |                                                  |\n",
    "  |  @property          -> lectura controlada        |\n",
    "  |  def valor(self):                                |\n",
    "  |      return self._valor                          |\n",
    "  |                                                  |\n",
    "  |  @valor.setter      -> escritura con validacion  |\n",
    "  |  def valor(self, nuevo):                         |\n",
    "  |      if es_valido(nuevo):                        |\n",
    "  |          self._valor = nuevo                     |\n",
    "  |      else:                                       |\n",
    "  |          raise ValueError(...)                   |\n",
    "  +--------------------------------------------------+\n",
    "```\n",
    "\n",
    "### Por que encapsular?\n",
    "\n",
    "En AI/ML hay muchos valores que **no pueden ser cualquier cosa**:\n",
    "\n",
    "| Invariante | Restriccion | Sin encapsulamiento |\n",
    "|---|---|---|\n",
    "| Score de confianza | 0.0 <= score <= 1.0 | Alguien pone `score = 5.0` y rompe todo |\n",
    "| Temperature de LLM | 0.0 <= temp <= 2.0 | `temp = -1` genera error en la API |\n",
    "| Nombre de modelo | No puede estar vacio | `name = \"\"` causa bugs silenciosos |\n",
    "| Conteo de tokens | Entero positivo | `tokens = -500` es absurdo |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# Seccion 2: Encapsulamiento con @property\n",
    "# =============================================================================\n",
    "\n",
    "class ConfidenceScore:\n",
    "    \"\"\"Score de confianza que SIEMPRE esta en el rango [0.0, 1.0].\"\"\"\n",
    "    \n",
    "    def __init__(self, value: float):\n",
    "        # Usamos el setter para validar incluso en __init__\n",
    "        self.value = value  # esto llama al @value.setter\n",
    "    \n",
    "    @property\n",
    "    def value(self) -> float:\n",
    "        \"\"\"Lectura del score.\"\"\"\n",
    "        return self._value\n",
    "    \n",
    "    @value.setter\n",
    "    def value(self, new_value: float):\n",
    "        \"\"\"Escritura con validacion estricta.\"\"\"\n",
    "        if not isinstance(new_value, (int, float)):\n",
    "            raise TypeError(f\"Score debe ser numerico, recibido: {type(new_value).__name__}\")\n",
    "        if not (0.0 <= new_value <= 1.0):\n",
    "            raise ValueError(f\"Score debe estar en [0.0, 1.0], recibido: {new_value}\")\n",
    "        self._value = float(new_value)\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"ConfidenceScore({self._value:.4f})\"\n",
    "\n",
    "\n",
    "class ModelRegistry:\n",
    "    \"\"\"Registro de modelos que previene duplicados y expone conteo read-only.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._models: Dict[str, dict] = {}  # interno, no acceder directamente\n",
    "    \n",
    "    @property\n",
    "    def count(self) -> int:\n",
    "        \"\"\"Numero de modelos registrados (solo lectura).\"\"\"\n",
    "        return len(self._models)\n",
    "    \n",
    "    @property\n",
    "    def model_names(self) -> List[str]:\n",
    "        \"\"\"Lista de nombres registrados (copia, no referencia interna).\"\"\"\n",
    "        return list(self._models.keys())\n",
    "    \n",
    "    def register(self, name: str, metadata: dict) -> None:\n",
    "        \"\"\"Registra un modelo. Lanza error si ya existe.\"\"\"\n",
    "        if not name or not name.strip():\n",
    "            raise ValueError(\"El nombre del modelo no puede estar vacio\")\n",
    "        if name in self._models:\n",
    "            raise ValueError(f\"Modelo '{name}' ya esta registrado\")\n",
    "        self._models[name] = {\"metadata\": metadata, \"registered_at\": time.time()}\n",
    "    \n",
    "    def get(self, name: str) -> Optional[dict]:\n",
    "        \"\"\"Obtiene metadata de un modelo.\"\"\"\n",
    "        return self._models.get(name)\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"ModelRegistry(count={self.count}, models={self.model_names})\"\n",
    "\n",
    "\n",
    "# --- Demostracion: ConfidenceScore ---\n",
    "print(\"=== ConfidenceScore ===\")\n",
    "score = ConfidenceScore(0.87)\n",
    "print(f\"Creado: {score}\")\n",
    "print(f\"Acceso via property: {score.value}\")\n",
    "\n",
    "score.value = 0.95  # actualizacion valida\n",
    "print(f\"Actualizado: {score}\")\n",
    "\n",
    "print(\"\\nIntentando valores invalidos:\")\n",
    "for val_invalido in [1.5, -0.3, \"hola\"]:\n",
    "    try:\n",
    "        score.value = val_invalido\n",
    "    except (ValueError, TypeError) as e:\n",
    "        print(f\"  Rechazado {val_invalido!r}: {e}\")\n",
    "\n",
    "print(f\"\\nValor final intacto: {score}\")\n",
    "\n",
    "# --- Demostracion: ModelRegistry ---\n",
    "print(\"\\n=== ModelRegistry ===\")\n",
    "registry = ModelRegistry()\n",
    "registry.register(\"gpt-4o\", {\"provider\": \"openai\", \"type\": \"chat\"})\n",
    "registry.register(\"claude-opus\", {\"provider\": \"anthropic\", \"type\": \"chat\"})\n",
    "print(registry)\n",
    "print(f\"Conteo (read-only): {registry.count}\")\n",
    "\n",
    "print(\"\\nIntentando duplicado:\")\n",
    "try:\n",
    "    registry.register(\"gpt-4o\", {\"provider\": \"openai\"})\n",
    "except ValueError as e:\n",
    "    print(f\"  Rechazado: {e}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Seccion 3: Herencia y Polimorfismo\n",
    "\n",
    "La **herencia** permite crear clases que comparten interfaz y comportamiento. El **polimorfismo** permite tratar objetos diferentes de forma uniforme.\n",
    "\n",
    "```\n",
    "         +--------------------+\n",
    "         |   BasePredictor    |  <- clase abstracta (ABC)\n",
    "         |   (interfaz comun) |\n",
    "         +---------+----------+\n",
    "                   |\n",
    "          +--------+--------+\n",
    "          |                 |\n",
    "  +-------+------+  +------+--------+\n",
    "  | RuleBased    |  | Threshold     |\n",
    "  | Predictor    |  | Predictor     |\n",
    "  +--------------+  +---------------+\n",
    "  | predict()    |  | predict()     |\n",
    "  | (reglas)     |  | (umbral)      |\n",
    "  +--------------+  +---------------+\n",
    "\n",
    "  Polimorfismo: cualquier funcion que reciba un BasePredictor\n",
    "  funciona con AMBAS subclases sin saber cual es.\n",
    "```\n",
    "\n",
    "### Cuando usar (y cuando NO usar) herencia\n",
    "\n",
    "| Situacion | Usar herencia? | Motivo |\n",
    "|---|---|---|\n",
    "| Varios predictores con misma interfaz `predict()` | **Si** | Relacion \"es-un\" genuina |\n",
    "| Todos los modelos necesitan `save()` y `load()` | **Si** | Interfaz comun, implementacion diferente |\n",
    "| Quiero reusar el metodo `log_request()` de otra clase | **No** | Eso es composicion, no herencia |\n",
    "| Tengo 4+ niveles de herencia | **No** | Jerarquias profundas son fragiles |\n",
    "| La subclase usa solo el 30% de la clase padre | **No** | Herencia excesiva, mejor componer |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# Seccion 3: Herencia, ABC y polimorfismo\n",
    "# =============================================================================\n",
    "\n",
    "class BasePredictor(ABC):\n",
    "    \"\"\"Interfaz abstracta para cualquier predictor.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, text: str) -> Prediction:\n",
    "        \"\"\"Realiza una prediccion. Cada subclase lo implementa distinto.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{type(self).__name__}(name='{self.name}')\"\n",
    "\n",
    "\n",
    "class RuleBasedPredictor(BasePredictor):\n",
    "    \"\"\"Predictor basado en reglas de palabras clave.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, positive_words: List[str], negative_words: List[str]):\n",
    "        super().__init__(name)\n",
    "        self.positive_words = [w.lower() for w in positive_words]\n",
    "        self.negative_words = [w.lower() for w in negative_words]\n",
    "    \n",
    "    def predict(self, text: str) -> Prediction:\n",
    "        text_lower = text.lower()\n",
    "        pos_count = sum(1 for w in self.positive_words if w in text_lower)\n",
    "        neg_count = sum(1 for w in self.negative_words if w in text_lower)\n",
    "        total = pos_count + neg_count\n",
    "        if total == 0:\n",
    "            return Prediction(\"neutral\", 0.5)\n",
    "        score = pos_count / total\n",
    "        label = \"positivo\" if score > 0.5 else \"negativo\" if score < 0.5 else \"neutral\"\n",
    "        return Prediction(label, score)\n",
    "\n",
    "\n",
    "class ThresholdPredictor(BasePredictor):\n",
    "    \"\"\"Predictor que clasifica basado en longitud de texto y umbral.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, threshold: int = 50):\n",
    "        super().__init__(name)\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def predict(self, text: str) -> Prediction:\n",
    "        length = len(text)\n",
    "        if length > self.threshold:\n",
    "            score = min(length / (self.threshold * 3), 1.0)\n",
    "            return Prediction(\"detallado\", score)\n",
    "        else:\n",
    "            score = max(1.0 - (length / self.threshold), 0.0)\n",
    "            return Prediction(\"breve\", score)\n",
    "\n",
    "\n",
    "# --- Polimorfismo en accion ---\n",
    "def evaluate_predictor(predictor: BasePredictor, texts: List[str]) -> None:\n",
    "    \"\"\"Funciona con CUALQUIER subclase de BasePredictor.\"\"\"\n",
    "    print(f\"\\nEvaluando: {predictor}\")\n",
    "    print(\"-\" * 50)\n",
    "    for text in texts:\n",
    "        result = predictor.predict(text)\n",
    "        snippet = text[:40] + \"...\" if len(text) > 40 else text\n",
    "        print(f\"  '{snippet}' -> {result}\")\n",
    "\n",
    "\n",
    "# Crear predictores diferentes\n",
    "rule_pred = RuleBasedPredictor(\n",
    "    \"sentimiento-reglas\",\n",
    "    positive_words=[\"bueno\", \"excelente\", \"genial\", \"rapido\"],\n",
    "    negative_words=[\"malo\", \"lento\", \"error\", \"falla\"]\n",
    ")\n",
    "\n",
    "threshold_pred = ThresholdPredictor(\"longitud-texto\", threshold=30)\n",
    "\n",
    "# Textos de prueba\n",
    "textos = [\n",
    "    \"El modelo es bueno y rapido\",\n",
    "    \"Hay un error malo en la falla del sistema\",\n",
    "    \"Hola\",\n",
    "    \"Este es un texto mucho mas largo que deberia clasificarse como detallado por el predictor\",\n",
    "]\n",
    "\n",
    "# La MISMA funcion funciona con ambos predictores (polimorfismo)\n",
    "for predictor in [rule_pred, threshold_pred]:\n",
    "    evaluate_predictor(predictor, textos)\n",
    "\n",
    "# --- No puedes instanciar la clase abstracta ---\n",
    "print(\"\\n=== Intentando instanciar ABC ===\")\n",
    "try:\n",
    "    base = BasePredictor(\"base\")\n",
    "except TypeError as e:\n",
    "    print(f\"  Error esperado: {e}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Seccion 4: Composicion sobre Herencia\n",
    "\n",
    "El principio **\"prefiere composicion sobre herencia\"** es una de las guias mas importantes en diseno orientado a objetos.\n",
    "\n",
    "```\n",
    "  HERENCIA (is-a)                COMPOSICION (has-a)\n",
    "  ================               ==================\n",
    "\n",
    "  InferenceService               InferenceService\n",
    "       |                          |-- preprocessor: Preprocessor\n",
    "       v                          |-- model: Model\n",
    "  PreprocessingService            |-- postprocessor: Postprocessor\n",
    "       |                          (cada pieza es independiente\n",
    "       v                           y se puede reemplazar)\n",
    "  ModelService\n",
    "       |\n",
    "       v\n",
    "  PostprocessingService\n",
    "  (cadena rigida, dificil\n",
    "   de modificar o testear)\n",
    "```\n",
    "\n",
    "### Comparacion directa\n",
    "\n",
    "| Aspecto | Herencia | Composicion |\n",
    "|---|---|---|\n",
    "| **Relacion** | \"Es un\" (is-a) | \"Tiene un\" (has-a) |\n",
    "| **Acoplamiento** | Alto (subclase depende de padre) | Bajo (piezas independientes) |\n",
    "| **Flexibilidad** | Rigida (jerarquia fija) | Flexible (intercambiar piezas) |\n",
    "| **Testing** | Dificil aislar partes | Facil testear cada pieza |\n",
    "| **Reutilizacion** | Solo via jerarquia | En cualquier combinacion |\n",
    "| **Cuando usar** | Interfaz comun genuina | La mayoria de los demas casos |\n",
    "\n",
    "> **Regla practica**: Si dudas entre herencia y composicion, elige composicion. Solo usa herencia cuando la relacion \"es-un\" es clara e inmutable."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# Seccion 4: Composicion en un servicio de inferencia\n",
    "# =============================================================================\n",
    "\n",
    "# --- Componentes independientes ---\n",
    "\n",
    "class Preprocessor:\n",
    "    \"\"\"Limpia y normaliza el texto de entrada.\"\"\"\n",
    "    \n",
    "    def process(self, text: str) -> str:\n",
    "        cleaned = text.strip().lower()\n",
    "        print(f\"    [Preprocessor] '{text[:30]}...' -> '{cleaned[:30]}...'\")\n",
    "        return cleaned\n",
    "\n",
    "\n",
    "class FakeModel:\n",
    "    \"\"\"Simula un modelo de ML (sin dependencias externas).\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "    \n",
    "    def predict(self, text: str) -> dict:\n",
    "        # Simulacion: score basado en longitud\n",
    "        score = min(len(text) / 100, 1.0)\n",
    "        result = {\"label\": \"positivo\" if score > 0.5 else \"negativo\", \"score\": score}\n",
    "        print(f\"    [FakeModel:{self.name}] score={score:.3f}\")\n",
    "        return result\n",
    "\n",
    "\n",
    "class Postprocessor:\n",
    "    \"\"\"Formatea y enriquece la salida del modelo.\"\"\"\n",
    "    \n",
    "    def __init__(self, confidence_threshold: float = 0.7):\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "    \n",
    "    def process(self, raw_result: dict) -> dict:\n",
    "        enriched = {\n",
    "            **raw_result,\n",
    "            \"is_confident\": raw_result[\"score\"] >= self.confidence_threshold,\n",
    "            \"timestamp\": time.time(),\n",
    "        }\n",
    "        print(f\"    [Postprocessor] confident={enriched['is_confident']}\")\n",
    "        return enriched\n",
    "\n",
    "\n",
    "# --- Servicio compuesto ---\n",
    "\n",
    "class InferenceService:\n",
    "    \"\"\"Servicio de inferencia que COMPONE (has-a) sus partes.\n",
    "    \n",
    "    Cada componente es independiente y se puede reemplazar.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, preprocessor: Preprocessor, model: FakeModel, postprocessor: Postprocessor):\n",
    "        self.preprocessor = preprocessor\n",
    "        self.model = model\n",
    "        self.postprocessor = postprocessor\n",
    "    \n",
    "    def run(self, text: str) -> dict:\n",
    "        \"\"\"Ejecuta el pipeline completo.\"\"\"\n",
    "        print(f\"  Pipeline de inferencia iniciado\")\n",
    "        cleaned = self.preprocessor.process(text)\n",
    "        raw = self.model.predict(cleaned)\n",
    "        final = self.postprocessor.process(raw)\n",
    "        print(f\"  Pipeline completado\")\n",
    "        return final\n",
    "\n",
    "\n",
    "# --- Uso: Composicion permite intercambiar piezas ---\n",
    "print(\"=== Servicio con modelo A ===\")\n",
    "service_a = InferenceService(\n",
    "    preprocessor=Preprocessor(),\n",
    "    model=FakeModel(\"modelo-sentimiento-v1\"),\n",
    "    postprocessor=Postprocessor(confidence_threshold=0.7)\n",
    ")\n",
    "result_a = service_a.run(\"  Este producto es EXCELENTE y lo recomiendo totalmente para todos  \")\n",
    "print(f\"  Resultado: {json.dumps(result_a, indent=2, default=str)}\")\n",
    "\n",
    "print(\"\\n=== Mismo servicio, modelo diferente (swap facil!) ===\")\n",
    "service_b = InferenceService(\n",
    "    preprocessor=Preprocessor(),\n",
    "    model=FakeModel(\"modelo-sentimiento-v2\"),  # <- solo cambiamos el modelo\n",
    "    postprocessor=Postprocessor(confidence_threshold=0.5)  # <- y el umbral\n",
    ")\n",
    "result_b = service_b.run(\"  Malo  \")\n",
    "print(f\"  Resultado: {json.dumps(result_b, indent=2, default=str)}\")\n",
    "\n",
    "print(\"\\n--- Ventaja clave ---\")\n",
    "print(\"Con composicion, cambiar un componente NO requiere modificar los demas.\")\n",
    "print(\"Con herencia profunda, un cambio en la clase padre puede romper TODAS las subclases.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Seccion 5: Dataclasses - Datos Estructurados sin Boilerplate\n",
    "\n",
    "Las **dataclasses** (Python 3.7+) generan automaticamente `__init__`, `__repr__`, `__eq__` y mas. Ideales para objetos que son principalmente **contenedores de datos**.\n",
    "\n",
    "### Clase regular vs Dataclass\n",
    "\n",
    "```python\n",
    "# --- SIN dataclass: mucho codigo repetitivo ---\n",
    "class ExperimentResult:\n",
    "    def __init__(self, model_name, accuracy, params):\n",
    "        self.model_name = model_name\n",
    "        self.accuracy = accuracy\n",
    "        self.params = params\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return (f\"ExperimentResult(model_name={self.model_name!r}, \"\n",
    "                f\"accuracy={self.accuracy}, params={self.params})\")\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return (self.model_name == other.model_name \n",
    "                and self.accuracy == other.accuracy\n",
    "                and self.params == other.params)\n",
    "\n",
    "# --- CON dataclass: Python genera todo lo anterior ---\n",
    "@dataclass\n",
    "class ExperimentResult:\n",
    "    model_name: str\n",
    "    accuracy: float\n",
    "    params: dict = field(default_factory=dict)\n",
    "```\n",
    "\n",
    "### Opciones importantes\n",
    "\n",
    "| Opcion | Default | Efecto |\n",
    "|---|---|---|\n",
    "| `@dataclass` | - | Genera `__init__`, `__repr__`, `__eq__` |\n",
    "| `frozen=True` | False | Instancias inmutables (no puedes cambiar atributos) |\n",
    "| `order=True` | False | Genera `__lt__`, `__le__`, etc. para ordenar |\n",
    "| `field(default_factory=list)` | - | Default seguro para tipos mutables |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# Seccion 5: Dataclasses en practica\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class ExperimentResult:\n",
    "    \"\"\"Resultado de un experimento de ML.\"\"\"\n",
    "    model_name: str\n",
    "    accuracy: float\n",
    "    f1_score: float\n",
    "    params: dict = field(default_factory=dict)\n",
    "    tags: List[str] = field(default_factory=list)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelVersion:\n",
    "    \"\"\"Version inmutable de un modelo (no se puede modificar despues de creada).\"\"\"\n",
    "    name: str\n",
    "    version: str\n",
    "    checksum: str\n",
    "\n",
    "\n",
    "@dataclass(order=True)\n",
    "class RankedModel:\n",
    "    \"\"\"Modelo con ranking. Ordena por score automaticamente.\"\"\"\n",
    "    score: float  # campo de ordenamiento (primer campo)\n",
    "    name: str = field(compare=False)  # no usar para comparar\n",
    "    details: str = field(compare=False, repr=False)\n",
    "\n",
    "\n",
    "# --- __repr__ automatico ---\n",
    "print(\"=== __repr__ automatico ===\")\n",
    "exp1 = ExperimentResult(\"bert-base\", 0.89, 0.87, {\"lr\": 0.001}, [\"nlp\", \"produccion\"])\n",
    "exp2 = ExperimentResult(\"gpt-finetune\", 0.92, 0.91, {\"lr\": 0.0001})\n",
    "print(exp1)\n",
    "print(exp2)\n",
    "\n",
    "# --- __eq__ automatico ---\n",
    "print(\"\\n=== __eq__ automatico ===\")\n",
    "exp3 = ExperimentResult(\"bert-base\", 0.89, 0.87, {\"lr\": 0.001}, [\"nlp\", \"produccion\"])\n",
    "print(f\"exp1 == exp3: {exp1 == exp3}\")  # True, mismos valores\n",
    "print(f\"exp1 == exp2: {exp1 == exp2}\")  # False, valores distintos\n",
    "\n",
    "# --- frozen=True: inmutabilidad ---\n",
    "print(\"\\n=== frozen=True (inmutable) ===\")\n",
    "version = ModelVersion(\"sentiment-model\", \"1.2.0\", \"abc123hash\")\n",
    "print(version)\n",
    "try:\n",
    "    version.name = \"otro-nombre\"  # no se puede!\n",
    "except AttributeError as e:\n",
    "    print(f\"  Inmutable! Error: {e}\")\n",
    "\n",
    "# --- order=True: ordenamiento automatico ---\n",
    "print(\"\\n=== order=True (ordenamiento) ===\")\n",
    "models = [\n",
    "    RankedModel(0.85, \"modelo-A\", \"baseline\"),\n",
    "    RankedModel(0.92, \"modelo-B\", \"mejorado\"),\n",
    "    RankedModel(0.78, \"modelo-C\", \"experimental\"),\n",
    "    RankedModel(0.95, \"modelo-D\", \"champion\"),\n",
    "]\n",
    "for m in sorted(models, reverse=True):\n",
    "    print(f\"  {m.score:.2f} - {m.name}\")\n",
    "\n",
    "# --- field(default_factory=...) evita el bug de mutable default ---\n",
    "print(\"\\n=== default_factory (seguridad con mutables) ===\")\n",
    "a = ExperimentResult(\"modelo-a\", 0.9, 0.88)\n",
    "b = ExperimentResult(\"modelo-b\", 0.8, 0.75)\n",
    "a.tags.append(\"produccion\")\n",
    "print(f\"Tags de a: {a.tags}\")\n",
    "print(f\"Tags de b: {b.tags}\")  # NO contaminado, cada uno tiene su propia lista"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Seccion 6: Logging en Clases\n",
    "\n",
    "El **logging** es esencial en produccion para rastrear el comportamiento de tus pipelines de ML. Cada clase deberia tener su propio logger.\n",
    "\n",
    "### Patron recomendado\n",
    "\n",
    "```python\n",
    "class MiClase:\n",
    "    def __init__(self):\n",
    "        self._logger = logging.getLogger(type(self).__name__)\n",
    "        self._logger.info(\"Instancia creada\")  # ciclo de vida\n",
    "    \n",
    "    def hacer_algo(self):\n",
    "        self._logger.debug(\"Procesando...\")    # detalle\n",
    "        self._logger.warning(\"Dato sospechoso\") # advertencia\n",
    "        self._logger.error(\"Algo fallo\")        # error\n",
    "```\n",
    "\n",
    "### Niveles de logging\n",
    "\n",
    "```\n",
    "  DEBUG    -> Detalles de ejecucion paso a paso\n",
    "  INFO     -> Eventos normales del ciclo de vida\n",
    "  WARNING  -> Algo inesperado pero no fatal\n",
    "  ERROR    -> Algo fallo, la operacion no se completo\n",
    "  CRITICAL -> Falla total del sistema\n",
    "```\n",
    "\n",
    "> **Buena practica**: Usa `type(self).__name__` en vez de `__name__` para que las subclases automaticamente obtengan su propio nombre de logger."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# Seccion 6: Logging en clases de ML\n",
    "# =============================================================================\n",
    "\n",
    "class MLPipeline:\n",
    "    \"\"\"Pipeline de ML con logging completo del ciclo de vida.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, steps: List[str]):\n",
    "        self._logger = logging.getLogger(type(self).__name__)\n",
    "        self.name = name\n",
    "        self.steps = steps\n",
    "        self._logger.info(f\"Pipeline '{name}' creado con {len(steps)} pasos: {steps}\")\n",
    "    \n",
    "    def process(self, data: List[str]) -> List[dict]:\n",
    "        \"\"\"Procesa una lista de textos a traves del pipeline.\"\"\"\n",
    "        self._logger.info(f\"Iniciando procesamiento de {len(data)} elementos\")\n",
    "        results = []\n",
    "        \n",
    "        for i, item in enumerate(data):\n",
    "            self._logger.debug(f\"Procesando item {i+1}/{len(data)}: '{item[:30]}...'\")\n",
    "            \n",
    "            # Advertencia si el texto es muy corto\n",
    "            if len(item.strip()) < 5:\n",
    "                self._logger.warning(f\"Item {i+1} tiene texto muy corto ({len(item)} chars), \"\n",
    "                                     f\"resultados pueden ser poco confiables\")\n",
    "            \n",
    "            # Simular procesamiento\n",
    "            try:\n",
    "                if not item.strip():\n",
    "                    raise ValueError(\"Texto vacio no permitido\")\n",
    "                result = {\n",
    "                    \"input\": item,\n",
    "                    \"output\": f\"procesado_{item[:20].lower()}\",\n",
    "                    \"steps_applied\": self.steps,\n",
    "                }\n",
    "                results.append(result)\n",
    "            except ValueError as e:\n",
    "                self._logger.error(f\"Error en item {i+1}: {e}\")\n",
    "        \n",
    "        self._logger.info(f\"Procesamiento completado: {len(results)}/{len(data)} exitosos\")\n",
    "        return results\n",
    "\n",
    "\n",
    "# --- Uso ---\n",
    "print(\"=\" * 60)\n",
    "print(\"  Observa los mensajes de logging (nivel, clase, mensaje)\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "pipeline = MLPipeline(\n",
    "    name=\"sentimiento-pipeline\",\n",
    "    steps=[\"tokenize\", \"normalize\", \"predict\"]\n",
    ")\n",
    "\n",
    "data = [\n",
    "    \"Este producto es excelente, lo recomiendo\",\n",
    "    \"Hola\",       # texto corto -> WARNING\n",
    "    \"\",           # texto vacio -> ERROR\n",
    "    \"El servicio al cliente fue pesimo y tardaron mucho\",\n",
    "]\n",
    "\n",
    "results = pipeline.process(data)\n",
    "print(f\"\\nResultados exitosos: {len(results)}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Seccion 7: Criterios de Diseno\n",
    "\n",
    "No todo necesita ser una clase. Saber **cuando usar cada herramienta** es la clave del buen diseno.\n",
    "\n",
    "### Tabla de decision\n",
    "\n",
    "| Situacion | Herramienta | Motivo |\n",
    "|---|---|---|\n",
    "| Transformar A -> B sin estado | **Funcion** | Simple, testeable, sin complejidad innecesaria |\n",
    "| Agrupar datos relacionados | **Dataclass** | Estructura clara, metodos auto-generados |\n",
    "| Mantener estado + comportamiento | **Clase** | Encapsulamiento, invariantes protegidos |\n",
    "| Operacion unica sin memoria | **Funcion** | Una clase con un solo metodo = funcion disfrazada |\n",
    "| Multiples implementaciones de una interfaz | **ABC + clases** | Polimorfismo genuino |\n",
    "| Configuracion inmutable | **Dataclass(frozen=True)** | Seguridad, hasheable |\n",
    "\n",
    "### Principios clave\n",
    "\n",
    "```\n",
    "1. RESPONSABILIDAD UNICA\n",
    "   Una clase = una razon para cambiar.\n",
    "   Si describes la clase con \"Y\", probablemente son dos clases.\n",
    "\n",
    "2. SUPERFICIE MINIMA\n",
    "   Exponer lo menos posible. Mas metodos publicos = mas contratos que mantener.\n",
    "\n",
    "3. COMPORTAMIENTO SOBRE DATOS\n",
    "   Si una clase solo tiene getters/setters sin logica, probablemente deberia\n",
    "   ser un diccionario o una dataclass.\n",
    "\n",
    "4. COMPOSICION SOBRE HERENCIA\n",
    "   Componer piezas es mas flexible que heredar cadenas.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# Seccion 7: Tres enfoques para el mismo problema\n",
    "# =============================================================================\n",
    "# Problema: wrapper para un proveedor de LLM con reintentos y cache\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "# ENFOQUE 1: Solo funciones (procedural)\n",
    "# Ventaja: simple, sin estado oculto\n",
    "# Desventaja: cada llamada necesita pasar toda la configuracion\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "def call_llm_functional(\n",
    "    prompt: str,\n",
    "    model: str,\n",
    "    temperature: float,\n",
    "    max_retries: int,\n",
    "    cache: dict,  # estado externo que el caller debe manejar\n",
    ") -> str:\n",
    "    \"\"\"Enfoque funcional: todo se pasa como parametro.\"\"\"\n",
    "    if prompt in cache:\n",
    "        return cache[prompt]\n",
    "    # Simular llamada\n",
    "    response = f\"[{model}] Respuesta para: {prompt[:30]}...\"\n",
    "    cache[prompt] = response\n",
    "    return response\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "# ENFOQUE 2: Clase con estado (OOP completo)\n",
    "# Ventaja: estado encapsulado, API limpia\n",
    "# Desventaja: mas codigo, mas complejidad\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "class LLMClient:\n",
    "    \"\"\"Enfoque OOP: estado encapsulado, metodos claros.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str, temperature: float = 0.7, max_retries: int = 3):\n",
    "        self._model = model\n",
    "        self._temperature = temperature\n",
    "        self._max_retries = max_retries\n",
    "        self._cache: Dict[str, str] = {}\n",
    "        self._call_count = 0\n",
    "    \n",
    "    def call(self, prompt: str) -> str:\n",
    "        if prompt in self._cache:\n",
    "            return self._cache[prompt]\n",
    "        self._call_count += 1\n",
    "        response = f\"[{self._model}] Respuesta para: {prompt[:30]}...\"\n",
    "        self._cache[prompt] = response\n",
    "        return response\n",
    "    \n",
    "    @property\n",
    "    def stats(self) -> dict:\n",
    "        return {\"calls\": self._call_count, \"cache_size\": len(self._cache)}\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "# ENFOQUE 3: Dataclass para config + funciones para comportamiento\n",
    "# Ventaja: datos y logica separados, muy testeable\n",
    "# Desventaja: no hay encapsulamiento del estado mutable\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class LLMConfig:\n",
    "    \"\"\"Configuracion inmutable del LLM.\"\"\"\n",
    "    model: str\n",
    "    temperature: float = 0.7\n",
    "    max_retries: int = 3\n",
    "\n",
    "\n",
    "def call_llm_with_config(config: LLMConfig, prompt: str, cache: dict) -> str:\n",
    "    \"\"\"Funcion pura (casi) que usa configuracion inmutable.\"\"\"\n",
    "    if prompt in cache:\n",
    "        return cache[prompt]\n",
    "    response = f\"[{config.model}] Respuesta para: {prompt[:30]}...\"\n",
    "    cache[prompt] = response\n",
    "    return response\n",
    "\n",
    "\n",
    "# --- Comparacion ---\n",
    "print(\"=\" * 60)\n",
    "print(\"  COMPARACION: 3 enfoques para wrapper de LLM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "prompt = \"Explica que es machine learning en 2 oraciones\"\n",
    "\n",
    "# Enfoque 1: Funcional\n",
    "cache1: dict = {}\n",
    "r1 = call_llm_functional(prompt, \"gpt-4\", 0.7, 3, cache1)\n",
    "print(f\"\\n1) Funcional:      {r1}\")\n",
    "\n",
    "# Enfoque 2: Clase\n",
    "client = LLMClient(\"gpt-4\")\n",
    "r2 = client.call(prompt)\n",
    "print(f\"2) Clase:          {r2}\")\n",
    "print(f\"   Stats:          {client.stats}\")\n",
    "\n",
    "# Enfoque 3: Dataclass + funcion\n",
    "config = LLMConfig(\"gpt-4\")\n",
    "cache3: dict = {}\n",
    "r3 = call_llm_with_config(config, prompt, cache3)\n",
    "print(f\"3) Dataclass+func: {r3}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Recomendacion:\")\n",
    "print(\"  - Si hay estado mutable importante (cache, conteo) -> Clase (enfoque 2)\")\n",
    "print(\"  - Si la config es fija y la logica es simple       -> Dataclass + funcion (enfoque 3)\")\n",
    "print(\"  - Si es una operacion suelta sin estado            -> Funcion pura (enfoque 1)\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "o0rx9u3mxk",
   "source": "---\n\n### Recapitulacion rapida antes de los ejercicios\n\nHasta aqui hemos cubierto **7 secciones** con los pilares de OOP aplicada:\n\n```\n  Seccion 1: Clases          ->  __init__, self, atributos, metodos\n  Seccion 2: Encapsulamiento ->  @property, validacion, invariantes\n  Seccion 3: Herencia        ->  ABC, @abstractmethod, polimorfismo\n  Seccion 4: Composicion     ->  has-a, piezas intercambiables\n  Seccion 5: Dataclasses     ->  @dataclass, field(), frozen\n  Seccion 6: Logging         ->  logging.getLogger, niveles\n  Seccion 7: Criterios       ->  funcion vs dataclass vs clase\n```\n\nLos ejercicios que siguen integran **multiples secciones** en cada problema. Si necesitas repasar, vuelve a la seccion correspondiente.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejercicios\n",
    "\n",
    "Pon en practica todo lo visto. Cada ejercicio integra multiples conceptos de las secciones anteriores.\n",
    "\n",
    "> **Nota**: Los cuerpos de los metodos estan con `pass`. Reemplaza `pass` con tu implementacion."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# EJERCICIO 1: LLMProvider con composicion\n",
    "# =============================================================================\n",
    "#\n",
    "# Conceptos: composicion, encapsulamiento, logging\n",
    "#\n",
    "# Instrucciones:\n",
    "#   1. Completa la clase RateLimiter:\n",
    "#      - Lleva un conteo de llamadas (_call_count) y un limite (max_calls)\n",
    "#      - El metodo check() retorna True si hay llamadas disponibles,\n",
    "#        False si se alcanzo el limite\n",
    "#      - El metodo record_call() incrementa el conteo\n",
    "#\n",
    "#   2. Completa la clase ResponseCache:\n",
    "#      - Usa un dict interno para almacenar respuestas\n",
    "#      - get(key) retorna la respuesta cacheada o None\n",
    "#      - set(key, value) almacena la respuesta\n",
    "#\n",
    "#   3. Completa la clase LLMProvider:\n",
    "#      - COMPONE un RateLimiter y un ResponseCache\n",
    "#      - Tiene su propio logger (logging.getLogger)\n",
    "#      - El metodo generate(prompt):\n",
    "#        a) Revisa el cache -> si hay respuesta, retornarla (log DEBUG)\n",
    "#        b) Revisa rate limit -> si no hay cuota, lanzar RuntimeError (log WARNING)\n",
    "#        c) \"Llama a la API\" (simula con f\"Respuesta para: {prompt}\")\n",
    "#        d) Cachea el resultado y registra la llamada (log INFO)\n",
    "#        e) Retorna la respuesta\n",
    "#\n",
    "# Pista: Mira la Seccion 4 (composicion) y Seccion 6 (logging) como referencia.\n",
    "# =============================================================================\n",
    "\n",
    "class RateLimiter:\n",
    "    \"\"\"Limita la cantidad de llamadas permitidas.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_calls: int):\n",
    "        self._max_calls = max_calls\n",
    "        self._call_count = 0\n",
    "    \n",
    "    def check(self) -> bool:\n",
    "        \"\"\"Retorna True si hay cuota disponible.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def record_call(self) -> None:\n",
    "        \"\"\"Registra una llamada realizada.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    def remaining(self) -> int:\n",
    "        \"\"\"Llamadas restantes.\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class ResponseCache:\n",
    "    \"\"\"Cache simple de respuestas.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._store: Dict[str, str] = {}\n",
    "    \n",
    "    def get(self, key: str) -> Optional[str]:\n",
    "        \"\"\"Retorna respuesta cacheada o None.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def set(self, key: str, value: str) -> None:\n",
    "        \"\"\"Almacena una respuesta.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    def size(self) -> int:\n",
    "        \"\"\"Numero de entradas en cache.\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class LLMProvider:\n",
    "    \"\"\"Proveedor de LLM que compone RateLimiter y ResponseCache.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str, max_calls: int = 10):\n",
    "        self.model_name = model_name\n",
    "        self._rate_limiter = RateLimiter(max_calls)\n",
    "        self._cache = ResponseCache()\n",
    "        self._logger = logging.getLogger(type(self).__name__)\n",
    "        self._logger.info(f\"Proveedor '{model_name}' inicializado (limite: {max_calls} llamadas)\")\n",
    "    \n",
    "    def generate(self, prompt: str) -> str:\n",
    "        \"\"\"Genera respuesta: cache -> rate limit -> API simulada -> cache.\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "# --- Prueba tu implementacion ---\n",
    "# Descomenta las siguientes lineas cuando completes el ejercicio:\n",
    "#\n",
    "# provider = LLMProvider(\"gpt-4o\", max_calls=3)\n",
    "# print(provider.generate(\"Hola mundo\"))           # llamada API\n",
    "# print(provider.generate(\"Hola mundo\"))           # desde cache\n",
    "# print(provider.generate(\"Otra pregunta\"))        # llamada API\n",
    "# print(provider.generate(\"Tercera pregunta\"))     # llamada API\n",
    "# print(provider.generate(\"Cuarta pregunta\"))      # RuntimeError: rate limit"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# EJERCICIO 2: ModelExperimentTracker con dataclasses\n",
    "# =============================================================================\n",
    "#\n",
    "# Conceptos: dataclasses, field(), metodos sobre colecciones\n",
    "#\n",
    "# Instrucciones:\n",
    "#   1. La dataclass Experiment ya esta definida. NO la modifiques.\n",
    "#\n",
    "#   2. Completa ExperimentTracker:\n",
    "#      - add_experiment(exp): agrega un experimento a la lista interna\n",
    "#      - best_by_metric(metric): retorna el experimento con el valor mas alto\n",
    "#        para esa metrica. Si ninguno tiene esa metrica, retorna None.\n",
    "#        (Las metricas estan en exp.metrics, que es un dict)\n",
    "#      - filter_by_tag(tag): retorna una lista de experimentos que contengan\n",
    "#        ese tag en su lista de tags.\n",
    "#      - summary(): retorna un dict con:\n",
    "#        {\"total\": N, \"models\": [lista de nombres unicos], \"all_tags\": [tags unicos]}\n",
    "#\n",
    "# Pista: Usa max() con key= para encontrar el mejor por metrica.\n",
    "#        Usa set comprehensions para tags/nombres unicos.\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class Experiment:\n",
    "    \"\"\"Un experimento individual.\"\"\"\n",
    "    name: str\n",
    "    model_name: str\n",
    "    metrics: Dict[str, float] = field(default_factory=dict)\n",
    "    tags: List[str] = field(default_factory=list)\n",
    "\n",
    "\n",
    "class ExperimentTracker:\n",
    "    \"\"\"Tracker que almacena y consulta experimentos.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._experiments: List[Experiment] = []\n",
    "    \n",
    "    def add_experiment(self, exp: Experiment) -> None:\n",
    "        \"\"\"Agrega un experimento al tracker.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def best_by_metric(self, metric: str) -> Optional[Experiment]:\n",
    "        \"\"\"Retorna el experimento con el valor mas alto para la metrica dada.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def filter_by_tag(self, tag: str) -> List[Experiment]:\n",
    "        \"\"\"Retorna experimentos que tengan el tag especificado.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def summary(self) -> dict:\n",
    "        \"\"\"Resumen general del tracker.\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "# --- Prueba tu implementacion ---\n",
    "# Descomenta las siguientes lineas cuando completes el ejercicio:\n",
    "#\n",
    "# tracker = ExperimentTracker()\n",
    "# tracker.add_experiment(Experiment(\"exp-001\", \"bert\", {\"accuracy\": 0.89, \"f1\": 0.87}, [\"nlp\", \"v1\"]))\n",
    "# tracker.add_experiment(Experiment(\"exp-002\", \"gpt\", {\"accuracy\": 0.92, \"f1\": 0.90}, [\"nlp\", \"v2\"]))\n",
    "# tracker.add_experiment(Experiment(\"exp-003\", \"bert\", {\"accuracy\": 0.91, \"f1\": 0.89}, [\"nlp\", \"v2\", \"produccion\"]))\n",
    "#\n",
    "# print(\"Mejor por accuracy:\", tracker.best_by_metric(\"accuracy\"))\n",
    "# print(\"Mejor por f1:\", tracker.best_by_metric(\"f1\"))\n",
    "# print(\"Tag 'v2':\", tracker.filter_by_tag(\"v2\"))\n",
    "# print(\"Summary:\", tracker.summary())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5noe4br3t43",
   "source": "# =============================================================================\n# EJERCICIO 4 (BONUS): Verificacion rapida de conceptos\n# =============================================================================\n# Ejecuta esta celda para verificar que entiendes los conceptos.\n# Cada assert debe pasar sin error. Si alguno falla, revisa la seccion\n# correspondiente.\n#\n# NO necesitas modificar nada. Solo ejecuta y observa.\n# =============================================================================\n\n# --- Test 1: Clases basicas ---\nclass _TestModel:\n    def __init__(self, name):\n        self.name = name\n    def greet(self):\n        return f\"Soy {self.name}\"\n\n_m = _TestModel(\"test\")\nassert _m.name == \"test\", \"Seccion 1: atributos de instancia\"\nassert _m.greet() == \"Soy test\", \"Seccion 1: metodos\"\nprint(\"Seccion 1 (Clases):          OK\")\n\n# --- Test 2: Encapsulamiento ---\n_cs = ConfidenceScore(0.5)\n_error_raised = False\ntry:\n    _cs.value = 2.0\nexcept ValueError:\n    _error_raised = True\nassert _error_raised, \"Seccion 2: @property setter debe rechazar valores invalidos\"\nassert _cs.value == 0.5, \"Seccion 2: valor no debe cambiar tras rechazo\"\nprint(\"Seccion 2 (Encapsulamiento):  OK\")\n\n# --- Test 3: Herencia ---\nassert isinstance(rule_pred, BasePredictor), \"Seccion 3: subclase es instancia del padre\"\n_pred_result = rule_pred.predict(\"bueno\")\nassert isinstance(_pred_result, Prediction), \"Seccion 3: predict retorna Prediction\"\nprint(\"Seccion 3 (Herencia):         OK\")\n\n# --- Test 4: Dataclasses ---\n_dc1 = ExperimentResult(\"a\", 0.9, 0.8)\n_dc2 = ExperimentResult(\"a\", 0.9, 0.8)\nassert _dc1 == _dc2, \"Seccion 5: __eq__ auto-generado en dataclass\"\n_dc1.tags.append(\"x\")\nassert _dc2.tags == [], \"Seccion 5: default_factory aisle listas\"\nprint(\"Seccion 5 (Dataclasses):      OK\")\n\n# --- Test 5: frozen ---\n_fv = ModelVersion(\"m\", \"1.0\", \"hash\")\n_frozen_error = False\ntry:\n    _fv.name = \"otro\"\nexcept AttributeError:\n    _frozen_error = True\nassert _frozen_error, \"Seccion 5: frozen=True impide modificacion\"\nprint(\"Seccion 5 (frozen):           OK\")\n\nprint(\"\\n\" + \"=\" * 50)\nprint(\"  Todos los conceptos verificados correctamente!\")\nprint(\"=\" * 50)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# EJERCICIO 3: Refactorizar una clase con demasiadas responsabilidades\n",
    "# =============================================================================\n",
    "#\n",
    "# Conceptos: responsabilidad unica, composicion, diseno limpio\n",
    "#\n",
    "# La siguiente clase \"DoEverythingModel\" viola el principio de responsabilidad\n",
    "# unica. Tiene DEMASIADAS responsabilidades mezcladas.\n",
    "#\n",
    "# Tu tarea: Refactoriza en clases mas pequenas y componlas.\n",
    "#\n",
    "# Pistas:\n",
    "#   - Identifica las responsabilidades (al menos 3 distintas)\n",
    "#   - Crea una clase por responsabilidad\n",
    "#   - Crea una clase orquestadora que las componga\n",
    "#   - Cada clase debe poder testearse independientemente\n",
    "# =============================================================================\n",
    "\n",
    "# --- CLASE PROBLEMATICA (NO modificar, es el \"antes\") ---\n",
    "\n",
    "class DoEverythingModel:\n",
    "    \"\"\"ANTI-PATRON: Esta clase hace demasiadas cosas.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str, db_path: str, log_file: str):\n",
    "        self.model_name = model_name\n",
    "        self.db_path = db_path\n",
    "        self.log_file = log_file\n",
    "        self.predictions = []       # almacena predicciones (responsabilidad: storage)\n",
    "        self.metrics = {}           # calcula metricas (responsabilidad: evaluacion)\n",
    "        self.call_count = 0         # rate limiting (responsabilidad: rate limit)\n",
    "        self.max_calls = 100\n",
    "    \n",
    "    def predict(self, text: str) -> dict:\n",
    "        # Rate limiting (responsabilidad 1)\n",
    "        if self.call_count >= self.max_calls:\n",
    "            raise RuntimeError(\"Rate limit alcanzado\")\n",
    "        self.call_count += 1\n",
    "        \n",
    "        # Preprocesamiento (responsabilidad 2)\n",
    "        text = text.strip().lower()\n",
    "        \n",
    "        # Prediccion (responsabilidad 3)\n",
    "        result = {\"label\": \"positivo\", \"score\": 0.85}\n",
    "        \n",
    "        # Storage (responsabilidad 4)\n",
    "        self.predictions.append({\"input\": text, \"output\": result})\n",
    "        \n",
    "        # Logging (responsabilidad 5)\n",
    "        print(f\"[LOG] {self.model_name} predijo {result['label']} para '{text[:20]}...'\")\n",
    "        \n",
    "        # Metricas (responsabilidad 6)\n",
    "        self.metrics[\"total_predictions\"] = len(self.predictions)\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "# --- TU REFACTORIZACION (escribe aqui debajo) ---\n",
    "# Crea las clases necesarias y luego una clase orquestadora\n",
    "# que las componga para lograr el mismo resultado.\n",
    "\n",
    "pass"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Consolidacion\n",
    "\n",
    "### Checklist de aprendizaje\n",
    "\n",
    "Marca cada item que puedas explicar con confianza:\n",
    "\n",
    "- [ ] Se como definir una clase con `__init__`, atributos y metodos\n",
    "- [ ] Entiendo que `self` es la referencia a la instancia actual\n",
    "- [ ] Puedo proteger invariantes con `@property` y `@setter`\n",
    "- [ ] Se la diferencia entre herencia (`is-a`) y composicion (`has-a`)\n",
    "- [ ] Puedo crear clases abstractas con `ABC` y `@abstractmethod`\n",
    "- [ ] Entiendo el polimorfismo: misma interfaz, distinta implementacion\n",
    "- [ ] Se cuando usar `@dataclass` en vez de una clase regular\n",
    "- [ ] Puedo usar `frozen=True` para crear objetos inmutables\n",
    "- [ ] Se configurar logging por clase con `logging.getLogger`\n",
    "- [ ] Puedo decidir entre funcion, dataclass y clase segun el problema\n",
    "\n",
    "### Framework de decision: Herencia vs Composicion\n",
    "\n",
    "```\n",
    "Necesito compartir interfaz/contrato?\n",
    "  |-- Si: Es una relacion \"es-un\" genuina?\n",
    "  |     |-- Si: Las subclases usan >80% de la clase padre?\n",
    "  |     |     |-- Si  -> HERENCIA (con ABC)\n",
    "  |     |     |-- No  -> COMPOSICION\n",
    "  |     |-- No -> COMPOSICION\n",
    "  |-- No: Solo quiero reusar codigo?\n",
    "        |-- Si -> COMPOSICION (o funciones)\n",
    "        |-- No -> Probablemente no necesitas ninguna de las dos\n",
    "```\n",
    "\n",
    "### Resumen de secciones\n",
    "\n",
    "| Seccion | Concepto clave | Patron principal |\n",
    "|---|---|---|\n",
    "| 1 | Clases y objetos | `class` + `__init__` + `self` |\n",
    "| 2 | Encapsulamiento | `@property` + validacion en setter |\n",
    "| 3 | Herencia/Polimorfismo | `ABC` + `@abstractmethod` |\n",
    "| 4 | Composicion | `has-a` en vez de `is-a` |\n",
    "| 5 | Dataclasses | `@dataclass` + `field()` |\n",
    "| 6 | Logging | `logging.getLogger(type(self).__name__)` |\n",
    "| 7 | Criterios de diseno | Funcion vs Dataclass vs Clase |\n",
    "\n",
    "---\n",
    "\n",
    "### Siguiente paso\n",
    "\n",
    "**Notebook 05: Algoritmos y Estructuras de Datos** - donde aplicaremos OOP para implementar estructuras de datos comunes y algoritmos fundamentales en contextos de AI/ML.\n",
    "\n",
    "---\n",
    "\n",
    "*Notebook 04 - OOP Aplicada a AI/ML Engineering - Clase Extra de Python*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}